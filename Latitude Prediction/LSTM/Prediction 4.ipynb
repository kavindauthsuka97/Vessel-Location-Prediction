{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Training set - 2023 Jan to 2024 May\n",
        "Input window = 28"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "61beb701-6eac-4e45-80c7-4239d4ab2ed0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Import the libraries"
      ],
      "metadata": {},
      "id": "8b7d27d4-1baa-4a30-a352-89e822008ce0"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install matplotlib"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: matplotlib in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (3.9.2)\nRequirement already satisfied: contourpy>=1.0.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib) (1.3.0)\nRequirement already satisfied: cycler>=0.10 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib) (4.54.1)\nRequirement already satisfied: kiwisolver>=1.3.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib) (1.4.7)\nRequirement already satisfied: numpy>=1.23 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib) (2.0.2)\nRequirement already satisfied: packaging>=20.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib) (24.1)\nRequirement already satisfied: pillow>=8 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib) (10.4.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib) (2.9.0)\nRequirement already satisfied: six>=1.5 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731508894100
        }
      },
      "id": "08f290a3-fda0-417b-9a9f-aa4034917cfc"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import timedelta\n",
        "import matplotlib.pyplot as plt"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1731508894292
        }
      },
      "id": "127f3d8f-3671-4640-b177-d8e7d2913b6b"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: tensorflow in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (2.18.0)\nRequirement already satisfied: termcolor>=1.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: flatbuffers>=24.3.25 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (24.3.25)\nRequirement already satisfied: numpy<2.1.0,>=1.26.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: typing-extensions>=3.6.6 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (4.12.2)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (0.6.0)\nRequirement already satisfied: absl-py>=1.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (2.1.0)\nRequirement already satisfied: packaging in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (24.1)\nRequirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (0.4.1)\nRequirement already satisfied: libclang>=13.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (1.65.4)\nRequirement already satisfied: wrapt>=1.11.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (1.14.1)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: astunparse>=1.6.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: six>=1.12.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: tensorboard<2.19,>=2.18 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (2.18.0)\nRequirement already satisfied: requests<3,>=2.21.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (2.32.3)\nRequirement already satisfied: opt-einsum>=2.3.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: keras>=3.5.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (3.5.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (0.37.1)\nRequirement already satisfied: setuptools in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (68.0.0)\nRequirement already satisfied: h5py>=3.11.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (3.11.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\nRequirement already satisfied: optree in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.12.1)\nRequirement already satisfied: namex in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\nRequirement already satisfied: rich in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (13.8.1)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.19)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.0.3)\nRequirement already satisfied: markdown>=2.6.8 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.5)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\nRequirement already satisfied: mdurl~=0.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2024-11-13 14:41:40.729950: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n2024-11-13 14:41:40.746093: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1731508900.765465   62850 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1731508900.771237   62850 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2024-11-13 14:41:40.791260: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731508901241
        }
      },
      "id": "163193b3-3302-43fa-a5fe-a03569386e15"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scipy scikit-learn"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: scipy in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (1.14.1)\nRequirement already satisfied: scikit-learn in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (1.5.2)\nRequirement already satisfied: numpy<2.3,>=1.23.5 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from scipy) (2.0.2)\nRequirement already satisfied: joblib>=1.2.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731508902012
        }
      },
      "id": "076892a3-aa54-4cc7-a69a-439bf536527e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Pre processing the dataset"
      ],
      "metadata": {},
      "id": "e4cc4d9f-b792-46c2-8712-666765ac0971"
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "data = pd.read_csv('LL_data.csv')"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1731508903134
        }
      },
      "id": "e256e925-7472-4f1c-9c5f-df13d393783f"
    },
    {
      "cell_type": "code",
      "source": [
        "data.tail()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "         Received_Timestamp  Latitude  Longitude\n796631  2024-08-16 20:26:55  6.301900  94.509340\n796632  2024-08-16 20:41:52  6.304237  94.558950\n796633  2024-08-16 20:44:07  6.304650  94.566895\n796634  2024-08-16 20:44:45  6.304758  94.569090\n796635  2024-08-16 21:01:24  6.306820  94.625694",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Received_Timestamp</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>796631</th>\n      <td>2024-08-16 20:26:55</td>\n      <td>6.301900</td>\n      <td>94.509340</td>\n    </tr>\n    <tr>\n      <th>796632</th>\n      <td>2024-08-16 20:41:52</td>\n      <td>6.304237</td>\n      <td>94.558950</td>\n    </tr>\n    <tr>\n      <th>796633</th>\n      <td>2024-08-16 20:44:07</td>\n      <td>6.304650</td>\n      <td>94.566895</td>\n    </tr>\n    <tr>\n      <th>796634</th>\n      <td>2024-08-16 20:44:45</td>\n      <td>6.304758</td>\n      <td>94.569090</td>\n    </tr>\n    <tr>\n      <th>796635</th>\n      <td>2024-08-16 21:01:24</td>\n      <td>6.306820</td>\n      <td>94.625694</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1731508903353
        }
      },
      "id": "10b13fcb-7cc9-42f7-8a51-2bd13a41a172"
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the 'Longitude' column\n",
        "data = data.drop(columns=['Longitude'])"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731508903582
        }
      },
      "id": "fb42c11a-328a-48cd-9a2a-76268cc3f1ba"
    },
    {
      "cell_type": "code",
      "source": [
        "data.tail()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "         Received_Timestamp  Latitude\n796631  2024-08-16 20:26:55  6.301900\n796632  2024-08-16 20:41:52  6.304237\n796633  2024-08-16 20:44:07  6.304650\n796634  2024-08-16 20:44:45  6.304758\n796635  2024-08-16 21:01:24  6.306820",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Received_Timestamp</th>\n      <th>Latitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>796631</th>\n      <td>2024-08-16 20:26:55</td>\n      <td>6.301900</td>\n    </tr>\n    <tr>\n      <th>796632</th>\n      <td>2024-08-16 20:41:52</td>\n      <td>6.304237</td>\n    </tr>\n    <tr>\n      <th>796633</th>\n      <td>2024-08-16 20:44:07</td>\n      <td>6.304650</td>\n    </tr>\n    <tr>\n      <th>796634</th>\n      <td>2024-08-16 20:44:45</td>\n      <td>6.304758</td>\n    </tr>\n    <tr>\n      <th>796635</th>\n      <td>2024-08-16 21:01:24</td>\n      <td>6.306820</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731508903816
        }
      },
      "id": "e40aaa60-1ac4-4aa1-9e8d-5c87f9d9ad4b"
    },
    {
      "cell_type": "code",
      "source": [
        "data['Received_Timestamp'] = pd.to_datetime(data['Received_Timestamp'])  # Convert to datetime\n",
        "data['Latitude'] = pd.to_numeric(data['Latitude'], errors='coerce')       # Convert to numeric, handling errors\n",
        "#data['Longitude'] = pd.to_numeric(data['Longitude'], errors='coerce')     # Convert to numeric, handling errors\n",
        "data = data.dropna()  # Drop rows with NaN values if any remain"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1731508904017
        }
      },
      "id": "f6c0ae3f-2e49-494c-a64a-2ecb0857965d"
    },
    {
      "cell_type": "code",
      "source": [
        "data.set_index('Received_Timestamp', inplace=True)  # Set datetime as the index"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1731508904202
        }
      },
      "id": "33499773-a2f4-4909-9721-ce54ba7b4d49"
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nDatetimeIndex: 796636 entries, 2023-01-01 00:36:49 to 2024-08-16 21:01:24\nData columns (total 1 columns):\n #   Column    Non-Null Count   Dtype  \n---  ------    --------------   -----  \n 0   Latitude  796636 non-null  float64\ndtypes: float64(1)\nmemory usage: 12.2 MB\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1731508904352
        }
      },
      "id": "22be6e4b-0125-4f16-b479-8c35f7696499"
    },
    {
      "cell_type": "code",
      "source": [
        "# Resample data to six-hour bins, handling empty bins with interpolation\n",
        "data = data.resample('6H').mean()  # Bin by six hours with mean aggregation\n",
        "data = data.interpolate(method='linear')  # Linear interpolation for missing bins"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/tmp/ipykernel_62850/4293368568.py:2: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n  data = data.resample('6H').mean()  # Bin by six hours with mean aggregation\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1731508904510
        }
      },
      "id": "6abe400b-de03-41ed-a463-6ecf09cd28f7"
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "                      Latitude\nReceived_Timestamp            \n2023-01-01 00:00:00  23.954669\n2023-01-01 06:00:00  23.719084\n2023-01-01 12:00:00  23.347651\n2023-01-01 18:00:00  23.076742\n2023-01-02 00:00:00  22.740178",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Latitude</th>\n    </tr>\n    <tr>\n      <th>Received_Timestamp</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2023-01-01 00:00:00</th>\n      <td>23.954669</td>\n    </tr>\n    <tr>\n      <th>2023-01-01 06:00:00</th>\n      <td>23.719084</td>\n    </tr>\n    <tr>\n      <th>2023-01-01 12:00:00</th>\n      <td>23.347651</td>\n    </tr>\n    <tr>\n      <th>2023-01-01 18:00:00</th>\n      <td>23.076742</td>\n    </tr>\n    <tr>\n      <th>2023-01-02 00:00:00</th>\n      <td>22.740178</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1731508904677
        }
      },
      "id": "d49f9023-7d31-46be-b9bf-e58bb7302e7f"
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nDatetimeIndex: 2376 entries, 2023-01-01 00:00:00 to 2024-08-16 18:00:00\nFreq: 6h\nData columns (total 1 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   Latitude  2376 non-null   float64\ndtypes: float64(1)\nmemory usage: 37.1 KB\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1731508904883
        }
      },
      "id": "a31a1b6f-eb1c-4a56-a32d-11b27f098db1"
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "# Ensure 'Latitude' is in a 2D format before scaling\n",
        "data['Latitude'] = scaler.fit_transform(data[['Latitude']])"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1731508905073
        }
      },
      "id": "a31d3de1-0e75-4202-b10f-afcfec093f49"
    },
    {
      "cell_type": "code",
      "source": [
        "# Training set: Entire year of 2023 and up to May 2024\n",
        "training_set = data.loc['2023':'2024-05']\n",
        "\n",
        "# Testing set: Remaining months in 2024, starting from June 2024\n",
        "testing_set = data.loc['2024-06':]\n"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1731508905228
        }
      },
      "id": "c435bd6b-edad-4602-8ab6-952796e778cd"
    },
    {
      "cell_type": "code",
      "source": [
        "training_set.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "                     Latitude\nReceived_Timestamp           \n2023-01-01 00:00:00  0.545963\n2023-01-01 06:00:00  0.543781\n2023-01-01 12:00:00  0.540342\n2023-01-01 18:00:00  0.537833\n2023-01-02 00:00:00  0.534716",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Latitude</th>\n    </tr>\n    <tr>\n      <th>Received_Timestamp</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2023-01-01 00:00:00</th>\n      <td>0.545963</td>\n    </tr>\n    <tr>\n      <th>2023-01-01 06:00:00</th>\n      <td>0.543781</td>\n    </tr>\n    <tr>\n      <th>2023-01-01 12:00:00</th>\n      <td>0.540342</td>\n    </tr>\n    <tr>\n      <th>2023-01-01 18:00:00</th>\n      <td>0.537833</td>\n    </tr>\n    <tr>\n      <th>2023-01-02 00:00:00</th>\n      <td>0.534716</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1731508905402
        }
      },
      "id": "b6d7c039-2321-4ef2-b487-44760a8ecf11"
    },
    {
      "cell_type": "code",
      "source": [
        "testing_set.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "                     Latitude\nReceived_Timestamp           \n2024-06-01 00:00:00  0.562647\n2024-06-01 06:00:00  0.564772\n2024-06-01 12:00:00  0.569488\n2024-06-01 18:00:00  0.575726\n2024-06-02 00:00:00  0.581195",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Latitude</th>\n    </tr>\n    <tr>\n      <th>Received_Timestamp</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2024-06-01 00:00:00</th>\n      <td>0.562647</td>\n    </tr>\n    <tr>\n      <th>2024-06-01 06:00:00</th>\n      <td>0.564772</td>\n    </tr>\n    <tr>\n      <th>2024-06-01 12:00:00</th>\n      <td>0.569488</td>\n    </tr>\n    <tr>\n      <th>2024-06-01 18:00:00</th>\n      <td>0.575726</td>\n    </tr>\n    <tr>\n      <th>2024-06-02 00:00:00</th>\n      <td>0.581195</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1731508905585
        }
      },
      "id": "a6725ebf-dc94-4b4c-aa94-a506d03bd02a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Sliding window approach"
      ],
      "metadata": {},
      "id": "11534071-f383-4583-a99d-1421b3a5b218"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input window size (20 data points)\n",
        "input_window_size = 28\n",
        "# Define the output window size (1 data point)\n",
        "output_window_size = 1\n",
        "# Define the stride, which determines how much to move forward for each new window (1 data point)\n",
        "stride = 1"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1731508905746
        }
      },
      "id": "76efb32f-016a-4de6-9ffd-31dd00dbbd30"
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply sliding window to create sequences\n",
        "# Initialize empty lists to store the input (X) and output (y) sequences\n",
        "X, y = [], []\n",
        "\n",
        "# Loop through the dataset to create windows of input and output sequences\n",
        "for i in range(0, len(training_set) - input_window_size - output_window_size + 1, stride):\n",
        "    # Define the input window, which is a slice of 20 data points\n",
        "    input_window = training_set.iloc[i:i+input_window_size][['Latitude']]\n",
        "    # Define the output window, which is a slice of 1 data point immediately following the input window\n",
        "    output_window = training_set.iloc[i+input_window_size:i+input_window_size+output_window_size][['Latitude']]\n",
        "    # Append the input window data to X and the last value of output window to y\n",
        "    X.append(input_window.values)\n",
        "    y.append(output_window.values[-1])"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1731508905995
        }
      },
      "id": "8f32ba08-62a7-4e23-a81d-d59f6e14722c"
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert X and y lists to numpy arrays for model input\n",
        "X, y = np.array(X), np.array(y)\n",
        "\n",
        "# Print the number of samples created\n",
        "print(f\"Number of samples: {X.shape[0]}\")\n",
        "# Print the shape of the input (X) and output (y) arrays\n",
        "print(f\"Input shape: {X.shape}, Target shape: {y.shape}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Number of samples: 2040\nInput shape: (2040, 28, 1), Target shape: (2040, 1)\n"
        }
      ],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1731508906174
        }
      },
      "id": "8b093cc8-84c1-45a9-a73f-19c77653909b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Define LSTM model architecture"
      ],
      "metadata": {},
      "id": "b8cfcfe8-106f-4e8b-bdf5-e7f7dc1cfe0c"
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary modules\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Define a function to create an LSTM model with specified hyperparameters\n",
        "def build_model(units=50, lstm_layers=2, dropout_rate=0.2, recurrent_dropout=0.2, activation='tanh', learning_rate=0.001):\n",
        "    \"\"\"\n",
        "    Builds an LSTM model with the given parameters.\n",
        "\n",
        "    Parameters:\n",
        "        units (int): Number of units in each LSTM layer.\n",
        "        lstm_layers (int): Number of stacked LSTM layers.\n",
        "        dropout_rate (float): Dropout rate for regularization.\n",
        "        recurrent_dropout (float): Dropout rate for the recurrent connections.\n",
        "        activation (str): Activation function for LSTM layers.\n",
        "        learning_rate (float): Learning rate for the optimizer.\n",
        "\n",
        "    Returns:\n",
        "        model (Sequential): Compiled Keras model ready for training.\n",
        "    \"\"\"\n",
        "    # Initialize a Sequential model\n",
        "    model = Sequential()\n",
        "    \n",
        "    # Add LSTM layers\n",
        "    for i in range(lstm_layers - 1):\n",
        "        # Add intermediate LSTM layers with return_sequences=True for stacking\n",
        "        model.add(LSTM(units=units, activation=activation, return_sequences=True, dropout=dropout_rate, recurrent_dropout=recurrent_dropout))\n",
        "    \n",
        "    # Add the final LSTM layer without return_sequences, as this is a many-to-one model\n",
        "    model.add(LSTM(units=units, activation=activation, dropout=dropout_rate, recurrent_dropout=recurrent_dropout))\n",
        "    \n",
        "    # Add a Dense layer with 1 unit for output (for regression)\n",
        "    model.add(Dense(1))\n",
        "    \n",
        "    # Initialize the Adam optimizer with the specified learning rate\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    \n",
        "    # Compile the model using mean squared error (MSE) as the loss function, which is suitable for regression\n",
        "    model.compile(optimizer=optimizer, loss='mse')\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Initialize variables to keep track of the best model and lowest validation loss\n",
        "best_model = None\n",
        "best_loss = float('inf')  # Start with a high initial loss for comparison\n",
        "\n",
        "# Define hyperparameter grids for tuning\n",
        "units_list = [50, 100, 150]       # Different numbers of units to try in LSTM layers\n",
        "layers_list = [1, 2, 3]           # Different numbers of LSTM layers to try\n",
        "dropout_list = [0.2, 0.3, 0.5]    # Different dropout rates to test for regularization\n",
        "learning_rates = [0.0001, 0.001, 0.005]  # Different learning rates for the optimizer\n",
        "batch_sizes = [16, 32, 48]        # Different batch sizes for training\n",
        "\n",
        "# Perform grid search across all combinations of hyperparameters\n",
        "for units in units_list:\n",
        "    for layers in layers_list:\n",
        "        for dropout in dropout_list:\n",
        "            for lr in learning_rates:\n",
        "                for batch_size in batch_sizes:\n",
        "                    # Print the current combination of hyperparameters being tested\n",
        "                    print(f\"Training model with units={units}, layers={layers}, dropout={dropout}, lr={lr}, batch_size={batch_size}\")\n",
        "                    \n",
        "                    # Build a model with the current set of hyperparameters\n",
        "                    model = build_model(units=units, lstm_layers=layers, dropout_rate=dropout, learning_rate=lr)\n",
        "                    \n",
        "                    # Define early stopping to stop training if validation loss doesn't improve for a number of epochs\n",
        "                    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "                    \n",
        "                    # Define learning rate scheduler to reduce learning rate if validation loss plateaus\n",
        "                    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
        "                    \n",
        "                    # Train the model on the data with a validation split of 30%\n",
        "                    # Early stopping and learning rate scheduler will be used as callbacks\n",
        "                    history = model.fit(X, y, \n",
        "                                        epochs=100, \n",
        "                                        batch_size=batch_size, \n",
        "                                        validation_split=0.3, \n",
        "                                        callbacks=[early_stopping, lr_scheduler], \n",
        "                                        verbose=1)\n",
        "                    \n",
        "                    # Retrieve the minimum validation loss achieved during training\n",
        "                    val_loss = min(history.history['val_loss'])\n",
        "                    \n",
        "                    # Check if the current model has achieved a lower validation loss than the best so far\n",
        "                    if val_loss < best_loss:\n",
        "                        # Update the best model and best loss\n",
        "                        best_loss = val_loss\n",
        "                        best_model = model\n",
        "                        best_params = (units, layers, dropout, lr, batch_size)\n",
        "                        best_history = history\n",
        "\n",
        "# At the end of the search, 'best_model' contains the model with the lowest validation loss\n",
        "# 'best_params' holds the parameters that yielded the best model, and 'best_history' contains the training history\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Training model with units=50, layers=1, dropout=0.2, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.3529 - val_loss: 0.1049 - learning_rate: 1.0000e-04\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0646 - val_loss: 0.0237 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0400 - val_loss: 0.0188 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0287 - val_loss: 0.0219 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0231 - val_loss: 0.0246 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0166 - val_loss: 0.0292 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0109 - val_loss: 0.0319 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0086 - val_loss: 0.0347 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0083 - val_loss: 0.0377 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0071 - val_loss: 0.0390 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0068 - val_loss: 0.0402 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0061 - val_loss: 0.0413 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0056 - val_loss: 0.0419 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.2, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.2882 - val_loss: 0.1598 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1175 - val_loss: 0.0341 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0509 - val_loss: 0.0172 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0428 - val_loss: 0.0169 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0373 - val_loss: 0.0167 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0339 - val_loss: 0.0192 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0269 - val_loss: 0.0199 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0233 - val_loss: 0.0224 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0184 - val_loss: 0.0238 - learning_rate: 5.0000e-05\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0168 - val_loss: 0.0259 - learning_rate: 5.0000e-05\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0147 - val_loss: 0.0281 - learning_rate: 5.0000e-05\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0122 - val_loss: 0.0293 - learning_rate: 2.5000e-05\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0112 - val_loss: 0.0304 - learning_rate: 2.5000e-05\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0109 - val_loss: 0.0316 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0111 - val_loss: 0.0322 - learning_rate: 1.2500e-05\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.2, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.3770 - val_loss: 0.3163 - learning_rate: 1.0000e-04\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2696 - val_loss: 0.2109 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1691 - val_loss: 0.0992 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0760 - val_loss: 0.0212 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0428 - val_loss: 0.0183 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0383 - val_loss: 0.0179 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0356 - val_loss: 0.0179 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0315 - val_loss: 0.0177 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0291 - val_loss: 0.0182 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0264 - val_loss: 0.0188 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0233 - val_loss: 0.0194 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0200 - val_loss: 0.0203 - learning_rate: 5.0000e-05\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0215 - val_loss: 0.0210 - learning_rate: 5.0000e-05\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0186 - val_loss: 0.0222 - learning_rate: 5.0000e-05\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0182 - val_loss: 0.0225 - learning_rate: 2.5000e-05\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0177 - val_loss: 0.0226 - learning_rate: 2.5000e-05\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0186 - val_loss: 0.0230 - learning_rate: 2.5000e-05\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0164 - val_loss: 0.0232 - learning_rate: 1.2500e-05\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.2, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0895 - val_loss: 0.0402 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0032 - val_loss: 0.0477 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0019 - val_loss: 0.0462 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0015 - val_loss: 0.0458 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0462 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0013 - val_loss: 0.0465 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0460 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0461 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0462 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 0.0467 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.7697e-04 - val_loss: 0.0460 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.2, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.1547 - val_loss: 0.0172 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0175 - val_loss: 0.0289 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0051 - val_loss: 0.0451 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0021 - val_loss: 0.0451 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0017 - val_loss: 0.0460 - learning_rate: 5.0000e-04\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0016 - val_loss: 0.0457 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - val_loss: 0.0462 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0014 - val_loss: 0.0467 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - val_loss: 0.0464 - learning_rate: 2.5000e-04\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - val_loss: 0.0462 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - val_loss: 0.0461 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.2, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0906 - val_loss: 0.0160 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0240 - val_loss: 0.0258 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0065 - val_loss: 0.0473 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0026 - val_loss: 0.0447 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0020 - val_loss: 0.0450 - learning_rate: 5.0000e-04\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0017 - val_loss: 0.0453 - learning_rate: 5.0000e-04\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0016 - val_loss: 0.0445 - learning_rate: 5.0000e-04\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - val_loss: 0.0447 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - val_loss: 0.0449 - learning_rate: 2.5000e-04\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014 - val_loss: 0.0449 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014 - val_loss: 0.0450 - learning_rate: 1.2500e-04\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.2, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0431 - val_loss: 0.0481 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0013 - val_loss: 0.0505 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 0.0441 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0460 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0419 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0013 - val_loss: 0.0436 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 9.7112e-04 - val_loss: 0.0390 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 9.1070e-04 - val_loss: 0.0372 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 0.0362 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 8.9661e-04 - val_loss: 0.0320 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 8.5322e-04 - val_loss: 0.0306 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 8.0580e-04 - val_loss: 0.0294 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.1647e-04 - val_loss: 0.0257 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 6.0591e-04 - val_loss: 0.0283 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 4.7128e-04 - val_loss: 0.0248 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.9600e-04 - val_loss: 0.0277 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 4.0373e-04 - val_loss: 0.0230 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 4.5377e-04 - val_loss: 0.0229 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.3613e-04 - val_loss: 0.0242 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 4.4407e-04 - val_loss: 0.0252 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.3137e-04 - val_loss: 0.0232 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.1104e-04 - val_loss: 0.0260 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.6395e-04 - val_loss: 0.0264 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.0323e-04 - val_loss: 0.0247 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 25/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.9342e-04 - val_loss: 0.0261 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 26/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.2703e-04 - val_loss: 0.0255 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 27/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.8138e-04 - val_loss: 0.0256 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 28/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2.4523e-04 - val_loss: 0.0256 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.2, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.1091 - val_loss: 0.0410 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0020 - val_loss: 0.0484 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - val_loss: 0.0486 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - val_loss: 0.0491 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0011 - val_loss: 0.0486 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014 - val_loss: 0.0492 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - val_loss: 0.0479 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - val_loss: 0.0488 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - val_loss: 0.0481 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 0.0487 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0010 - val_loss: 0.0485 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.2, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.1110 - val_loss: 0.0302 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0040 - val_loss: 0.0453 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0014 - val_loss: 0.0468 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0013 - val_loss: 0.0469 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0475 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0010 - val_loss: 0.0465 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0471 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012 - val_loss: 0.0471 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0011 - val_loss: 0.0466 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0472 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012 - val_loss: 0.0473 - learning_rate: 6.2500e-04\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.3, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.2461 - val_loss: 0.0445 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0591 - val_loss: 0.0243 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0425 - val_loss: 0.0228 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0237 - val_loss: 0.0322 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0102 - val_loss: 0.0427 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0063 - val_loss: 0.0462 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0050 - val_loss: 0.0457 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0049 - val_loss: 0.0454 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0045 - val_loss: 0.0461 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0036 - val_loss: 0.0459 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0042 - val_loss: 0.0463 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0037 - val_loss: 0.0464 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0036 - val_loss: 0.0463 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.3, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.1744 - val_loss: 0.0816 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0889 - val_loss: 0.0249 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0632 - val_loss: 0.0244 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0554 - val_loss: 0.0210 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0456 - val_loss: 0.0200 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0278 - val_loss: 0.0264 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0145 - val_loss: 0.0370 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0084 - val_loss: 0.0383 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0066 - val_loss: 0.0388 - learning_rate: 5.0000e-05\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0057 - val_loss: 0.0388 - learning_rate: 5.0000e-05\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0061 - val_loss: 0.0394 - learning_rate: 5.0000e-05\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0057 - val_loss: 0.0395 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0056 - val_loss: 0.0394 - learning_rate: 2.5000e-05\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0054 - val_loss: 0.0392 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0054 - val_loss: 0.0394 - learning_rate: 1.2500e-05\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.3, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.2858 - val_loss: 0.2144 - learning_rate: 1.0000e-04\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1703 - val_loss: 0.1019 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0966 - val_loss: 0.0309 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0627 - val_loss: 0.0264 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0560 - val_loss: 0.0242 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0569 - val_loss: 0.0218 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0444 - val_loss: 0.0223 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0338 - val_loss: 0.0228 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0289 - val_loss: 0.0248 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0242 - val_loss: 0.0264 - learning_rate: 5.0000e-05\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0202 - val_loss: 0.0283 - learning_rate: 5.0000e-05\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0174 - val_loss: 0.0301 - learning_rate: 5.0000e-05\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0152 - val_loss: 0.0310 - learning_rate: 2.5000e-05\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0136 - val_loss: 0.0322 - learning_rate: 2.5000e-05\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0128 - val_loss: 0.0334 - learning_rate: 2.5000e-05\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0121 - val_loss: 0.0340 - learning_rate: 1.2500e-05\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.3, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0835 - val_loss: 0.0461 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0027 - val_loss: 0.0454 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0018 - val_loss: 0.0460 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0016 - val_loss: 0.0472 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0013 - val_loss: 0.0465 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0469 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 0.0470 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0013 - val_loss: 0.0474 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 0.0466 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0474 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0474 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0471 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.3, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.1549 - val_loss: 0.0234 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0111 - val_loss: 0.0447 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0029 - val_loss: 0.0468 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0021 - val_loss: 0.0474 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0017 - val_loss: 0.0472 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0016 - val_loss: 0.0479 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - val_loss: 0.0482 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - val_loss: 0.0476 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0014 - val_loss: 0.0476 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - val_loss: 0.0478 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0014 - val_loss: 0.0476 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.3, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.1707 - val_loss: 0.0319 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0327 - val_loss: 0.0310 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0067 - val_loss: 0.0494 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0025 - val_loss: 0.0463 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0020 - val_loss: 0.0473 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0018 - val_loss: 0.0480 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0016 - val_loss: 0.0476 - learning_rate: 5.0000e-04\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0015 - val_loss: 0.0477 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0015 - val_loss: 0.0475 - learning_rate: 2.5000e-04\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0016 - val_loss: 0.0474 - learning_rate: 2.5000e-04\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0015 - val_loss: 0.0476 - learning_rate: 2.5000e-04\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0014 - val_loss: 0.0475 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.3, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0358 - val_loss: 0.0480 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0494 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - val_loss: 0.0481 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - val_loss: 0.0479 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0459 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0014 - val_loss: 0.0446 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 0.0458 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 9.9786e-04 - val_loss: 0.0402 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 9.3942e-04 - val_loss: 0.0385 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 9.0134e-04 - val_loss: 0.0392 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 7.8788e-04 - val_loss: 0.0364 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 7.9546e-04 - val_loss: 0.0347 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 7.4167e-04 - val_loss: 0.0380 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 6.9806e-04 - val_loss: 0.0346 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 6.3507e-04 - val_loss: 0.0385 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.5168e-04 - val_loss: 0.0346 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.5268e-04 - val_loss: 0.0373 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 4.5705e-04 - val_loss: 0.0372 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.7738e-04 - val_loss: 0.0350 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 4.2612e-04 - val_loss: 0.0362 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 5.5506e-04 - val_loss: 0.0359 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 4.0818e-04 - val_loss: 0.0360 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 4.2407e-04 - val_loss: 0.0359 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3.5718e-04 - val_loss: 0.0372 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.3, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0747 - val_loss: 0.0470 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - val_loss: 0.0485 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - val_loss: 0.0483 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0010 - val_loss: 0.0503 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 0.0490 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 0.0484 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0010 - val_loss: 0.0488 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.6469e-04 - val_loss: 0.0479 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0010 - val_loss: 0.0482 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.9915e-04 - val_loss: 0.0477 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 0.0478 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.3, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.1180 - val_loss: 0.0443 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0022 - val_loss: 0.0470 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - val_loss: 0.0487 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0011 - val_loss: 0.0482 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0010 - val_loss: 0.0492 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012 - val_loss: 0.0494 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0486 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0488 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012 - val_loss: 0.0490 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0010 - val_loss: 0.0487 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0490 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.5, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.2771 - val_loss: 0.1040 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1092 - val_loss: 0.0420 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0623 - val_loss: 0.0325 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0169 - val_loss: 0.0458 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0086 - val_loss: 0.0464 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0066 - val_loss: 0.0470 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0064 - val_loss: 0.0476 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0053 - val_loss: 0.0472 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0054 - val_loss: 0.0482 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0048 - val_loss: 0.0480 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0047 - val_loss: 0.0479 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0043 - val_loss: 0.0477 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0045 - val_loss: 0.0478 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.5, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.1778 - val_loss: 0.0695 - learning_rate: 1.0000e-04\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1203 - val_loss: 0.0525 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1004 - val_loss: 0.0396 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0672 - val_loss: 0.0307 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0260 - val_loss: 0.0461 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0112 - val_loss: 0.0464 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0089 - val_loss: 0.0473 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0076 - val_loss: 0.0473 - learning_rate: 5.0000e-05\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0074 - val_loss: 0.0471 - learning_rate: 5.0000e-05\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0072 - val_loss: 0.0474 - learning_rate: 5.0000e-05\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0060 - val_loss: 0.0475 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0060 - val_loss: 0.0475 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0062 - val_loss: 0.0474 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0055 - val_loss: 0.0475 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.5, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.2087 - val_loss: 0.1338 - learning_rate: 1.0000e-04\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1497 - val_loss: 0.0735 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1151 - val_loss: 0.0522 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1060 - val_loss: 0.0462 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0857 - val_loss: 0.0380 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0693 - val_loss: 0.0329 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0387 - val_loss: 0.0367 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0193 - val_loss: 0.0445 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0155 - val_loss: 0.0441 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0116 - val_loss: 0.0443 - learning_rate: 5.0000e-05\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0106 - val_loss: 0.0441 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0104 - val_loss: 0.0449 - learning_rate: 5.0000e-05\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0100 - val_loss: 0.0446 - learning_rate: 2.5000e-05\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0107 - val_loss: 0.0446 - learning_rate: 2.5000e-05\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0098 - val_loss: 0.0447 - learning_rate: 2.5000e-05\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0091 - val_loss: 0.0446 - learning_rate: 1.2500e-05\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.5, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0921 - val_loss: 0.0517 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0024 - val_loss: 0.0496 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0016 - val_loss: 0.0488 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0014 - val_loss: 0.0506 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0502 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0481 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0014 - val_loss: 0.0498 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0496 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0012 - val_loss: 0.0494 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 0.0497 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0010 - val_loss: 0.0491 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 0.0499 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 0.0497 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 9.5968e-04 - val_loss: 0.0501 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 0.0492 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.9710e-04 - val_loss: 0.0492 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.5, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.1415 - val_loss: 0.0533 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0060 - val_loss: 0.0495 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0024 - val_loss: 0.0485 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0022 - val_loss: 0.0496 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0018 - val_loss: 0.0496 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - val_loss: 0.0495 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0017 - val_loss: 0.0506 - learning_rate: 5.0000e-04\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0015 - val_loss: 0.0499 - learning_rate: 5.0000e-04\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0013 - val_loss: 0.0499 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - val_loss: 0.0501 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - val_loss: 0.0495 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - val_loss: 0.0494 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0499 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.5, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.1444 - val_loss: 0.0322 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0129 - val_loss: 0.0457 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0032 - val_loss: 0.0495 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0025 - val_loss: 0.0501 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0022 - val_loss: 0.0496 - learning_rate: 5.0000e-04\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0020 - val_loss: 0.0493 - learning_rate: 5.0000e-04\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0017 - val_loss: 0.0495 - learning_rate: 5.0000e-04\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0017 - val_loss: 0.0497 - learning_rate: 2.5000e-04\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0018 - val_loss: 0.0496 - learning_rate: 2.5000e-04\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0015 - val_loss: 0.0497 - learning_rate: 2.5000e-04\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0016 - val_loss: 0.0498 - learning_rate: 1.2500e-04\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.5, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0365 - val_loss: 0.0511 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0510 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0484 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 0.0497 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0014 - val_loss: 0.0484 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0494 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 0.0502 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 9.5805e-04 - val_loss: 0.0489 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 0.0503 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 8.4644e-04 - val_loss: 0.0498 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 9.5414e-04 - val_loss: 0.0512 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 9.2605e-04 - val_loss: 0.0505 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 7.1004e-04 - val_loss: 0.0518 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.5, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0923 - val_loss: 0.0485 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - val_loss: 0.0499 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012 - val_loss: 0.0506 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0507 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0010 - val_loss: 0.0507 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0011 - val_loss: 0.0496 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 0.0503 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0011 - val_loss: 0.0502 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012 - val_loss: 0.0502 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0010 - val_loss: 0.0499 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.7953e-04 - val_loss: 0.0502 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.5, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.1228 - val_loss: 0.0554 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0021 - val_loss: 0.0505 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0507 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0506 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0511 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0011 - val_loss: 0.0505 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0013 - val_loss: 0.0509 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0010 - val_loss: 0.0509 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0508 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0011 - val_loss: 0.0506 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0509 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0504 - learning_rate: 6.2500e-04\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0506 - learning_rate: 6.2500e-04\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0504 - learning_rate: 6.2500e-04\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0506 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0011 - val_loss: 0.0506 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0504 - learning_rate: 3.1250e-04\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0504 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9.9697e-04 - val_loss: 0.0505 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0504 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0011 - val_loss: 0.0503 - learning_rate: 1.5625e-04\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0011 - val_loss: 0.0504 - learning_rate: 7.8125e-05\b\b\b\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0504 - learning_rate: 7.8125e-05\b\b\b\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012 - val_loss: 0.0503 - learning_rate: 7.8125e-05\b\b\b\b\b\b\nEpoch 25/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0504 - learning_rate: 3.9062e-05\b\b\b\b\b\b\b\b\b\b\nEpoch 26/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 9.4911e-04 - val_loss: 0.0504 - learning_rate: 3.9062e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 27/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0010 - val_loss: 0.0505 - learning_rate: 3.9062e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 28/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0010 - val_loss: 0.0505 - learning_rate: 1.9531e-05\b\b\b\b\b\b\b\b\b\b\nEpoch 29/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0011 - val_loss: 0.0505 - learning_rate: 1.9531e-05\b\b\b\b\b\b\b\b\b\b\nEpoch 30/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0010 - val_loss: 0.0505 - learning_rate: 1.9531e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 31/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0505 - learning_rate: 9.7656e-06\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.2, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.2395 - val_loss: 0.0118 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0342 - val_loss: 0.0181 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0231 - val_loss: 0.0253 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0133 - val_loss: 0.0349 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0079 - val_loss: 0.0396 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0068 - val_loss: 0.0430 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0056 - val_loss: 0.0453 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0055 - val_loss: 0.0461 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0046 - val_loss: 0.0467 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0046 - val_loss: 0.0470 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0047 - val_loss: 0.0469 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.2, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 0.2727 - val_loss: 0.1264 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0811 - val_loss: 0.0117 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0392 - val_loss: 0.0152 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0320 - val_loss: 0.0185 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0220 - val_loss: 0.0210 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0187 - val_loss: 0.0232 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0147 - val_loss: 0.0268 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0125 - val_loss: 0.0302 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0093 - val_loss: 0.0319 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0084 - val_loss: 0.0340 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0078 - val_loss: 0.0355 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0069 - val_loss: 0.0362 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.2, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - loss: 0.1747 - val_loss: 0.0532 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0664 - val_loss: 0.0100 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0497 - val_loss: 0.0153 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0359 - val_loss: 0.0135 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0373 - val_loss: 0.0165 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0303 - val_loss: 0.0156 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0258 - val_loss: 0.0173 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0224 - val_loss: 0.0184 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0226 - val_loss: 0.0190 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0202 - val_loss: 0.0203 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0208 - val_loss: 0.0211 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0173 - val_loss: 0.0221 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.2, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.0664 - val_loss: 0.0491 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0025 - val_loss: 0.0483 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0020 - val_loss: 0.0482 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0016 - val_loss: 0.0491 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0014 - val_loss: 0.0489 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0012 - val_loss: 0.0481 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0013 - val_loss: 0.0486 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0012 - val_loss: 0.0495 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0012 - val_loss: 0.0487 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0012 - val_loss: 0.0487 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0011 - val_loss: 0.0484 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0011 - val_loss: 0.0485 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0012 - val_loss: 0.0482 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0013 - val_loss: 0.0483 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0012 - val_loss: 0.0486 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0011 - val_loss: 0.0484 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.2, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 0.0993 - val_loss: 0.0274 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0081 - val_loss: 0.0493 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0027 - val_loss: 0.0470 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0022 - val_loss: 0.0484 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0018 - val_loss: 0.0486 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0017 - val_loss: 0.0480 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0017 - val_loss: 0.0490 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0016 - val_loss: 0.0487 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0017 - val_loss: 0.0484 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0014 - val_loss: 0.0483 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0015 - val_loss: 0.0482 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.2, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.1379 - val_loss: 0.0173 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0152 - val_loss: 0.0346 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0048 - val_loss: 0.0496 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0026 - val_loss: 0.0481 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0020 - val_loss: 0.0479 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0020 - val_loss: 0.0484 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0018 - val_loss: 0.0487 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0018 - val_loss: 0.0486 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0017 - val_loss: 0.0488 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0019 - val_loss: 0.0486 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0016 - val_loss: 0.0487 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.2, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0401 - val_loss: 0.0494 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0015 - val_loss: 0.0501 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0014 - val_loss: 0.0505 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0011 - val_loss: 0.0499 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0012 - val_loss: 0.0499 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0010 - val_loss: 0.0506 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0013 - val_loss: 0.0500 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0012 - val_loss: 0.0503 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0011 - val_loss: 0.0502 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0012 - val_loss: 0.0501 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0011 - val_loss: 0.0499 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.2, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0618 - val_loss: 0.0498 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0017 - val_loss: 0.0498 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0013 - val_loss: 0.0496 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0012 - val_loss: 0.0501 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0012 - val_loss: 0.0490 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0014 - val_loss: 0.0496 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0011 - val_loss: 0.0494 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0014 - val_loss: 0.0506 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0011 - val_loss: 0.0501 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0010 - val_loss: 0.0496 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0012 - val_loss: 0.0495 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0011 - val_loss: 0.0495 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0012 - val_loss: 0.0492 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0011 - val_loss: 0.0495 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0011 - val_loss: 0.0501 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.2, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0788 - val_loss: 0.0444 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0019 - val_loss: 0.0494 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0014 - val_loss: 0.0487 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0012 - val_loss: 0.0489 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0012 - val_loss: 0.0497 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0011 - val_loss: 0.0500 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0011 - val_loss: 0.0494 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0012 - val_loss: 0.0502 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0012 - val_loss: 0.0503 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0011 - val_loss: 0.0494 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0011 - val_loss: 0.0497 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.3, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 0.1617 - val_loss: 0.0214 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0547 - val_loss: 0.0228 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0247 - val_loss: 0.0402 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0073 - val_loss: 0.0470 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0055 - val_loss: 0.0475 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0053 - val_loss: 0.0476 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0047 - val_loss: 0.0480 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0042 - val_loss: 0.0483 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0043 - val_loss: 0.0482 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0037 - val_loss: 0.0484 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0040 - val_loss: 0.0481 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.3, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 0.2555 - val_loss: 0.0650 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0716 - val_loss: 0.0229 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0553 - val_loss: 0.0226 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0371 - val_loss: 0.0261 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0213 - val_loss: 0.0339 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0123 - val_loss: 0.0417 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0092 - val_loss: 0.0443 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0073 - val_loss: 0.0459 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0070 - val_loss: 0.0467 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0064 - val_loss: 0.0471 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0063 - val_loss: 0.0474 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0058 - val_loss: 0.0475 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0059 - val_loss: 0.0478 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.3, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.3759 - val_loss: 0.2386 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1832 - val_loss: 0.0694 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0740 - val_loss: 0.0185 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0553 - val_loss: 0.0230 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0464 - val_loss: 0.0236 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0395 - val_loss: 0.0229 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0306 - val_loss: 0.0247 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0248 - val_loss: 0.0262 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0208 - val_loss: 0.0283 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0191 - val_loss: 0.0295 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0169 - val_loss: 0.0307 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0164 - val_loss: 0.0316 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0159 - val_loss: 0.0322 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.3, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.0682 - val_loss: 0.0511 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0026 - val_loss: 0.0502 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0018 - val_loss: 0.0517 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0014 - val_loss: 0.0505 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0015 - val_loss: 0.0507 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0013 - val_loss: 0.0512 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0014 - val_loss: 0.0510 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0010 - val_loss: 0.0509 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0012 - val_loss: 0.0499 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0011 - val_loss: 0.0505 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0011 - val_loss: 0.0503 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0012 - val_loss: 0.0509 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0011 - val_loss: 0.0509 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0011 - val_loss: 0.0506 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0012 - val_loss: 0.0508 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0012 - val_loss: 0.0505 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0011 - val_loss: 0.0502 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0012 - val_loss: 0.0507 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0011 - val_loss: 0.0502 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.3, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 0.0987 - val_loss: 0.0374 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0043 - val_loss: 0.0509 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0028 - val_loss: 0.0492 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0020 - val_loss: 0.0504 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0016 - val_loss: 0.0503 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0015 - val_loss: 0.0501 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0015 - val_loss: 0.0505 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0016 - val_loss: 0.0508 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0014 - val_loss: 0.0504 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0012 - val_loss: 0.0510 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0013 - val_loss: 0.0507 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.3, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - loss: 0.1248 - val_loss: 0.0277 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0123 - val_loss: 0.0519 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0035 - val_loss: 0.0484 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0028 - val_loss: 0.0489 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0024 - val_loss: 0.0497 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0023 - val_loss: 0.0501 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0020 - val_loss: 0.0497 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0019 - val_loss: 0.0501 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0018 - val_loss: 0.0505 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0016 - val_loss: 0.0498 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0016 - val_loss: 0.0498 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.3, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.0293 - val_loss: 0.0503 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0015 - val_loss: 0.0502 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0012 - val_loss: 0.0497 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0014 - val_loss: 0.0491 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0012 - val_loss: 0.0495 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0012 - val_loss: 0.0497 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0013 - val_loss: 0.0483 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0013 - val_loss: 0.0494 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0011 - val_loss: 0.0494 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0014 - val_loss: 0.0482 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0011 - val_loss: 0.0490 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0011 - val_loss: 0.0444 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0011 - val_loss: 0.0480 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0010 - val_loss: 0.0453 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0011 - val_loss: 0.0470 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 8.9403e-04 - val_loss: 0.0429 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 7.6087e-04 - val_loss: 0.0413 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 6.9841e-04 - val_loss: 0.0408 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 9.1032e-04 - val_loss: 0.0399 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 7.0814e-04 - val_loss: 0.0400 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 9.2665e-04 - val_loss: 0.0419 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 7.6649e-04 - val_loss: 0.0386 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 6.8725e-04 - val_loss: 0.0411 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 7.0960e-04 - val_loss: 0.0379 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 25/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 6.8549e-04 - val_loss: 0.0376 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 26/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 6.8217e-04 - val_loss: 0.0401 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 27/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 7.1437e-04 - val_loss: 0.0385 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 28/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 6.1467e-04 - val_loss: 0.0399 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 29/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 5.9559e-04 - val_loss: 0.0394 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 30/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 4.3458e-04 - val_loss: 0.0383 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 31/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 6.5267e-04 - val_loss: 0.0399 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 32/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 5.1122e-04 - val_loss: 0.0381 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 33/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 4.9661e-04 - val_loss: 0.0396 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 34/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 4.9370e-04 - val_loss: 0.0380 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 35/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 5.2683e-04 - val_loss: 0.0377 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.3, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 0.0699 - val_loss: 0.0520 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0017 - val_loss: 0.0504 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0016 - val_loss: 0.0502 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0012 - val_loss: 0.0505 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0013 - val_loss: 0.0498 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0013 - val_loss: 0.0504 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0012 - val_loss: 0.0511 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0012 - val_loss: 0.0504 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0011 - val_loss: 0.0505 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0012 - val_loss: 0.0508 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0011 - val_loss: 0.0505 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 9.9857e-04 - val_loss: 0.0507 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0010 - val_loss: 0.0498 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0012 - val_loss: 0.0505 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0011 - val_loss: 0.0501 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.3, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.0570 - val_loss: 0.0469 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0017 - val_loss: 0.0519 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0013 - val_loss: 0.0503 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0012 - val_loss: 0.0514 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0012 - val_loss: 0.0497 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0010 - val_loss: 0.0507 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0012 - val_loss: 0.0502 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0012 - val_loss: 0.0504 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0013 - val_loss: 0.0502 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0011 - val_loss: 0.0500 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0011 - val_loss: 0.0501 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.5, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 0.1973 - val_loss: 0.0443 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0715 - val_loss: 0.0360 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0186 - val_loss: 0.0466 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0098 - val_loss: 0.0491 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0075 - val_loss: 0.0497 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0066 - val_loss: 0.0498 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0054 - val_loss: 0.0506 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0052 - val_loss: 0.0510 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0049 - val_loss: 0.0504 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0042 - val_loss: 0.0510 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0046 - val_loss: 0.0506 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0040 - val_loss: 0.0506 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.5, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 0.2478 - val_loss: 0.0787 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.1228 - val_loss: 0.0362 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0834 - val_loss: 0.0269 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0458 - val_loss: 0.0336 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0194 - val_loss: 0.0458 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0109 - val_loss: 0.0483 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0096 - val_loss: 0.0489 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0092 - val_loss: 0.0488 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0079 - val_loss: 0.0494 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0073 - val_loss: 0.0500 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0079 - val_loss: 0.0503 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0074 - val_loss: 0.0503 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0065 - val_loss: 0.0505 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.5, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - loss: 0.3162 - val_loss: 0.2067 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1756 - val_loss: 0.0741 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.1153 - val_loss: 0.0365 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0881 - val_loss: 0.0316 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0669 - val_loss: 0.0277 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0396 - val_loss: 0.0328 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0223 - val_loss: 0.0412 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0121 - val_loss: 0.0467 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0108 - val_loss: 0.0473 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0094 - val_loss: 0.0478 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0096 - val_loss: 0.0475 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0085 - val_loss: 0.0479 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0093 - val_loss: 0.0482 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0086 - val_loss: 0.0480 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0088 - val_loss: 0.0481 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.5, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.1159 - val_loss: 0.0496 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0034 - val_loss: 0.0519 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0023 - val_loss: 0.0515 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0017 - val_loss: 0.0505 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0015 - val_loss: 0.0510 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0014 - val_loss: 0.0514 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0014 - val_loss: 0.0512 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0012 - val_loss: 0.0508 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0013 - val_loss: 0.0508 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0013 - val_loss: 0.0515 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0013 - val_loss: 0.0510 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.5, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 0.1351 - val_loss: 0.0526 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0047 - val_loss: 0.0491 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0029 - val_loss: 0.0501 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0022 - val_loss: 0.0501 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0017 - val_loss: 0.0504 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0017 - val_loss: 0.0504 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0015 - val_loss: 0.0508 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0017 - val_loss: 0.0509 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0015 - val_loss: 0.0509 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0013 - val_loss: 0.0506 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0014 - val_loss: 0.0509 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0012 - val_loss: 0.0508 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.5, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.1595 - val_loss: 0.0429 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0089 - val_loss: 0.0498 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0038 - val_loss: 0.0512 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0032 - val_loss: 0.0525 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0025 - val_loss: 0.0510 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0020 - val_loss: 0.0510 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0019 - val_loss: 0.0510 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0017 - val_loss: 0.0514 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0018 - val_loss: 0.0509 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0016 - val_loss: 0.0515 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0015 - val_loss: 0.0514 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.5, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.0398 - val_loss: 0.0500 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0015 - val_loss: 0.0505 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0015 - val_loss: 0.0502 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0014 - val_loss: 0.0508 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0013 - val_loss: 0.0507 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0011 - val_loss: 0.0519 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0012 - val_loss: 0.0511 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0013 - val_loss: 0.0509 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0011 - val_loss: 0.0510 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0012 - val_loss: 0.0509 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0013 - val_loss: 0.0515 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.5, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 0.0562 - val_loss: 0.0498 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0015 - val_loss: 0.0510 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0012 - val_loss: 0.0522 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0014 - val_loss: 0.0510 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0012 - val_loss: 0.0508 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0011 - val_loss: 0.0510 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0012 - val_loss: 0.0500 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0013 - val_loss: 0.0508 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0011 - val_loss: 0.0507 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0012 - val_loss: 0.0506 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0013 - val_loss: 0.0512 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.5, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - loss: 0.0991 - val_loss: 0.0539 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0023 - val_loss: 0.0511 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0016 - val_loss: 0.0507 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0014 - val_loss: 0.0501 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0015 - val_loss: 0.0509 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0013 - val_loss: 0.0509 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0011 - val_loss: 0.0509 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0012 - val_loss: 0.0504 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0013 - val_loss: 0.0504 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0013 - val_loss: 0.0515 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0012 - val_loss: 0.0510 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0012 - val_loss: 0.0503 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0012 - val_loss: 0.0511 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 9.7284e-04 - val_loss: 0.0506 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.2, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - loss: 0.2237 - val_loss: 0.0160 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0328 - val_loss: 0.0197 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0229 - val_loss: 0.0274 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0110 - val_loss: 0.0365 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0063 - val_loss: 0.0403 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0051 - val_loss: 0.0433 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0046 - val_loss: 0.0457 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0038 - val_loss: 0.0466 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0035 - val_loss: 0.0476 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0037 - val_loss: 0.0483 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0029 - val_loss: 0.0486 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.2, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.2025 - val_loss: 0.0155 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0470 - val_loss: 0.0154 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0352 - val_loss: 0.0190 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0221 - val_loss: 0.0237 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0177 - val_loss: 0.0267 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0127 - val_loss: 0.0304 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0113 - val_loss: 0.0347 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0085 - val_loss: 0.0364 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0081 - val_loss: 0.0381 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0073 - val_loss: 0.0397 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0069 - val_loss: 0.0402 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0067 - val_loss: 0.0409 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.2, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 0.2145 - val_loss: 0.0510 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0587 - val_loss: 0.0147 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0422 - val_loss: 0.0178 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0349 - val_loss: 0.0181 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0286 - val_loss: 0.0211 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0250 - val_loss: 0.0225 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0201 - val_loss: 0.0243 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0168 - val_loss: 0.0268 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0168 - val_loss: 0.0281 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0137 - val_loss: 0.0296 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0124 - val_loss: 0.0311 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0114 - val_loss: 0.0319 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.2, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 0.0555 - val_loss: 0.0494 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0025 - val_loss: 0.0493 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0020 - val_loss: 0.0506 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0017 - val_loss: 0.0497 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0016 - val_loss: 0.0504 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0013 - val_loss: 0.0494 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0013 - val_loss: 0.0503 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0013 - val_loss: 0.0500 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0014 - val_loss: 0.0502 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0012 - val_loss: 0.0510 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0013 - val_loss: 0.0502 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0012 - val_loss: 0.0504 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.2, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0906 - val_loss: 0.0374 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0048 - val_loss: 0.0486 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0025 - val_loss: 0.0496 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0018 - val_loss: 0.0490 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0015 - val_loss: 0.0499 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0014 - val_loss: 0.0498 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0015 - val_loss: 0.0501 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0013 - val_loss: 0.0506 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0013 - val_loss: 0.0500 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0013 - val_loss: 0.0503 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0013 - val_loss: 0.0504 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.2, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 46ms/step - loss: 0.0904 - val_loss: 0.0319 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0083 - val_loss: 0.0478 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0034 - val_loss: 0.0504 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0024 - val_loss: 0.0494 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0019 - val_loss: 0.0496 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0019 - val_loss: 0.0496 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0018 - val_loss: 0.0508 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0016 - val_loss: 0.0507 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0015 - val_loss: 0.0500 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0015 - val_loss: 0.0503 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0014 - val_loss: 0.0500 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.2, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 0.0518 - val_loss: 0.0498 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0015 - val_loss: 0.0495 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0012 - val_loss: 0.0505 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0013 - val_loss: 0.0503 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0013 - val_loss: 0.0498 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0013 - val_loss: 0.0504 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0011 - val_loss: 0.0498 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0011 - val_loss: 0.0499 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0011 - val_loss: 0.0508 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0012 - val_loss: 0.0511 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0012 - val_loss: 0.0500 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0010 - val_loss: 0.0499 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.2, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0714 - val_loss: 0.0471 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0017 - val_loss: 0.0497 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0014 - val_loss: 0.0500 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0015 - val_loss: 0.0508 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0013 - val_loss: 0.0504 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0013 - val_loss: 0.0512 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0015 - val_loss: 0.0503 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0012 - val_loss: 0.0500 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0012 - val_loss: 0.0505 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0011 - val_loss: 0.0501 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0011 - val_loss: 0.0506 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.2, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step - loss: 0.1165 - val_loss: 0.0455 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0030 - val_loss: 0.0478 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0018 - val_loss: 0.0486 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0015 - val_loss: 0.0500 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0015 - val_loss: 0.0501 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0013 - val_loss: 0.0503 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0013 - val_loss: 0.0504 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0013 - val_loss: 0.0505 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0013 - val_loss: 0.0507 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0012 - val_loss: 0.0503 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0014 - val_loss: 0.0502 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.3, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - loss: 0.2294 - val_loss: 0.0240 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0401 - val_loss: 0.0313 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0178 - val_loss: 0.0416 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0085 - val_loss: 0.0467 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0065 - val_loss: 0.0476 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0058 - val_loss: 0.0489 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0046 - val_loss: 0.0498 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0042 - val_loss: 0.0500 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0041 - val_loss: 0.0502 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0039 - val_loss: 0.0505 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0036 - val_loss: 0.0507 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.3, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.2619 - val_loss: 0.0491 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0744 - val_loss: 0.0247 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0488 - val_loss: 0.0234 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0318 - val_loss: 0.0291 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0197 - val_loss: 0.0373 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0114 - val_loss: 0.0435 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0081 - val_loss: 0.0460 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0074 - val_loss: 0.0470 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0069 - val_loss: 0.0485 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0062 - val_loss: 0.0492 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0055 - val_loss: 0.0497 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0051 - val_loss: 0.0502 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0049 - val_loss: 0.0503 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.3, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 46ms/step - loss: 0.3151 - val_loss: 0.1627 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.1240 - val_loss: 0.0225 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0633 - val_loss: 0.0224 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0523 - val_loss: 0.0210 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0388 - val_loss: 0.0234 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0276 - val_loss: 0.0286 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0196 - val_loss: 0.0333 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0133 - val_loss: 0.0358 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0124 - val_loss: 0.0382 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0098 - val_loss: 0.0401 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0097 - val_loss: 0.0411 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0095 - val_loss: 0.0418 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0088 - val_loss: 0.0424 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0079 - val_loss: 0.0428 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.3, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - loss: 0.0662 - val_loss: 0.0497 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0024 - val_loss: 0.0509 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0016 - val_loss: 0.0509 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0013 - val_loss: 0.0512 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0014 - val_loss: 0.0508 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0013 - val_loss: 0.0504 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0014 - val_loss: 0.0514 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0013 - val_loss: 0.0516 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0012 - val_loss: 0.0515 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0012 - val_loss: 0.0506 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0012 - val_loss: 0.0509 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.3, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.1020 - val_loss: 0.0465 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0038 - val_loss: 0.0516 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0022 - val_loss: 0.0509 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0015 - val_loss: 0.0513 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0014 - val_loss: 0.0511 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0013 - val_loss: 0.0509 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0013 - val_loss: 0.0513 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0013 - val_loss: 0.0508 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0014 - val_loss: 0.0510 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0012 - val_loss: 0.0510 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0011 - val_loss: 0.0511 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.3, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - loss: 0.1403 - val_loss: 0.0341 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0116 - val_loss: 0.0446 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0041 - val_loss: 0.0497 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0033 - val_loss: 0.0494 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0024 - val_loss: 0.0500 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0021 - val_loss: 0.0502 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0021 - val_loss: 0.0506 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0017 - val_loss: 0.0501 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0017 - val_loss: 0.0503 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0015 - val_loss: 0.0501 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0015 - val_loss: 0.0502 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.3, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 0.0403 - val_loss: 0.0515 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0016 - val_loss: 0.0508 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0013 - val_loss: 0.0509 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0014 - val_loss: 0.0503 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0013 - val_loss: 0.0517 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0013 - val_loss: 0.0517 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0013 - val_loss: 0.0506 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0011 - val_loss: 0.0508 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0011 - val_loss: 0.0502 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0012 - val_loss: 0.0503 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0011 - val_loss: 0.0499 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0012 - val_loss: 0.0505 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0011 - val_loss: 0.0507 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0012 - val_loss: 0.0508 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0013 - val_loss: 0.0509 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0013 - val_loss: 0.0502 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0012 - val_loss: 0.0508 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0010 - val_loss: 0.0508 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0012 - val_loss: 0.0506 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0012 - val_loss: 0.0507 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0012 - val_loss: 0.0504 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.3, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0559 - val_loss: 0.0525 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0015 - val_loss: 0.0499 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0012 - val_loss: 0.0508 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0012 - val_loss: 0.0498 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0014 - val_loss: 0.0506 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0014 - val_loss: 0.0510 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0012 - val_loss: 0.0505 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0012 - val_loss: 0.0500 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0012 - val_loss: 0.0510 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0012 - val_loss: 0.0507 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0012 - val_loss: 0.0506 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0011 - val_loss: 0.0505 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0012 - val_loss: 0.0501 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0011 - val_loss: 0.0503 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.3, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 48ms/step - loss: 0.0933 - val_loss: 0.0495 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0021 - val_loss: 0.0508 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0014 - val_loss: 0.0512 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0015 - val_loss: 0.0510 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0015 - val_loss: 0.0512 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0013 - val_loss: 0.0510 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0014 - val_loss: 0.0513 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0012 - val_loss: 0.0507 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0012 - val_loss: 0.0508 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0013 - val_loss: 0.0506 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0012 - val_loss: 0.0509 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.5, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - loss: 0.2510 - val_loss: 0.0345 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0709 - val_loss: 0.0323 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0225 - val_loss: 0.0431 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0134 - val_loss: 0.0472 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0089 - val_loss: 0.0486 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0076 - val_loss: 0.0489 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0065 - val_loss: 0.0493 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0052 - val_loss: 0.0494 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0048 - val_loss: 0.0500 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0049 - val_loss: 0.0501 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0045 - val_loss: 0.0506 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0038 - val_loss: 0.0509 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.5, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - loss: 0.2759 - val_loss: 0.1171 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.1249 - val_loss: 0.0301 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0690 - val_loss: 0.0278 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0370 - val_loss: 0.0380 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0188 - val_loss: 0.0443 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0136 - val_loss: 0.0448 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0126 - val_loss: 0.0458 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0112 - val_loss: 0.0462 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0105 - val_loss: 0.0473 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0088 - val_loss: 0.0471 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0087 - val_loss: 0.0476 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0081 - val_loss: 0.0476 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0084 - val_loss: 0.0482 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.5, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - loss: 0.2672 - val_loss: 0.1348 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.1434 - val_loss: 0.0317 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0955 - val_loss: 0.0282 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0556 - val_loss: 0.0306 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0314 - val_loss: 0.0390 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0191 - val_loss: 0.0441 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0152 - val_loss: 0.0458 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0142 - val_loss: 0.0458 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0123 - val_loss: 0.0467 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0120 - val_loss: 0.0469 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0117 - val_loss: 0.0470 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0106 - val_loss: 0.0475 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0104 - val_loss: 0.0477 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.5, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - loss: 0.0861 - val_loss: 0.0509 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0023 - val_loss: 0.0534 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0018 - val_loss: 0.0510 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0015 - val_loss: 0.0510 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0016 - val_loss: 0.0518 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0014 - val_loss: 0.0505 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0013 - val_loss: 0.0514 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0013 - val_loss: 0.0523 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0014 - val_loss: 0.0511 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0013 - val_loss: 0.0511 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0011 - val_loss: 0.0516 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0013 - val_loss: 0.0511 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0010 - val_loss: 0.0515 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0012 - val_loss: 0.0515 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0012 - val_loss: 0.0515 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0011 - val_loss: 0.0512 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.5, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - loss: 0.1226 - val_loss: 0.0541 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0046 - val_loss: 0.0509 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0024 - val_loss: 0.0514 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0019 - val_loss: 0.0508 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0016 - val_loss: 0.0526 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0014 - val_loss: 0.0519 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0014 - val_loss: 0.0519 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0014 - val_loss: 0.0523 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0012 - val_loss: 0.0515 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0012 - val_loss: 0.0510 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0013 - val_loss: 0.0511 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0013 - val_loss: 0.0512 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0013 - val_loss: 0.0512 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0014 - val_loss: 0.0517 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.5, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - loss: 0.1450 - val_loss: 0.0491 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0071 - val_loss: 0.0496 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0034 - val_loss: 0.0510 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0020 - val_loss: 0.0527 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0016 - val_loss: 0.0510 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0016 - val_loss: 0.0515 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0016 - val_loss: 0.0509 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0016 - val_loss: 0.0521 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0014 - val_loss: 0.0514 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0014 - val_loss: 0.0516 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0012 - val_loss: 0.0512 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.5, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - loss: 0.0433 - val_loss: 0.0514 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0015 - val_loss: 0.0511 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0015 - val_loss: 0.0513 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0014 - val_loss: 0.0504 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0013 - val_loss: 0.0502 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0013 - val_loss: 0.0516 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0011 - val_loss: 0.0503 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0013 - val_loss: 0.0503 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0012 - val_loss: 0.0511 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0012 - val_loss: 0.0513 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0011 - val_loss: 0.0507 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0012 - val_loss: 0.0513 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0011 - val_loss: 0.0509 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0012 - val_loss: 0.0508 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0012 - val_loss: 0.0502 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.5, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0572 - val_loss: 0.0510 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0015 - val_loss: 0.0517 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0013 - val_loss: 0.0499 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0015 - val_loss: 0.0519 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0013 - val_loss: 0.0506 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0012 - val_loss: 0.0504 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0014 - val_loss: 0.0523 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0014 - val_loss: 0.0512 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0011 - val_loss: 0.0508 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0013 - val_loss: 0.0513 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0013 - val_loss: 0.0512 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0012 - val_loss: 0.0507 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0012 - val_loss: 0.0507 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.5, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - loss: 0.0738 - val_loss: 0.0519 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0020 - val_loss: 0.0508 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0018 - val_loss: 0.0516 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0013 - val_loss: 0.0504 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0013 - val_loss: 0.0515 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0016 - val_loss: 0.0517 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0013 - val_loss: 0.0515 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0013 - val_loss: 0.0508 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0012 - val_loss: 0.0517 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0013 - val_loss: 0.0511 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0012 - val_loss: 0.0509 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0012 - val_loss: 0.0512 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0012 - val_loss: 0.0510 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0012 - val_loss: 0.0509 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.2, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.2508 - val_loss: 0.0168 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0366 - val_loss: 0.0188 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0272 - val_loss: 0.0240 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0128 - val_loss: 0.0372 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0077 - val_loss: 0.0418 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0057 - val_loss: 0.0433 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0049 - val_loss: 0.0440 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0044 - val_loss: 0.0442 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0039 - val_loss: 0.0449 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0035 - val_loss: 0.0449 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0035 - val_loss: 0.0451 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.2, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.2476 - val_loss: 0.0460 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0458 - val_loss: 0.0171 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0422 - val_loss: 0.0146 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0306 - val_loss: 0.0174 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0275 - val_loss: 0.0225 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0145 - val_loss: 0.0288 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0094 - val_loss: 0.0343 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0065 - val_loss: 0.0394 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0062 - val_loss: 0.0423 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0049 - val_loss: 0.0427 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0052 - val_loss: 0.0428 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0046 - val_loss: 0.0432 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0047 - val_loss: 0.0433 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.2, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.2162 - val_loss: 0.1043 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0756 - val_loss: 0.0098 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0421 - val_loss: 0.0176 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0420 - val_loss: 0.0143 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0333 - val_loss: 0.0156 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0314 - val_loss: 0.0162 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0275 - val_loss: 0.0177 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0232 - val_loss: 0.0187 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0209 - val_loss: 0.0202 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0185 - val_loss: 0.0218 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0170 - val_loss: 0.0233 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0132 - val_loss: 0.0243 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.2, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0722 - val_loss: 0.0483 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0021 - val_loss: 0.0455 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0013 - val_loss: 0.0450 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0436 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0466 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0011 - val_loss: 0.0442 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0448 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 9.0780e-04 - val_loss: 0.0438 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 9.9777e-04 - val_loss: 0.0442 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 9.6852e-04 - val_loss: 0.0414 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0010 - val_loss: 0.0421 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 9.1410e-04 - val_loss: 0.0397 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 9.4819e-04 - val_loss: 0.0400 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 9.1936e-04 - val_loss: 0.0395 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 9.6511e-04 - val_loss: 0.0388 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 8.7786e-04 - val_loss: 0.0380 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 9.9564e-04 - val_loss: 0.0351 - learning_rate: 5.0000e-04\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 7.3594e-04 - val_loss: 0.0321 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 8.0135e-04 - val_loss: 0.0323 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6.8954e-04 - val_loss: 0.0323 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6.9541e-04 - val_loss: 0.0308 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6.6292e-04 - val_loss: 0.0307 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5.5901e-04 - val_loss: 0.0259 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5.7453e-04 - val_loss: 0.0285 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 25/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5.3728e-04 - val_loss: 0.0284 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 26/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5.0205e-04 - val_loss: 0.0260 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 27/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 4.2569e-04 - val_loss: 0.0243 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 28/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6.0205e-04 - val_loss: 0.0256 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 29/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4.7301e-04 - val_loss: 0.0265 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 30/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 4.7270e-04 - val_loss: 0.0269 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 31/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 4.3256e-04 - val_loss: 0.0260 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 32/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5.3283e-04 - val_loss: 0.0251 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 33/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 4.3761e-04 - val_loss: 0.0250 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 34/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 3.5375e-04 - val_loss: 0.0242 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 35/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4.0273e-04 - val_loss: 0.0253 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 36/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4.0398e-04 - val_loss: 0.0258 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 37/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 3.9210e-04 - val_loss: 0.0248 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 38/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 3.0716e-04 - val_loss: 0.0248 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 39/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 3.7423e-04 - val_loss: 0.0241 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 40/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 3.3876e-04 - val_loss: 0.0248 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 41/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4.7508e-04 - val_loss: 0.0245 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 42/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 3.2837e-04 - val_loss: 0.0245 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 43/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 3.6254e-04 - val_loss: 0.0250 - learning_rate: 1.5625e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 44/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4.3556e-04 - val_loss: 0.0247 - learning_rate: 1.5625e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 45/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 5.2763e-04 - val_loss: 0.0247 - learning_rate: 1.5625e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 46/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 3.8807e-04 - val_loss: 0.0246 - learning_rate: 7.8125e-06\b\b\b\b\b\b\b\b\b\b\b\nEpoch 47/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 3.9238e-04 - val_loss: 0.0245 - learning_rate: 7.8125e-06\b\b\b\b\b\b\b\b\b\b\b\nEpoch 48/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 4.2594e-04 - val_loss: 0.0245 - learning_rate: 7.8125e-06\b\b\b\b\b\b\b\b\b\b\b\nEpoch 49/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 3.6136e-04 - val_loss: 0.0246 - learning_rate: 3.9063e-06\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.2, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - loss: 0.0885 - val_loss: 0.0198 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0077 - val_loss: 0.0415 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0017 - val_loss: 0.0447 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0014 - val_loss: 0.0455 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0011 - val_loss: 0.0465 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0012 - val_loss: 0.0454 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0012 - val_loss: 0.0452 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0012 - val_loss: 0.0450 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0012 - val_loss: 0.0447 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0011 - val_loss: 0.0454 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0011 - val_loss: 0.0451 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.2, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.1303 - val_loss: 0.0127 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0219 - val_loss: 0.0316 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0035 - val_loss: 0.0465 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0019 - val_loss: 0.0477 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0015 - val_loss: 0.0472 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0016 - val_loss: 0.0464 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0014 - val_loss: 0.0469 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0014 - val_loss: 0.0467 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0013 - val_loss: 0.0469 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0013 - val_loss: 0.0469 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0014 - val_loss: 0.0472 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.2, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0594 - val_loss: 0.0470 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0015 - val_loss: 0.0505 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0013 - val_loss: 0.0493 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0010 - val_loss: 0.0472 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0012 - val_loss: 0.0468 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 9.9587e-04 - val_loss: 0.0457 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0457 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0010 - val_loss: 0.0450 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0011 - val_loss: 0.0469 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0450 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0011 - val_loss: 0.0443 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0011 - val_loss: 0.0439 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 9.8851e-04 - val_loss: 0.0444 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 9.6102e-04 - val_loss: 0.0423 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 8.9037e-04 - val_loss: 0.0381 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 6.7974e-04 - val_loss: 0.0374 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 7.3950e-04 - val_loss: 0.0363 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 6.4824e-04 - val_loss: 0.0285 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 7.6896e-04 - val_loss: 0.0307 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 5.8612e-04 - val_loss: 0.0293 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 5.1887e-04 - val_loss: 0.0311 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 5.8435e-04 - val_loss: 0.0291 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4.0588e-04 - val_loss: 0.0264 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4.6705e-04 - val_loss: 0.0278 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 25/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4.7334e-04 - val_loss: 0.0265 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 26/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 3.9590e-04 - val_loss: 0.0266 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 27/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 4.5679e-04 - val_loss: 0.0264 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 28/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 3.3908e-04 - val_loss: 0.0276 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 29/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 3.6558e-04 - val_loss: 0.0265 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 30/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.8241e-04 - val_loss: 0.0262 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 31/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 3.8430e-04 - val_loss: 0.0261 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 32/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 3.3042e-04 - val_loss: 0.0258 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 33/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 3.9053e-04 - val_loss: 0.0271 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 34/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 3.2620e-04 - val_loss: 0.0263 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 35/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4.0149e-04 - val_loss: 0.0265 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 36/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4.1297e-04 - val_loss: 0.0265 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 37/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4.0660e-04 - val_loss: 0.0264 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 38/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 3.4834e-04 - val_loss: 0.0262 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 39/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 3.8460e-04 - val_loss: 0.0265 - learning_rate: 7.8125e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 40/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 3.1662e-04 - val_loss: 0.0266 - learning_rate: 7.8125e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 41/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 3.2656e-04 - val_loss: 0.0263 - learning_rate: 7.8125e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 42/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4.0129e-04 - val_loss: 0.0262 - learning_rate: 3.9062e-05\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.2, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0604 - val_loss: 0.0484 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0018 - val_loss: 0.0478 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0013 - val_loss: 0.0484 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0011 - val_loss: 0.0493 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0011 - val_loss: 0.0471 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0011 - val_loss: 0.0446 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0011 - val_loss: 0.0456 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0011 - val_loss: 0.0457 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0012 - val_loss: 0.0454 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0010 - val_loss: 0.0436 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0010 - val_loss: 0.0431 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0012 - val_loss: 0.0416 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0011 - val_loss: 0.0387 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 8.8947e-04 - val_loss: 0.0384 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 8.7044e-04 - val_loss: 0.0378 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 7.8345e-04 - val_loss: 0.0362 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 9.0973e-04 - val_loss: 0.0324 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 6.6973e-04 - val_loss: 0.0298 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 6.9195e-04 - val_loss: 0.0318 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 5.3776e-04 - val_loss: 0.0258 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 7.8663e-04 - val_loss: 0.0306 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 5.5818e-04 - val_loss: 0.0295 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 6.0174e-04 - val_loss: 0.0315 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 4.5774e-04 - val_loss: 0.0293 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 25/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 4.7588e-04 - val_loss: 0.0278 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 26/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 4.3954e-04 - val_loss: 0.0273 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 27/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 4.6057e-04 - val_loss: 0.0268 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 28/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.0344e-04 - val_loss: 0.0277 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 29/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 3.6749e-04 - val_loss: 0.0270 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 30/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 2.9619e-04 - val_loss: 0.0275 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.2, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0845 - val_loss: 0.0268 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0053 - val_loss: 0.0484 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0011 - val_loss: 0.0471 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0011 - val_loss: 0.0485 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0012 - val_loss: 0.0474 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0011 - val_loss: 0.0468 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0012 - val_loss: 0.0472 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0012 - val_loss: 0.0479 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0011 - val_loss: 0.0470 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0010 - val_loss: 0.0471 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0011 - val_loss: 0.0476 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.3, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.2153 - val_loss: 0.0254 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0535 - val_loss: 0.0213 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0263 - val_loss: 0.0415 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0068 - val_loss: 0.0433 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0048 - val_loss: 0.0434 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0043 - val_loss: 0.0441 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0038 - val_loss: 0.0442 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0036 - val_loss: 0.0435 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0030 - val_loss: 0.0444 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0032 - val_loss: 0.0439 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0032 - val_loss: 0.0445 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0032 - val_loss: 0.0443 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.3, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.2353 - val_loss: 0.0516 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0713 - val_loss: 0.0286 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0606 - val_loss: 0.0213 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0387 - val_loss: 0.0209 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0246 - val_loss: 0.0326 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0082 - val_loss: 0.0440 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0063 - val_loss: 0.0429 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0046 - val_loss: 0.0433 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0048 - val_loss: 0.0437 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0046 - val_loss: 0.0435 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0038 - val_loss: 0.0436 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0041 - val_loss: 0.0434 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0039 - val_loss: 0.0435 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0041 - val_loss: 0.0438 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.3, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.2433 - val_loss: 0.1321 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1057 - val_loss: 0.0240 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0707 - val_loss: 0.0242 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0592 - val_loss: 0.0212 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0504 - val_loss: 0.0199 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0357 - val_loss: 0.0226 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0198 - val_loss: 0.0360 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0074 - val_loss: 0.0428 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0067 - val_loss: 0.0425 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0059 - val_loss: 0.0424 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0059 - val_loss: 0.0429 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0054 - val_loss: 0.0426 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0053 - val_loss: 0.0429 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0051 - val_loss: 0.0431 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0049 - val_loss: 0.0433 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.3, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0652 - val_loss: 0.0490 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0016 - val_loss: 0.0481 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0015 - val_loss: 0.0480 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0475 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0012 - val_loss: 0.0472 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0012 - val_loss: 0.0458 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0013 - val_loss: 0.0462 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 9.7208e-04 - val_loss: 0.0449 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0011 - val_loss: 0.0456 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0011 - val_loss: 0.0442 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0010 - val_loss: 0.0425 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 9.1426e-04 - val_loss: 0.0447 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0010 - val_loss: 0.0399 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0011 - val_loss: 0.0396 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 8.6121e-04 - val_loss: 0.0367 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 8.9999e-04 - val_loss: 0.0373 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 8.2170e-04 - val_loss: 0.0336 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 8.7996e-04 - val_loss: 0.0352 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 6.6831e-04 - val_loss: 0.0358 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 6.6429e-04 - val_loss: 0.0411 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 6.2320e-04 - val_loss: 0.0358 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 6.2320e-04 - val_loss: 0.0368 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 7.2062e-04 - val_loss: 0.0352 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5.4862e-04 - val_loss: 0.0351 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 25/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 5.0315e-04 - val_loss: 0.0352 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 26/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4.6536e-04 - val_loss: 0.0340 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 27/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 5.5992e-04 - val_loss: 0.0360 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.3, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.1069 - val_loss: 0.0310 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0050 - val_loss: 0.0472 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0016 - val_loss: 0.0480 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0014 - val_loss: 0.0477 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0013 - val_loss: 0.0476 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0013 - val_loss: 0.0474 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0012 - val_loss: 0.0470 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0012 - val_loss: 0.0478 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0012 - val_loss: 0.0480 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0012 - val_loss: 0.0476 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0011 - val_loss: 0.0474 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.3, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.1565 - val_loss: 0.0191 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0197 - val_loss: 0.0501 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0026 - val_loss: 0.0461 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0019 - val_loss: 0.0479 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0017 - val_loss: 0.0488 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0015 - val_loss: 0.0477 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0015 - val_loss: 0.0487 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0014 - val_loss: 0.0480 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0015 - val_loss: 0.0488 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0012 - val_loss: 0.0486 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0013 - val_loss: 0.0481 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.3, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0336 - val_loss: 0.0504 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0475 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0468 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0012 - val_loss: 0.0481 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0011 - val_loss: 0.0486 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0011 - val_loss: 0.0459 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0011 - val_loss: 0.0448 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0012 - val_loss: 0.0440 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0011 - val_loss: 0.0450 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0010 - val_loss: 0.0403 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0014 - val_loss: 0.0392 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0431 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 9.5038e-04 - val_loss: 0.0378 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0012 - val_loss: 0.0364 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 8.7890e-04 - val_loss: 0.0363 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 7.1119e-04 - val_loss: 0.0361 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6.8287e-04 - val_loss: 0.0349 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 7.2411e-04 - val_loss: 0.0383 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 7.1404e-04 - val_loss: 0.0420 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 5.5694e-04 - val_loss: 0.0394 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 4.7627e-04 - val_loss: 0.0359 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 6.2411e-04 - val_loss: 0.0363 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 5.8576e-04 - val_loss: 0.0375 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4.8377e-04 - val_loss: 0.0375 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 25/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.1746e-04 - val_loss: 0.0376 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 26/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 4.0962e-04 - val_loss: 0.0383 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 27/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 4.1989e-04 - val_loss: 0.0374 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.3, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0885 - val_loss: 0.0517 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0017 - val_loss: 0.0478 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0011 - val_loss: 0.0486 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0010 - val_loss: 0.0489 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0011 - val_loss: 0.0499 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0011 - val_loss: 0.0481 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0012 - val_loss: 0.0484 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0010 - val_loss: 0.0495 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0012 - val_loss: 0.0491 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0011 - val_loss: 0.0477 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0011 - val_loss: 0.0485 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0011 - val_loss: 0.0499 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0011 - val_loss: 0.0486 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 9.9896e-04 - val_loss: 0.0482 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0011 - val_loss: 0.0485 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0010 - val_loss: 0.0485 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0011 - val_loss: 0.0483 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0012 - val_loss: 0.0482 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0011 - val_loss: 0.0485 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0011 - val_loss: 0.0484 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.3, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.1099 - val_loss: 0.0380 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0034 - val_loss: 0.0495 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0011 - val_loss: 0.0491 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0011 - val_loss: 0.0491 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0013 - val_loss: 0.0495 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0011 - val_loss: 0.0504 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0011 - val_loss: 0.0491 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0011 - val_loss: 0.0494 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0011 - val_loss: 0.0487 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0011 - val_loss: 0.0490 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0010 - val_loss: 0.0489 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.5, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.2555 - val_loss: 0.0584 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0817 - val_loss: 0.0337 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0127 - val_loss: 0.0477 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0067 - val_loss: 0.0471 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0049 - val_loss: 0.0473 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0043 - val_loss: 0.0480 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0042 - val_loss: 0.0478 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0040 - val_loss: 0.0490 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0036 - val_loss: 0.0490 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0035 - val_loss: 0.0488 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0031 - val_loss: 0.0488 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0029 - val_loss: 0.0489 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.5, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.2827 - val_loss: 0.0829 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.1107 - val_loss: 0.0501 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0713 - val_loss: 0.0343 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0270 - val_loss: 0.0488 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0091 - val_loss: 0.0475 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0078 - val_loss: 0.0481 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0063 - val_loss: 0.0473 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0063 - val_loss: 0.0481 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0060 - val_loss: 0.0485 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0055 - val_loss: 0.0480 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0054 - val_loss: 0.0479 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0052 - val_loss: 0.0478 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0045 - val_loss: 0.0481 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.5, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.2924 - val_loss: 0.1861 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1562 - val_loss: 0.0641 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.1097 - val_loss: 0.0563 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0918 - val_loss: 0.0396 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0643 - val_loss: 0.0296 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0264 - val_loss: 0.0464 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0093 - val_loss: 0.0468 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0079 - val_loss: 0.0461 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0071 - val_loss: 0.0473 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0067 - val_loss: 0.0476 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0065 - val_loss: 0.0468 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0062 - val_loss: 0.0468 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0061 - val_loss: 0.0468 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0054 - val_loss: 0.0473 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0053 - val_loss: 0.0474 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.5, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0720 - val_loss: 0.0490 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0015 - val_loss: 0.0497 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0015 - val_loss: 0.0511 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0013 - val_loss: 0.0503 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0496 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0508 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0497 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0500 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0010 - val_loss: 0.0493 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 9.1136e-04 - val_loss: 0.0501 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 8.9540e-04 - val_loss: 0.0497 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.5, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.1123 - val_loss: 0.0474 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0026 - val_loss: 0.0489 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0015 - val_loss: 0.0494 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0014 - val_loss: 0.0505 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0014 - val_loss: 0.0498 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0012 - val_loss: 0.0505 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0012 - val_loss: 0.0502 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0012 - val_loss: 0.0507 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0011 - val_loss: 0.0499 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0011 - val_loss: 0.0503 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0011 - val_loss: 0.0501 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.5, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.1745 - val_loss: 0.0286 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0120 - val_loss: 0.0483 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0019 - val_loss: 0.0506 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0016 - val_loss: 0.0507 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0015 - val_loss: 0.0489 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0016 - val_loss: 0.0501 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0014 - val_loss: 0.0498 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0014 - val_loss: 0.0501 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0013 - val_loss: 0.0497 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0014 - val_loss: 0.0499 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0014 - val_loss: 0.0499 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.5, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0381 - val_loss: 0.0506 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0013 - val_loss: 0.0518 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0489 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0010 - val_loss: 0.0491 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0013 - val_loss: 0.0521 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0015 - val_loss: 0.0506 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0010 - val_loss: 0.0512 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 9.3789e-04 - val_loss: 0.0498 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 9.7894e-04 - val_loss: 0.0506 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 9.2774e-04 - val_loss: 0.0519 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 8.0415e-04 - val_loss: 0.0534 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 7.6458e-04 - val_loss: 0.0548 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 7.4715e-04 - val_loss: 0.0536 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.5, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0799 - val_loss: 0.0490 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0012 - val_loss: 0.0520 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0013 - val_loss: 0.0507 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0012 - val_loss: 0.0506 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0011 - val_loss: 0.0502 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0013 - val_loss: 0.0497 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0011 - val_loss: 0.0504 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0011 - val_loss: 0.0503 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0011 - val_loss: 0.0503 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0012 - val_loss: 0.0509 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0011 - val_loss: 0.0506 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.5, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0780 - val_loss: 0.0496 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0013 - val_loss: 0.0501 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0013 - val_loss: 0.0507 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0013 - val_loss: 0.0504 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0011 - val_loss: 0.0504 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0013 - val_loss: 0.0501 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0010 - val_loss: 0.0501 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0011 - val_loss: 0.0505 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0011 - val_loss: 0.0509 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0012 - val_loss: 0.0511 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0012 - val_loss: 0.0503 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.2, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 0.1739 - val_loss: 0.0131 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0282 - val_loss: 0.0224 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0109 - val_loss: 0.0446 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0038 - val_loss: 0.0452 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0034 - val_loss: 0.0464 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0032 - val_loss: 0.0461 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0029 - val_loss: 0.0467 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0027 - val_loss: 0.0462 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0030 - val_loss: 0.0469 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0025 - val_loss: 0.0470 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0025 - val_loss: 0.0471 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.2, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 0.2611 - val_loss: 0.0073 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0494 - val_loss: 0.0136 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0329 - val_loss: 0.0168 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0227 - val_loss: 0.0245 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0140 - val_loss: 0.0299 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0090 - val_loss: 0.0364 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0056 - val_loss: 0.0421 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0050 - val_loss: 0.0445 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0043 - val_loss: 0.0452 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0046 - val_loss: 0.0457 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0040 - val_loss: 0.0457 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.2, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - loss: 0.1491 - val_loss: 0.0064 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0514 - val_loss: 0.0164 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0408 - val_loss: 0.0149 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0333 - val_loss: 0.0157 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0220 - val_loss: 0.0192 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0197 - val_loss: 0.0243 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0114 - val_loss: 0.0315 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0073 - val_loss: 0.0350 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0061 - val_loss: 0.0389 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0058 - val_loss: 0.0417 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0048 - val_loss: 0.0425 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.2, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 0.0606 - val_loss: 0.0461 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0018 - val_loss: 0.0471 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0018 - val_loss: 0.0479 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0013 - val_loss: 0.0487 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0013 - val_loss: 0.0474 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0013 - val_loss: 0.0476 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0012 - val_loss: 0.0486 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0012 - val_loss: 0.0480 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0012 - val_loss: 0.0467 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0012 - val_loss: 0.0480 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0012 - val_loss: 0.0473 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.2, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 0.0803 - val_loss: 0.0321 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0036 - val_loss: 0.0461 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0019 - val_loss: 0.0493 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0016 - val_loss: 0.0483 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0013 - val_loss: 0.0481 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0013 - val_loss: 0.0482 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0012 - val_loss: 0.0483 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0013 - val_loss: 0.0477 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0014 - val_loss: 0.0477 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0013 - val_loss: 0.0478 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0012 - val_loss: 0.0478 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.2, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - loss: 0.1105 - val_loss: 0.0200 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0127 - val_loss: 0.0376 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0024 - val_loss: 0.0454 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0021 - val_loss: 0.0478 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0017 - val_loss: 0.0468 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0019 - val_loss: 0.0475 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0016 - val_loss: 0.0475 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0015 - val_loss: 0.0477 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0014 - val_loss: 0.0467 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0016 - val_loss: 0.0468 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0014 - val_loss: 0.0473 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.2, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - loss: 0.0331 - val_loss: 0.0531 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0017 - val_loss: 0.0494 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0014 - val_loss: 0.0486 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0012 - val_loss: 0.0525 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0013 - val_loss: 0.0510 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0014 - val_loss: 0.0489 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0012 - val_loss: 0.0457 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0013 - val_loss: 0.0487 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0012 - val_loss: 0.0444 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0011 - val_loss: 0.0454 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0010 - val_loss: 0.0437 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0011 - val_loss: 0.0402 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0014 - val_loss: 0.0446 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 9.9700e-04 - val_loss: 0.0427 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 9.3872e-04 - val_loss: 0.0386 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 8.9617e-04 - val_loss: 0.0325 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 8.6622e-04 - val_loss: 0.0376 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 9.1588e-04 - val_loss: 0.0388 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 8.6572e-04 - val_loss: 0.0242 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0012 - val_loss: 0.0412 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 7.2325e-04 - val_loss: 0.0364 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 8.9117e-04 - val_loss: 0.0350 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 5.6895e-04 - val_loss: 0.0369 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 4.5408e-04 - val_loss: 0.0356 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 25/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 4.2692e-04 - val_loss: 0.0354 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 26/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 3.4152e-04 - val_loss: 0.0364 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 27/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 4.2023e-04 - val_loss: 0.0353 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 28/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 3.8134e-04 - val_loss: 0.0357 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 29/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 3.7555e-04 - val_loss: 0.0351 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.2, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - loss: 0.0515 - val_loss: 0.0483 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0013 - val_loss: 0.0482 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0013 - val_loss: 0.0509 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0014 - val_loss: 0.0505 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0012 - val_loss: 0.0490 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0012 - val_loss: 0.0487 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0012 - val_loss: 0.0484 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0011 - val_loss: 0.0493 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0011 - val_loss: 0.0496 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0011 - val_loss: 0.0495 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0011 - val_loss: 0.0497 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0013 - val_loss: 0.0492 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.2, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - loss: 0.0653 - val_loss: 0.0465 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0021 - val_loss: 0.0500 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0013 - val_loss: 0.0499 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0012 - val_loss: 0.0513 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0013 - val_loss: 0.0494 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0012 - val_loss: 0.0514 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0013 - val_loss: 0.0501 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0012 - val_loss: 0.0492 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0011 - val_loss: 0.0487 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0013 - val_loss: 0.0495 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0012 - val_loss: 0.0492 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.3, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - loss: 0.1519 - val_loss: 0.0201 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0352 - val_loss: 0.0410 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0063 - val_loss: 0.0451 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0054 - val_loss: 0.0464 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0041 - val_loss: 0.0468 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0034 - val_loss: 0.0472 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0033 - val_loss: 0.0472 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0034 - val_loss: 0.0477 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0029 - val_loss: 0.0476 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0029 - val_loss: 0.0478 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0027 - val_loss: 0.0478 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.3, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 0.2081 - val_loss: 0.0124 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0617 - val_loss: 0.0192 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0352 - val_loss: 0.0262 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0145 - val_loss: 0.0464 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0068 - val_loss: 0.0458 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0054 - val_loss: 0.0456 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0048 - val_loss: 0.0456 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0047 - val_loss: 0.0457 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0047 - val_loss: 0.0462 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0040 - val_loss: 0.0461 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0042 - val_loss: 0.0461 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.3, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - loss: 0.2090 - val_loss: 0.0161 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0832 - val_loss: 0.0279 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0550 - val_loss: 0.0197 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0381 - val_loss: 0.0234 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0221 - val_loss: 0.0300 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0129 - val_loss: 0.0375 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0084 - val_loss: 0.0433 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0069 - val_loss: 0.0445 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0058 - val_loss: 0.0446 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0063 - val_loss: 0.0452 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0063 - val_loss: 0.0454 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.3, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 0.0644 - val_loss: 0.0485 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0022 - val_loss: 0.0495 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0016 - val_loss: 0.0492 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0014 - val_loss: 0.0493 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0014 - val_loss: 0.0484 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0014 - val_loss: 0.0492 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0013 - val_loss: 0.0500 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0011 - val_loss: 0.0485 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0012 - val_loss: 0.0493 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0012 - val_loss: 0.0486 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0011 - val_loss: 0.0489 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0012 - val_loss: 0.0497 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0011 - val_loss: 0.0490 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0011 - val_loss: 0.0487 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0013 - val_loss: 0.0486 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.3, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 0.0956 - val_loss: 0.0507 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0030 - val_loss: 0.0495 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0020 - val_loss: 0.0505 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0019 - val_loss: 0.0499 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0017 - val_loss: 0.0504 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0015 - val_loss: 0.0495 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0016 - val_loss: 0.0507 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0013 - val_loss: 0.0500 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0013 - val_loss: 0.0491 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0013 - val_loss: 0.0494 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0013 - val_loss: 0.0497 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0012 - val_loss: 0.0501 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0012 - val_loss: 0.0499 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0012 - val_loss: 0.0494 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0013 - val_loss: 0.0495 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0012 - val_loss: 0.0497 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0012 - val_loss: 0.0496 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0011 - val_loss: 0.0495 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0012 - val_loss: 0.0497 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.3, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - loss: 0.1045 - val_loss: 0.0333 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0067 - val_loss: 0.0474 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0022 - val_loss: 0.0502 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0020 - val_loss: 0.0486 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0017 - val_loss: 0.0491 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0017 - val_loss: 0.0495 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0016 - val_loss: 0.0491 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0015 - val_loss: 0.0494 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0014 - val_loss: 0.0494 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0013 - val_loss: 0.0489 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0015 - val_loss: 0.0495 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.3, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 0.0341 - val_loss: 0.0525 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0014 - val_loss: 0.0486 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0015 - val_loss: 0.0517 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0015 - val_loss: 0.0493 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0015 - val_loss: 0.0497 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0013 - val_loss: 0.0493 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0013 - val_loss: 0.0501 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0013 - val_loss: 0.0496 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0011 - val_loss: 0.0495 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0013 - val_loss: 0.0488 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0013 - val_loss: 0.0489 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0012 - val_loss: 0.0487 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.3, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 0.0557 - val_loss: 0.0516 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0014 - val_loss: 0.0499 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0013 - val_loss: 0.0498 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0013 - val_loss: 0.0498 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0014 - val_loss: 0.0488 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0014 - val_loss: 0.0502 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0013 - val_loss: 0.0507 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0012 - val_loss: 0.0503 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0015 - val_loss: 0.0512 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0013 - val_loss: 0.0491 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0011 - val_loss: 0.0502 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0010 - val_loss: 0.0503 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0013 - val_loss: 0.0502 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0011 - val_loss: 0.0497 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0013 - val_loss: 0.0500 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.3, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - loss: 0.0776 - val_loss: 0.0526 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0015 - val_loss: 0.0499 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0016 - val_loss: 0.0508 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0013 - val_loss: 0.0502 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0013 - val_loss: 0.0502 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0013 - val_loss: 0.0504 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0012 - val_loss: 0.0503 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0013 - val_loss: 0.0503 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0011 - val_loss: 0.0495 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0010 - val_loss: 0.0501 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0010 - val_loss: 0.0505 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0011 - val_loss: 0.0508 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0011 - val_loss: 0.0501 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0012 - val_loss: 0.0501 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0012 - val_loss: 0.0499 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0013 - val_loss: 0.0502 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0011 - val_loss: 0.0502 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0012 - val_loss: 0.0499 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0011 - val_loss: 0.0503 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.5, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 0.1954 - val_loss: 0.0375 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0448 - val_loss: 0.0464 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0072 - val_loss: 0.0481 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0062 - val_loss: 0.0491 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0048 - val_loss: 0.0489 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0046 - val_loss: 0.0485 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0037 - val_loss: 0.0485 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0040 - val_loss: 0.0494 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0036 - val_loss: 0.0494 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0034 - val_loss: 0.0499 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0032 - val_loss: 0.0493 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.5, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 0.2035 - val_loss: 0.0503 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.1040 - val_loss: 0.0335 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0401 - val_loss: 0.0494 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0127 - val_loss: 0.0470 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0076 - val_loss: 0.0474 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0069 - val_loss: 0.0478 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0057 - val_loss: 0.0489 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0057 - val_loss: 0.0486 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0055 - val_loss: 0.0489 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0059 - val_loss: 0.0489 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0044 - val_loss: 0.0487 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0050 - val_loss: 0.0489 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.5, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - loss: 0.1885 - val_loss: 0.0410 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.1221 - val_loss: 0.0416 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0712 - val_loss: 0.0332 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0178 - val_loss: 0.0482 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0091 - val_loss: 0.0465 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0078 - val_loss: 0.0468 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0070 - val_loss: 0.0468 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0065 - val_loss: 0.0479 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0060 - val_loss: 0.0482 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0053 - val_loss: 0.0478 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0055 - val_loss: 0.0474 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0058 - val_loss: 0.0476 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0051 - val_loss: 0.0479 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.5, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 0.0716 - val_loss: 0.0507 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0025 - val_loss: 0.0509 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0017 - val_loss: 0.0512 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0016 - val_loss: 0.0494 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0014 - val_loss: 0.0521 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0015 - val_loss: 0.0504 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0013 - val_loss: 0.0506 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0012 - val_loss: 0.0519 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0012 - val_loss: 0.0507 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0012 - val_loss: 0.0511 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0011 - val_loss: 0.0505 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0011 - val_loss: 0.0505 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0013 - val_loss: 0.0502 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0011 - val_loss: 0.0500 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.5, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 0.1079 - val_loss: 0.0487 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0028 - val_loss: 0.0499 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0022 - val_loss: 0.0519 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0016 - val_loss: 0.0514 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0015 - val_loss: 0.0508 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0016 - val_loss: 0.0502 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0014 - val_loss: 0.0515 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0014 - val_loss: 0.0513 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0012 - val_loss: 0.0511 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0013 - val_loss: 0.0510 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0013 - val_loss: 0.0511 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.5, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - loss: 0.1131 - val_loss: 0.0630 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0043 - val_loss: 0.0522 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0021 - val_loss: 0.0499 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0019 - val_loss: 0.0499 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0018 - val_loss: 0.0509 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0016 - val_loss: 0.0510 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0013 - val_loss: 0.0510 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0014 - val_loss: 0.0504 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0013 - val_loss: 0.0509 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0012 - val_loss: 0.0513 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0013 - val_loss: 0.0507 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0014 - val_loss: 0.0509 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0014 - val_loss: 0.0506 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.5, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 0.0599 - val_loss: 0.0516 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0017 - val_loss: 0.0497 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0014 - val_loss: 0.0509 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0016 - val_loss: 0.0497 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0013 - val_loss: 0.0513 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0013 - val_loss: 0.0503 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0011 - val_loss: 0.0507 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0011 - val_loss: 0.0506 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0012 - val_loss: 0.0498 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0011 - val_loss: 0.0509 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0011 - val_loss: 0.0500 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0012 - val_loss: 0.0507 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.5, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 0.0793 - val_loss: 0.0508 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0016 - val_loss: 0.0503 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0015 - val_loss: 0.0504 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0013 - val_loss: 0.0500 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0014 - val_loss: 0.0503 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0013 - val_loss: 0.0511 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0014 - val_loss: 0.0504 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0011 - val_loss: 0.0507 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0013 - val_loss: 0.0512 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0011 - val_loss: 0.0508 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0012 - val_loss: 0.0507 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0012 - val_loss: 0.0503 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0011 - val_loss: 0.0506 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0012 - val_loss: 0.0503 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.5, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.0977 - val_loss: 0.0476 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0019 - val_loss: 0.0518 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0014 - val_loss: 0.0502 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0014 - val_loss: 0.0500 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0014 - val_loss: 0.0507 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0012 - val_loss: 0.0508 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0012 - val_loss: 0.0507 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0012 - val_loss: 0.0507 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0011 - val_loss: 0.0503 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0012 - val_loss: 0.0501 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0011 - val_loss: 0.0506 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.2, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - loss: 0.1385 - val_loss: 0.0154 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0286 - val_loss: 0.0331 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0070 - val_loss: 0.0486 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0041 - val_loss: 0.0489 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0033 - val_loss: 0.0484 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0033 - val_loss: 0.0485 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0030 - val_loss: 0.0488 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0029 - val_loss: 0.0488 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0028 - val_loss: 0.0481 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0028 - val_loss: 0.0487 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0023 - val_loss: 0.0488 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.2, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - loss: 0.1714 - val_loss: 0.0258 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0395 - val_loss: 0.0184 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0222 - val_loss: 0.0248 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0128 - val_loss: 0.0396 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0054 - val_loss: 0.0487 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - loss: 0.0043 - val_loss: 0.0475 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0046 - val_loss: 0.0473 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0041 - val_loss: 0.0481 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0036 - val_loss: 0.0479 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0035 - val_loss: 0.0479 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0033 - val_loss: 0.0481 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0034 - val_loss: 0.0481 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.2, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 66ms/step - loss: 0.2363 - val_loss: 0.0099 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0531 - val_loss: 0.0199 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0334 - val_loss: 0.0175 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0251 - val_loss: 0.0214 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0189 - val_loss: 0.0250 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - loss: 0.0157 - val_loss: 0.0287 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0113 - val_loss: 0.0345 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0077 - val_loss: 0.0370 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0070 - val_loss: 0.0398 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0055 - val_loss: 0.0423 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0056 - val_loss: 0.0431 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.2, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - loss: 0.0488 - val_loss: 0.0480 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.0018 - val_loss: 0.0489 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0017 - val_loss: 0.0489 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0015 - val_loss: 0.0486 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0013 - val_loss: 0.0482 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0012 - val_loss: 0.0481 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0013 - val_loss: 0.0490 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0012 - val_loss: 0.0489 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0011 - val_loss: 0.0495 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0013 - val_loss: 0.0490 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0012 - val_loss: 0.0488 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.2, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - loss: 0.0787 - val_loss: 0.0426 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0025 - val_loss: 0.0483 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0018 - val_loss: 0.0488 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0017 - val_loss: 0.0501 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0014 - val_loss: 0.0487 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0015 - val_loss: 0.0489 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0013 - val_loss: 0.0490 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0012 - val_loss: 0.0496 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0013 - val_loss: 0.0489 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0013 - val_loss: 0.0492 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0013 - val_loss: 0.0495 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.2, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 66ms/step - loss: 0.1030 - val_loss: 0.0298 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0064 - val_loss: 0.0494 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0023 - val_loss: 0.0480 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0017 - val_loss: 0.0485 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0016 - val_loss: 0.0482 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0017 - val_loss: 0.0496 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0015 - val_loss: 0.0491 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0014 - val_loss: 0.0483 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0014 - val_loss: 0.0488 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0015 - val_loss: 0.0495 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0014 - val_loss: 0.0490 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.2, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - loss: 0.0567 - val_loss: 0.0498 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0014 - val_loss: 0.0490 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0014 - val_loss: 0.0502 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0013 - val_loss: 0.0502 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0014 - val_loss: 0.0517 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0013 - val_loss: 0.0503 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0011 - val_loss: 0.0503 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0013 - val_loss: 0.0500 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0012 - val_loss: 0.0503 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0012 - val_loss: 0.0505 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0012 - val_loss: 0.0494 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0012 - val_loss: 0.0502 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.2, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - loss: 0.0518 - val_loss: 0.0502 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0013 - val_loss: 0.0501 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0013 - val_loss: 0.0496 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0012 - val_loss: 0.0502 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0013 - val_loss: 0.0503 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0013 - val_loss: 0.0502 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0012 - val_loss: 0.0496 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0011 - val_loss: 0.0500 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0012 - val_loss: 0.0509 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0012 - val_loss: 0.0501 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0012 - val_loss: 0.0504 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0012 - val_loss: 0.0503 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0012 - val_loss: 0.0502 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0010 - val_loss: 0.0502 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0011 - val_loss: 0.0500 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0010 - val_loss: 0.0502 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0012 - val_loss: 0.0501 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.2, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - loss: 0.1361 - val_loss: 0.0482 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0021 - val_loss: 0.0496 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0014 - val_loss: 0.0500 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0013 - val_loss: 0.0498 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0013 - val_loss: 0.0495 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0012 - val_loss: 0.0498 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0013 - val_loss: 0.0495 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0012 - val_loss: 0.0499 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0013 - val_loss: 0.0500 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0013 - val_loss: 0.0503 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0013 - val_loss: 0.0500 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.3, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - loss: 0.1518 - val_loss: 0.0236 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.0253 - val_loss: 0.0473 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0069 - val_loss: 0.0484 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.0049 - val_loss: 0.0490 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0036 - val_loss: 0.0483 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0036 - val_loss: 0.0481 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.0033 - val_loss: 0.0484 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0030 - val_loss: 0.0481 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0030 - val_loss: 0.0489 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0031 - val_loss: 0.0487 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0028 - val_loss: 0.0486 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.3, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - loss: 0.2138 - val_loss: 0.0226 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0496 - val_loss: 0.0224 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0258 - val_loss: 0.0385 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0080 - val_loss: 0.0479 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0067 - val_loss: 0.0469 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0052 - val_loss: 0.0474 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0051 - val_loss: 0.0477 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0048 - val_loss: 0.0480 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0042 - val_loss: 0.0481 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0048 - val_loss: 0.0481 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0041 - val_loss: 0.0480 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0043 - val_loss: 0.0481 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.3, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 64ms/step - loss: 0.1863 - val_loss: 0.0127 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0680 - val_loss: 0.0189 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0454 - val_loss: 0.0239 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0237 - val_loss: 0.0314 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0130 - val_loss: 0.0386 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0094 - val_loss: 0.0452 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0078 - val_loss: 0.0479 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0064 - val_loss: 0.0477 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0062 - val_loss: 0.0476 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0061 - val_loss: 0.0479 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0067 - val_loss: 0.0477 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.3, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - loss: 0.0559 - val_loss: 0.0491 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0024 - val_loss: 0.0490 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0018 - val_loss: 0.0502 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.0015 - val_loss: 0.0509 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - loss: 0.0013 - val_loss: 0.0494 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0014 - val_loss: 0.0499 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0012 - val_loss: 0.0504 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0013 - val_loss: 0.0504 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0012 - val_loss: 0.0503 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0013 - val_loss: 0.0495 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0012 - val_loss: 0.0502 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0012 - val_loss: 0.0501 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.3, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - loss: 0.0754 - val_loss: 0.0496 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0029 - val_loss: 0.0502 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0021 - val_loss: 0.0492 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0015 - val_loss: 0.0513 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0018 - val_loss: 0.0500 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0016 - val_loss: 0.0516 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0015 - val_loss: 0.0508 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0013 - val_loss: 0.0506 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0014 - val_loss: 0.0512 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0012 - val_loss: 0.0512 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0011 - val_loss: 0.0504 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0013 - val_loss: 0.0506 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0011 - val_loss: 0.0506 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.3, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 68ms/step - loss: 0.0999 - val_loss: 0.0482 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0037 - val_loss: 0.0472 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0025 - val_loss: 0.0499 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0019 - val_loss: 0.0499 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0017 - val_loss: 0.0506 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0016 - val_loss: 0.0496 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0016 - val_loss: 0.0495 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0013 - val_loss: 0.0502 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0015 - val_loss: 0.0502 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0013 - val_loss: 0.0506 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0014 - val_loss: 0.0505 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0011 - val_loss: 0.0506 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.3, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - loss: 0.0932 - val_loss: 0.0499 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0015 - val_loss: 0.0503 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0017 - val_loss: 0.0501 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0013 - val_loss: 0.0495 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0014 - val_loss: 0.0501 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0011 - val_loss: 0.0508 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0011 - val_loss: 0.0502 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0011 - val_loss: 0.0499 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0012 - val_loss: 0.0499 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0011 - val_loss: 0.0503 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0012 - val_loss: 0.0509 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0013 - val_loss: 0.0501 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0010 - val_loss: 0.0505 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0011 - val_loss: 0.0503 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.3, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - loss: 0.0902 - val_loss: 0.0506 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0017 - val_loss: 0.0501 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0013 - val_loss: 0.0508 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0014 - val_loss: 0.0504 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0011 - val_loss: 0.0501 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0012 - val_loss: 0.0510 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0012 - val_loss: 0.0501 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0012 - val_loss: 0.0505 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0012 - val_loss: 0.0510 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0011 - val_loss: 0.0506 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0012 - val_loss: 0.0506 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0012 - val_loss: 0.0506 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.3, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 65ms/step - loss: 0.0804 - val_loss: 0.0532 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0018 - val_loss: 0.0500 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0014 - val_loss: 0.0507 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0015 - val_loss: 0.0502 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0012 - val_loss: 0.0516 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0013 - val_loss: 0.0505 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0011 - val_loss: 0.0504 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0011 - val_loss: 0.0513 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.0012 - val_loss: 0.0508 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0012 - val_loss: 0.0509 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 9.9958e-04 - val_loss: 0.0505 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0011 - val_loss: 0.0500 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.5, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.1968 - val_loss: 0.0269 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0259 - val_loss: 0.0470 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0092 - val_loss: 0.0479 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0072 - val_loss: 0.0493 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0052 - val_loss: 0.0495 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0051 - val_loss: 0.0495 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0040 - val_loss: 0.0507 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0036 - val_loss: 0.0504 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0031 - val_loss: 0.0505 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0029 - val_loss: 0.0509 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0028 - val_loss: 0.0511 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.5, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - loss: 0.2137 - val_loss: 0.0384 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0835 - val_loss: 0.0279 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0296 - val_loss: 0.0464 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0121 - val_loss: 0.0472 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0087 - val_loss: 0.0474 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0069 - val_loss: 0.0481 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0059 - val_loss: 0.0490 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0053 - val_loss: 0.0489 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0050 - val_loss: 0.0495 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0048 - val_loss: 0.0500 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0040 - val_loss: 0.0496 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0044 - val_loss: 0.0496 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.5, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 65ms/step - loss: 0.2327 - val_loss: 0.0325 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.1091 - val_loss: 0.0288 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0626 - val_loss: 0.0306 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0221 - val_loss: 0.0466 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0123 - val_loss: 0.0476 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0096 - val_loss: 0.0474 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0087 - val_loss: 0.0476 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0073 - val_loss: 0.0473 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0065 - val_loss: 0.0473 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0068 - val_loss: 0.0479 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0068 - val_loss: 0.0482 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0061 - val_loss: 0.0483 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.5, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - loss: 0.0643 - val_loss: 0.0510 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0021 - val_loss: 0.0506 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0014 - val_loss: 0.0505 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0015 - val_loss: 0.0525 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0014 - val_loss: 0.0505 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0013 - val_loss: 0.0516 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0013 - val_loss: 0.0515 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0013 - val_loss: 0.0509 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0012 - val_loss: 0.0506 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0013 - val_loss: 0.0505 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0011 - val_loss: 0.0503 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0012 - val_loss: 0.0505 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0012 - val_loss: 0.0513 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0012 - val_loss: 0.0506 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0011 - val_loss: 0.0511 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0012 - val_loss: 0.0508 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0011 - val_loss: 0.0507 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0012 - val_loss: 0.0512 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0012 - val_loss: 0.0509 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0012 - val_loss: 0.0510 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0014 - val_loss: 0.0508 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.5, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - loss: 0.0912 - val_loss: 0.0476 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0032 - val_loss: 0.0521 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0019 - val_loss: 0.0514 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0017 - val_loss: 0.0515 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0015 - val_loss: 0.0516 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0012 - val_loss: 0.0508 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0014 - val_loss: 0.0504 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0013 - val_loss: 0.0506 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0012 - val_loss: 0.0518 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0012 - val_loss: 0.0507 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0012 - val_loss: 0.0510 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.5, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 68ms/step - loss: 0.1402 - val_loss: 0.0561 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0041 - val_loss: 0.0501 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0022 - val_loss: 0.0513 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0016 - val_loss: 0.0509 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0015 - val_loss: 0.0512 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0014 - val_loss: 0.0514 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0014 - val_loss: 0.0511 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0013 - val_loss: 0.0515 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0013 - val_loss: 0.0514 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0011 - val_loss: 0.0509 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0012 - val_loss: 0.0508 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0014 - val_loss: 0.0510 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.5, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - loss: 0.0436 - val_loss: 0.0504 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0014 - val_loss: 0.0512 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0013 - val_loss: 0.0507 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0015 - val_loss: 0.0513 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0012 - val_loss: 0.0504 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0011 - val_loss: 0.0503 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0015 - val_loss: 0.0509 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0012 - val_loss: 0.0505 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0012 - val_loss: 0.0510 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0012 - val_loss: 0.0505 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0011 - val_loss: 0.0514 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0011 - val_loss: 0.0508 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0013 - val_loss: 0.0510 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0012 - val_loss: 0.0511 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 9.9685e-04 - val_loss: 0.0508 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0010 - val_loss: 0.0508 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.5, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - loss: 0.0695 - val_loss: 0.0516 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0017 - val_loss: 0.0509 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0014 - val_loss: 0.0507 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0014 - val_loss: 0.0512 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0013 - val_loss: 0.0511 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0013 - val_loss: 0.0505 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0014 - val_loss: 0.0502 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0012 - val_loss: 0.0518 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0014 - val_loss: 0.0505 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0013 - val_loss: 0.0506 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0012 - val_loss: 0.0506 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0012 - val_loss: 0.0512 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0013 - val_loss: 0.0507 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0013 - val_loss: 0.0509 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0011 - val_loss: 0.0511 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0012 - val_loss: 0.0508 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0012 - val_loss: 0.0510 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.5, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 66ms/step - loss: 0.0831 - val_loss: 0.0509 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0019 - val_loss: 0.0515 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0015 - val_loss: 0.0509 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0014 - val_loss: 0.0507 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0014 - val_loss: 0.0507 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0013 - val_loss: 0.0523 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0014 - val_loss: 0.0513 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0013 - val_loss: 0.0509 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0011 - val_loss: 0.0515 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0012 - val_loss: 0.0502 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0012 - val_loss: 0.0510 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0013 - val_loss: 0.0504 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0012 - val_loss: 0.0506 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0013 - val_loss: 0.0507 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0011 - val_loss: 0.0511 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0010 - val_loss: 0.0513 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0012 - val_loss: 0.0504 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0012 - val_loss: 0.0508 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0010 - val_loss: 0.0505 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0011 - val_loss: 0.0507 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.2, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.1895 - val_loss: 0.0127 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0372 - val_loss: 0.0187 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0161 - val_loss: 0.0450 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0045 - val_loss: 0.0457 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0034 - val_loss: 0.0426 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0030 - val_loss: 0.0417 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0029 - val_loss: 0.0436 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0023 - val_loss: 0.0428 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0024 - val_loss: 0.0428 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0027 - val_loss: 0.0429 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0023 - val_loss: 0.0432 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.2, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.2018 - val_loss: 0.0065 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0442 - val_loss: 0.0132 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0392 - val_loss: 0.0145 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0251 - val_loss: 0.0176 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0200 - val_loss: 0.0246 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0105 - val_loss: 0.0343 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0060 - val_loss: 0.0409 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0047 - val_loss: 0.0416 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0044 - val_loss: 0.0418 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0041 - val_loss: 0.0412 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0042 - val_loss: 0.0414 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.2, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.2773 - val_loss: 0.0871 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0621 - val_loss: 0.0109 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0460 - val_loss: 0.0143 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0387 - val_loss: 0.0150 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0311 - val_loss: 0.0153 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0241 - val_loss: 0.0166 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0243 - val_loss: 0.0179 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0199 - val_loss: 0.0209 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0156 - val_loss: 0.0226 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0140 - val_loss: 0.0246 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0115 - val_loss: 0.0271 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0105 - val_loss: 0.0287 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.2, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0604 - val_loss: 0.0422 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0016 - val_loss: 0.0472 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0014 - val_loss: 0.0456 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0011 - val_loss: 0.0441 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0010 - val_loss: 0.0450 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0011 - val_loss: 0.0447 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 8.9506e-04 - val_loss: 0.0432 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 9.2716e-04 - val_loss: 0.0442 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 9.8337e-04 - val_loss: 0.0430 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0010 - val_loss: 0.0437 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 9.0437e-04 - val_loss: 0.0419 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 9.6444e-04 - val_loss: 0.0411 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 9.2331e-04 - val_loss: 0.0414 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 9.3692e-04 - val_loss: 0.0420 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 9.2502e-04 - val_loss: 0.0399 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 9.0758e-04 - val_loss: 0.0406 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 8.7131e-04 - val_loss: 0.0394 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 8.5444e-04 - val_loss: 0.0399 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 8.2656e-04 - val_loss: 0.0392 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 8.4139e-04 - val_loss: 0.0383 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 8.7333e-04 - val_loss: 0.0387 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 8.6020e-04 - val_loss: 0.0374 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 7.2254e-04 - val_loss: 0.0354 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 8.0127e-04 - val_loss: 0.0364 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 25/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 6.4683e-04 - val_loss: 0.0355 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 26/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 7.1337e-04 - val_loss: 0.0343 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 27/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 6.8952e-04 - val_loss: 0.0336 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 28/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 6.9501e-04 - val_loss: 0.0318 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 29/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 6.1025e-04 - val_loss: 0.0309 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 30/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 6.9791e-04 - val_loss: 0.0314 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 31/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.9431e-04 - val_loss: 0.0300 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 32/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 6.3690e-04 - val_loss: 0.0296 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 33/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 6.2066e-04 - val_loss: 0.0301 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 34/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.0039e-04 - val_loss: 0.0303 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 35/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.9466e-04 - val_loss: 0.0285 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 36/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.8184e-04 - val_loss: 0.0284 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 37/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.9517e-04 - val_loss: 0.0297 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 38/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 6.4781e-04 - val_loss: 0.0275 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 39/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.7368e-04 - val_loss: 0.0281 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 40/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.0149e-04 - val_loss: 0.0257 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 41/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.3021e-04 - val_loss: 0.0260 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 42/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.9150e-04 - val_loss: 0.0258 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 43/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.0687e-04 - val_loss: 0.0249 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 44/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.7227e-04 - val_loss: 0.0275 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 45/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.2806e-04 - val_loss: 0.0243 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 46/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.3082e-04 - val_loss: 0.0249 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 47/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 4.5204e-04 - val_loss: 0.0270 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 48/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.0028e-04 - val_loss: 0.0266 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 49/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.6649e-04 - val_loss: 0.0262 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 50/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.0579e-04 - val_loss: 0.0256 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 51/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.3446e-04 - val_loss: 0.0258 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 52/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.8579e-04 - val_loss: 0.0253 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 53/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.1337e-04 - val_loss: 0.0246 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 54/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.6068e-04 - val_loss: 0.0247 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 55/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.9731e-04 - val_loss: 0.0250 - learning_rate: 1.5625e-05\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.2, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.1139 - val_loss: 0.0209 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0067 - val_loss: 0.0433 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0016 - val_loss: 0.0446 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0013 - val_loss: 0.0452 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0012 - val_loss: 0.0456 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0011 - val_loss: 0.0457 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0011 - val_loss: 0.0448 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 9.7274e-04 - val_loss: 0.0461 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0010 - val_loss: 0.0453 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0012 - val_loss: 0.0459 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0011 - val_loss: 0.0455 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.2, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.1221 - val_loss: 0.0123 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0180 - val_loss: 0.0400 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0021 - val_loss: 0.0448 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0015 - val_loss: 0.0475 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0013 - val_loss: 0.0462 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0014 - val_loss: 0.0466 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0012 - val_loss: 0.0459 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0011 - val_loss: 0.0460 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0012 - val_loss: 0.0461 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0011 - val_loss: 0.0461 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0011 - val_loss: 0.0466 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.2, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0386 - val_loss: 0.0473 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0012 - val_loss: 0.0466 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0012 - val_loss: 0.0489 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0011 - val_loss: 0.0476 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0012 - val_loss: 0.0452 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0013 - val_loss: 0.0482 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0016 - val_loss: 0.0468 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0011 - val_loss: 0.0456 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0012 - val_loss: 0.0414 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 9.4670e-04 - val_loss: 0.0407 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 8.7486e-04 - val_loss: 0.0388 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 9.1243e-04 - val_loss: 0.0384 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 8.3786e-04 - val_loss: 0.0338 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 6.5959e-04 - val_loss: 0.0321 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.8543e-04 - val_loss: 0.0308 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 7.3398e-04 - val_loss: 0.0288 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 5.6905e-04 - val_loss: 0.0282 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.3980e-04 - val_loss: 0.0290 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.7122e-04 - val_loss: 0.0313 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 4.9694e-04 - val_loss: 0.0285 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 4.7520e-04 - val_loss: 0.0306 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.1472e-04 - val_loss: 0.0282 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.0910e-04 - val_loss: 0.0299 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.1693e-04 - val_loss: 0.0290 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 25/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.7400e-04 - val_loss: 0.0279 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 26/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.2939e-04 - val_loss: 0.0278 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 27/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.6377e-04 - val_loss: 0.0301 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 28/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.1245e-04 - val_loss: 0.0286 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 29/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.7456e-04 - val_loss: 0.0292 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 30/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.8919e-04 - val_loss: 0.0284 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 31/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.3283e-04 - val_loss: 0.0284 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 32/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.1656e-04 - val_loss: 0.0292 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 33/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.7122e-04 - val_loss: 0.0283 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 34/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.2146e-04 - val_loss: 0.0290 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 35/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.4384e-04 - val_loss: 0.0293 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 36/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 2.3395e-04 - val_loss: 0.0288 - learning_rate: 7.8125e-05\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.2, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0492 - val_loss: 0.0494 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0016 - val_loss: 0.0493 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0013 - val_loss: 0.0459 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0011 - val_loss: 0.0462 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0013 - val_loss: 0.0438 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0014 - val_loss: 0.0412 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0011 - val_loss: 0.0413 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 9.8381e-04 - val_loss: 0.0419 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0011 - val_loss: 0.0347 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0011 - val_loss: 0.0366 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 7.6804e-04 - val_loss: 0.0318 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 8.1537e-04 - val_loss: 0.0331 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 8.3570e-04 - val_loss: 0.0281 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 6.7920e-04 - val_loss: 0.0292 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 8.2567e-04 - val_loss: 0.0273 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 5.0383e-04 - val_loss: 0.0279 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 5.9107e-04 - val_loss: 0.0263 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 5.0770e-04 - val_loss: 0.0299 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 5.9482e-04 - val_loss: 0.0278 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 6.0156e-04 - val_loss: 0.0282 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 5.3227e-04 - val_loss: 0.0278 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 5.5714e-04 - val_loss: 0.0290 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3.6834e-04 - val_loss: 0.0274 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 3.3542e-04 - val_loss: 0.0272 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 25/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 4.0563e-04 - val_loss: 0.0266 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 26/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 5.4864e-04 - val_loss: 0.0280 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 27/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3.0530e-04 - val_loss: 0.0265 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.2, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0804 - val_loss: 0.0352 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0023 - val_loss: 0.0461 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0013 - val_loss: 0.0492 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0011 - val_loss: 0.0487 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0011 - val_loss: 0.0490 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0013 - val_loss: 0.0484 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0010 - val_loss: 0.0475 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0012 - val_loss: 0.0480 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0011 - val_loss: 0.0482 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0010 - val_loss: 0.0487 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0011 - val_loss: 0.0484 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.3, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.1550 - val_loss: 0.0211 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0489 - val_loss: 0.0454 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0054 - val_loss: 0.0449 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0036 - val_loss: 0.0460 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0027 - val_loss: 0.0445 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0028 - val_loss: 0.0441 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0025 - val_loss: 0.0439 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0023 - val_loss: 0.0443 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0025 - val_loss: 0.0440 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0021 - val_loss: 0.0441 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0021 - val_loss: 0.0443 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.3, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.1795 - val_loss: 0.0164 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0663 - val_loss: 0.0213 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0455 - val_loss: 0.0223 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0192 - val_loss: 0.0488 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0053 - val_loss: 0.0453 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0049 - val_loss: 0.0460 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0045 - val_loss: 0.0452 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0042 - val_loss: 0.0458 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0039 - val_loss: 0.0453 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0034 - val_loss: 0.0455 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0039 - val_loss: 0.0456 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.3, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.2264 - val_loss: 0.0550 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0771 - val_loss: 0.0230 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0648 - val_loss: 0.0204 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0506 - val_loss: 0.0209 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0309 - val_loss: 0.0262 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0119 - val_loss: 0.0461 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0054 - val_loss: 0.0429 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0048 - val_loss: 0.0432 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0052 - val_loss: 0.0439 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0047 - val_loss: 0.0435 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0043 - val_loss: 0.0435 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0040 - val_loss: 0.0443 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0040 - val_loss: 0.0438 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.3, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0653 - val_loss: 0.0493 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0015 - val_loss: 0.0480 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0013 - val_loss: 0.0480 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0011 - val_loss: 0.0449 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0011 - val_loss: 0.0485 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0012 - val_loss: 0.0466 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0012 - val_loss: 0.0436 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 9.5459e-04 - val_loss: 0.0445 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0011 - val_loss: 0.0463 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 9.9218e-04 - val_loss: 0.0433 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 9.2691e-04 - val_loss: 0.0396 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 7.7371e-04 - val_loss: 0.0371 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 6.9070e-04 - val_loss: 0.0395 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 8.0999e-04 - val_loss: 0.0399 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 8.4021e-04 - val_loss: 0.0389 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 5.6304e-04 - val_loss: 0.0371 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.2662e-04 - val_loss: 0.0363 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.9469e-04 - val_loss: 0.0366 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.1029e-04 - val_loss: 0.0353 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.5080e-04 - val_loss: 0.0356 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 6.2245e-04 - val_loss: 0.0369 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.6187e-04 - val_loss: 0.0329 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 6.8866e-04 - val_loss: 0.0358 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.3829e-04 - val_loss: 0.0384 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 25/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.5290e-04 - val_loss: 0.0356 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 26/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.3285e-04 - val_loss: 0.0360 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 27/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.0121e-04 - val_loss: 0.0353 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 28/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.3181e-04 - val_loss: 0.0370 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 29/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.2801e-04 - val_loss: 0.0363 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 30/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.3575e-04 - val_loss: 0.0359 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 31/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.5761e-04 - val_loss: 0.0350 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 32/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.7986e-04 - val_loss: 0.0362 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.3, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0852 - val_loss: 0.0572 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0022 - val_loss: 0.0485 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0013 - val_loss: 0.0498 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0013 - val_loss: 0.0494 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0012 - val_loss: 0.0502 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0012 - val_loss: 0.0491 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 9.8446e-04 - val_loss: 0.0487 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0011 - val_loss: 0.0484 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0010 - val_loss: 0.0472 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0011 - val_loss: 0.0482 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0010 - val_loss: 0.0487 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0010 - val_loss: 0.0476 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0011 - val_loss: 0.0477 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0010 - val_loss: 0.0468 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0010 - val_loss: 0.0478 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0010 - val_loss: 0.0466 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 9.3943e-04 - val_loss: 0.0460 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0011 - val_loss: 0.0466 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 9.6663e-04 - val_loss: 0.0468 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0010 - val_loss: 0.0463 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0011 - val_loss: 0.0465 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 9.5541e-04 - val_loss: 0.0461 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 9.8298e-04 - val_loss: 0.0463 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 8.9954e-04 - val_loss: 0.0463 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 25/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 9.7625e-04 - val_loss: 0.0461 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 26/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 9.1334e-04 - val_loss: 0.0455 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 27/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 9.3443e-04 - val_loss: 0.0458 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 28/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 9.9586e-04 - val_loss: 0.0452 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 29/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0010 - val_loss: 0.0456 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nEpoch 30/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 9.4915e-04 - val_loss: 0.0456 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 31/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 8.8636e-04 - val_loss: 0.0452 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 32/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 9.2637e-04 - val_loss: 0.0448 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 33/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 9.1566e-04 - val_loss: 0.0452 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 34/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 9.8617e-04 - val_loss: 0.0451 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 35/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 9.8904e-04 - val_loss: 0.0451 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 36/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 9.1747e-04 - val_loss: 0.0456 - learning_rate: 1.5625e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 37/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0010 - val_loss: 0.0456 - learning_rate: 1.5625e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 38/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 9.2574e-04 - val_loss: 0.0451 - learning_rate: 1.5625e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 39/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 9.6442e-04 - val_loss: 0.0451 - learning_rate: 7.8125e-06\b\b\b\b\b\b\b\b\b\b\b\nEpoch 40/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 8.6840e-04 - val_loss: 0.0451 - learning_rate: 7.8125e-06\b\b\b\b\b\b\b\b\b\b\b\nEpoch 41/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 8.9322e-04 - val_loss: 0.0452 - learning_rate: 7.8125e-06\b\b\b\b\b\b\b\b\b\b\b\nEpoch 42/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 9.7379e-04 - val_loss: 0.0452 - learning_rate: 3.9063e-06\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.3, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.1196 - val_loss: 0.0203 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0105 - val_loss: 0.0500 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0015 - val_loss: 0.0511 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0014 - val_loss: 0.0495 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0012 - val_loss: 0.0484 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0012 - val_loss: 0.0494 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0013 - val_loss: 0.0495 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0012 - val_loss: 0.0487 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0013 - val_loss: 0.0495 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0011 - val_loss: 0.0487 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0013 - val_loss: 0.0489 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.3, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0307 - val_loss: 0.0514 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0016 - val_loss: 0.0483 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0013 - val_loss: 0.0475 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0014 - val_loss: 0.0452 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0012 - val_loss: 0.0493 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0011 - val_loss: 0.0455 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0011 - val_loss: 0.0403 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0011 - val_loss: 0.0396 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 9.1823e-04 - val_loss: 0.0394 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 8.8817e-04 - val_loss: 0.0415 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0011 - val_loss: 0.0421 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 8.7419e-04 - val_loss: 0.0444 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 8.2732e-04 - val_loss: 0.0356 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 6.4644e-04 - val_loss: 0.0378 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.8461e-04 - val_loss: 0.0369 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 4.2927e-04 - val_loss: 0.0359 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 5.1677e-04 - val_loss: 0.0376 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 5.3302e-04 - val_loss: 0.0384 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.7593e-04 - val_loss: 0.0403 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 4.0522e-04 - val_loss: 0.0388 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.0886e-04 - val_loss: 0.0396 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.3163e-04 - val_loss: 0.0394 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 5.0588e-04 - val_loss: 0.0405 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.3, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0489 - val_loss: 0.0499 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0012 - val_loss: 0.0475 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0012 - val_loss: 0.0472 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0013 - val_loss: 0.0481 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0013 - val_loss: 0.0480 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0013 - val_loss: 0.0466 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0012 - val_loss: 0.0485 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0011 - val_loss: 0.0461 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0011 - val_loss: 0.0452 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 9.4136e-04 - val_loss: 0.0428 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0010 - val_loss: 0.0415 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 9.9033e-04 - val_loss: 0.0405 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 8.5282e-04 - val_loss: 0.0389 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 6.7874e-04 - val_loss: 0.0374 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 6.9713e-04 - val_loss: 0.0409 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 7.1656e-04 - val_loss: 0.0384 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 7.5780e-04 - val_loss: 0.0409 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 6.6482e-04 - val_loss: 0.0376 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 5.4120e-04 - val_loss: 0.0417 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 6.4902e-04 - val_loss: 0.0380 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 5.3885e-04 - val_loss: 0.0386 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 4.6930e-04 - val_loss: 0.0381 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 4.5447e-04 - val_loss: 0.0399 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 4.1826e-04 - val_loss: 0.0394 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.3, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0682 - val_loss: 0.0466 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0013 - val_loss: 0.0496 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0012 - val_loss: 0.0499 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0011 - val_loss: 0.0498 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0012 - val_loss: 0.0496 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0012 - val_loss: 0.0500 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0012 - val_loss: 0.0497 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0011 - val_loss: 0.0499 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0012 - val_loss: 0.0498 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0011 - val_loss: 0.0489 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0010 - val_loss: 0.0484 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.5, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.1605 - val_loss: 0.0341 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0249 - val_loss: 0.0486 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0054 - val_loss: 0.0474 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0041 - val_loss: 0.0481 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0035 - val_loss: 0.0482 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0034 - val_loss: 0.0479 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0031 - val_loss: 0.0490 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0026 - val_loss: 0.0483 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0027 - val_loss: 0.0481 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0025 - val_loss: 0.0485 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0022 - val_loss: 0.0485 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.5, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.2544 - val_loss: 0.0525 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.1154 - val_loss: 0.0428 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0640 - val_loss: 0.0442 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0085 - val_loss: 0.0488 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0066 - val_loss: 0.0468 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0052 - val_loss: 0.0471 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0046 - val_loss: 0.0476 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0042 - val_loss: 0.0475 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0041 - val_loss: 0.0480 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0042 - val_loss: 0.0478 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0035 - val_loss: 0.0475 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0036 - val_loss: 0.0476 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.5, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.2492 - val_loss: 0.0980 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1221 - val_loss: 0.0546 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0992 - val_loss: 0.0378 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0605 - val_loss: 0.0358 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0100 - val_loss: 0.0475 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0061 - val_loss: 0.0478 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0053 - val_loss: 0.0469 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0047 - val_loss: 0.0475 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0041 - val_loss: 0.0473 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0043 - val_loss: 0.0477 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0044 - val_loss: 0.0472 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0040 - val_loss: 0.0475 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0041 - val_loss: 0.0481 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0037 - val_loss: 0.0481 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.5, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0656 - val_loss: 0.0505 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0013 - val_loss: 0.0502 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0013 - val_loss: 0.0495 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0012 - val_loss: 0.0487 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0011 - val_loss: 0.0482 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0016 - val_loss: 0.0503 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0011 - val_loss: 0.0488 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0010 - val_loss: 0.0517 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 9.3535e-04 - val_loss: 0.0501 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0010 - val_loss: 0.0491 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0011 - val_loss: 0.0503 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 8.7448e-04 - val_loss: 0.0520 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 7.9413e-04 - val_loss: 0.0502 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 7.9311e-04 - val_loss: 0.0509 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 7.8307e-04 - val_loss: 0.0506 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.5, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.1189 - val_loss: 0.0438 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0023 - val_loss: 0.0503 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0013 - val_loss: 0.0494 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0013 - val_loss: 0.0496 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0011 - val_loss: 0.0497 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0012 - val_loss: 0.0503 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0011 - val_loss: 0.0502 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0013 - val_loss: 0.0502 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0011 - val_loss: 0.0498 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0011 - val_loss: 0.0498 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0010 - val_loss: 0.0504 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.5, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 0.1364 - val_loss: 0.0639 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0049 - val_loss: 0.0520 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0015 - val_loss: 0.0505 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0012 - val_loss: 0.0498 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0011 - val_loss: 0.0491 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0012 - val_loss: 0.0496 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0013 - val_loss: 0.0509 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0012 - val_loss: 0.0504 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0012 - val_loss: 0.0503 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0011 - val_loss: 0.0500 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0012 - val_loss: 0.0507 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0012 - val_loss: 0.0495 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0011 - val_loss: 0.0501 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0013 - val_loss: 0.0501 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0010 - val_loss: 0.0498 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.5, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0412 - val_loss: 0.0514 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0014 - val_loss: 0.0504 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0011 - val_loss: 0.0509 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0012 - val_loss: 0.0498 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0013 - val_loss: 0.0515 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0014 - val_loss: 0.0512 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0013 - val_loss: 0.0493 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0012 - val_loss: 0.0504 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0014 - val_loss: 0.0504 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0012 - val_loss: 0.0476 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0014 - val_loss: 0.0501 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0013 - val_loss: 0.0499 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0011 - val_loss: 0.0516 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0012 - val_loss: 0.0512 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 9.4732e-04 - val_loss: 0.0501 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0010 - val_loss: 0.0529 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 9.5959e-04 - val_loss: 0.0519 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 7.8173e-04 - val_loss: 0.0533 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 6.8675e-04 - val_loss: 0.0530 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 6.9187e-04 - val_loss: 0.0552 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.5, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0650 - val_loss: 0.0488 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0014 - val_loss: 0.0511 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0011 - val_loss: 0.0505 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0014 - val_loss: 0.0516 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0012 - val_loss: 0.0509 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0012 - val_loss: 0.0504 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0011 - val_loss: 0.0495 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0012 - val_loss: 0.0505 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0011 - val_loss: 0.0507 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0012 - val_loss: 0.0497 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0012 - val_loss: 0.0500 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.5, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0793 - val_loss: 0.0534 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0014 - val_loss: 0.0504 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0013 - val_loss: 0.0510 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0013 - val_loss: 0.0502 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0012 - val_loss: 0.0511 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0012 - val_loss: 0.0493 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0013 - val_loss: 0.0513 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0010 - val_loss: 0.0500 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0012 - val_loss: 0.0503 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0011 - val_loss: 0.0504 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0012 - val_loss: 0.0502 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0011 - val_loss: 0.0497 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0011 - val_loss: 0.0502 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0010 - val_loss: 0.0499 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0011 - val_loss: 0.0500 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 9.9960e-04 - val_loss: 0.0503 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.2, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 0.1312 - val_loss: 0.0161 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0226 - val_loss: 0.0445 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0038 - val_loss: 0.0452 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0030 - val_loss: 0.0450 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0025 - val_loss: 0.0460 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0025 - val_loss: 0.0456 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0025 - val_loss: 0.0466 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0018 - val_loss: 0.0464 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0021 - val_loss: 0.0465 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0019 - val_loss: 0.0466 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0019 - val_loss: 0.0465 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.2, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - loss: 0.1502 - val_loss: 0.0197 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0426 - val_loss: 0.0158 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0235 - val_loss: 0.0266 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0077 - val_loss: 0.0478 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0040 - val_loss: 0.0448 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0037 - val_loss: 0.0462 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0032 - val_loss: 0.0457 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0030 - val_loss: 0.0460 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0029 - val_loss: 0.0461 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0027 - val_loss: 0.0457 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0024 - val_loss: 0.0457 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0024 - val_loss: 0.0462 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.2, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - loss: 0.1709 - val_loss: 0.0054 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0485 - val_loss: 0.0127 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0416 - val_loss: 0.0154 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0278 - val_loss: 0.0192 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0153 - val_loss: 0.0242 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0104 - val_loss: 0.0344 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0055 - val_loss: 0.0430 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0040 - val_loss: 0.0435 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0039 - val_loss: 0.0436 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0036 - val_loss: 0.0440 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0034 - val_loss: 0.0442 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.2, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 0.0471 - val_loss: 0.0463 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0016 - val_loss: 0.0484 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0015 - val_loss: 0.0473 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0012 - val_loss: 0.0486 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0012 - val_loss: 0.0443 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0012 - val_loss: 0.0470 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0013 - val_loss: 0.0458 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0012 - val_loss: 0.0439 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0011 - val_loss: 0.0460 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0011 - val_loss: 0.0434 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0011 - val_loss: 0.0442 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.0011 - val_loss: 0.0436 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0011 - val_loss: 0.0442 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0010 - val_loss: 0.0415 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 9.8341e-04 - val_loss: 0.0405 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 9.9279e-04 - val_loss: 0.0405 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 9.5064e-04 - val_loss: 0.0387 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 9.1994e-04 - val_loss: 0.0380 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 8.6845e-04 - val_loss: 0.0353 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0011 - val_loss: 0.0366 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 8.2097e-04 - val_loss: 0.0356 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 7.8010e-04 - val_loss: 0.0355 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 8.2219e-04 - val_loss: 0.0343 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 7.7462e-04 - val_loss: 0.0343 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 25/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 8.1059e-04 - val_loss: 0.0344 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 26/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 7.6538e-04 - val_loss: 0.0328 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 27/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 7.4072e-04 - val_loss: 0.0331 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 28/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 7.5691e-04 - val_loss: 0.0309 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 29/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 8.3430e-04 - val_loss: 0.0331 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 30/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 6.7986e-04 - val_loss: 0.0308 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 31/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 7.2673e-04 - val_loss: 0.0318 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 32/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 7.3739e-04 - val_loss: 0.0310 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 33/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 6.2390e-04 - val_loss: 0.0311 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 34/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 5.6885e-04 - val_loss: 0.0283 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 35/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 7.4190e-04 - val_loss: 0.0300 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 36/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 6.2280e-04 - val_loss: 0.0308 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 37/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 6.3171e-04 - val_loss: 0.0297 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 38/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 6.8226e-04 - val_loss: 0.0310 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 39/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 6.4465e-04 - val_loss: 0.0304 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 40/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 5.6987e-04 - val_loss: 0.0292 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 41/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 5.5902e-04 - val_loss: 0.0295 - learning_rate: 1.5625e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 42/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 5.0652e-04 - val_loss: 0.0294 - learning_rate: 1.5625e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 43/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 6.2026e-04 - val_loss: 0.0292 - learning_rate: 1.5625e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 44/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 7.8593e-04 - val_loss: 0.0297 - learning_rate: 7.8125e-06\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.2, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - loss: 0.0735 - val_loss: 0.0480 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0022 - val_loss: 0.0482 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0019 - val_loss: 0.0488 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0015 - val_loss: 0.0481 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0013 - val_loss: 0.0480 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0013 - val_loss: 0.0474 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0013 - val_loss: 0.0482 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0012 - val_loss: 0.0477 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0013 - val_loss: 0.0463 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0012 - val_loss: 0.0479 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0012 - val_loss: 0.0479 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.0013 - val_loss: 0.0473 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0011 - val_loss: 0.0462 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0011 - val_loss: 0.0456 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0013 - val_loss: 0.0463 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0012 - val_loss: 0.0466 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0010 - val_loss: 0.0458 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0010 - val_loss: 0.0458 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0010 - val_loss: 0.0460 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.0011 - val_loss: 0.0460 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0011 - val_loss: 0.0455 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 9.4130e-04 - val_loss: 0.0456 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0012 - val_loss: 0.0458 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0010 - val_loss: 0.0455 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 25/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0011 - val_loss: 0.0453 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\nEpoch 26/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0011 - val_loss: 0.0454 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 27/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 9.0864e-04 - val_loss: 0.0460 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 28/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0011 - val_loss: 0.0450 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\nEpoch 29/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0010 - val_loss: 0.0456 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 30/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0011 - val_loss: 0.0450 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\nEpoch 31/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0011 - val_loss: 0.0453 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\nEpoch 32/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 9.6208e-04 - val_loss: 0.0448 - learning_rate: 1.5625e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 33/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0010 - val_loss: 0.0452 - learning_rate: 1.5625e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 34/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 9.6095e-04 - val_loss: 0.0451 - learning_rate: 1.5625e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 35/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 9.7261e-04 - val_loss: 0.0453 - learning_rate: 1.5625e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 36/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0011 - val_loss: 0.0450 - learning_rate: 7.8125e-06\b\b\b\b\b\b\b\nEpoch 37/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0011 - val_loss: 0.0451 - learning_rate: 7.8125e-06\b\b\b\b\b\b\b\nEpoch 38/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0011 - val_loss: 0.0450 - learning_rate: 7.8125e-06\b\b\b\b\b\b\b\nEpoch 39/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0012 - val_loss: 0.0451 - learning_rate: 3.9063e-06\b\b\b\b\b\b\b\b\b\b\b\nEpoch 40/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 9.4828e-04 - val_loss: 0.0452 - learning_rate: 3.9063e-06\b\b\b\b\b\b\b\b\b\b\b\nEpoch 41/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0010 - val_loss: 0.0451 - learning_rate: 3.9063e-06\b\b\b\b\b\b\b\nEpoch 42/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0011 - val_loss: 0.0450 - learning_rate: 1.9531e-06\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.2, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - loss: 0.0823 - val_loss: 0.0244 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0070 - val_loss: 0.0534 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0018 - val_loss: 0.0485 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0015 - val_loss: 0.0480 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0016 - val_loss: 0.0481 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0013 - val_loss: 0.0483 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0014 - val_loss: 0.0478 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0014 - val_loss: 0.0480 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0012 - val_loss: 0.0478 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0013 - val_loss: 0.0485 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0013 - val_loss: 0.0480 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.2, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 0.0572 - val_loss: 0.0484 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0013 - val_loss: 0.0484 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0014 - val_loss: 0.0480 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0012 - val_loss: 0.0482 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0013 - val_loss: 0.0480 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0012 - val_loss: 0.0504 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0014 - val_loss: 0.0491 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0014 - val_loss: 0.0493 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0011 - val_loss: 0.0485 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0012 - val_loss: 0.0482 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0010 - val_loss: 0.0471 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0010 - val_loss: 0.0464 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0011 - val_loss: 0.0461 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0011 - val_loss: 0.0460 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 9.3263e-04 - val_loss: 0.0450 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0012 - val_loss: 0.0436 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 8.6557e-04 - val_loss: 0.0391 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 9.2708e-04 - val_loss: 0.0429 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 9.0646e-04 - val_loss: 0.0344 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 8.8037e-04 - val_loss: 0.0478 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 9.9961e-04 - val_loss: 0.0321 - learning_rate: 0.0012\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 7.4054e-04 - val_loss: 0.0335 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 6.7186e-04 - val_loss: 0.0310 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 7.6099e-04 - val_loss: 0.0353 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 25/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 5.3247e-04 - val_loss: 0.0373 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 26/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 5.1857e-04 - val_loss: 0.0348 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 27/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 6.0082e-04 - val_loss: 0.0344 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 28/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 4.9124e-04 - val_loss: 0.0291 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 29/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 5.6008e-04 - val_loss: 0.0319 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 30/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 4.3162e-04 - val_loss: 0.0328 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 31/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 4.4054e-04 - val_loss: 0.0330 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 32/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 3.3615e-04 - val_loss: 0.0317 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 33/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 3.3192e-04 - val_loss: 0.0309 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 34/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 4.2865e-04 - val_loss: 0.0299 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 35/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 3.3901e-04 - val_loss: 0.0324 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 36/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 3.5393e-04 - val_loss: 0.0308 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 37/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 3.7960e-04 - val_loss: 0.0301 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 38/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 3.0808e-04 - val_loss: 0.0304 - learning_rate: 7.8125e-05\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.2, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - loss: 0.1134 - val_loss: 0.0436 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0019 - val_loss: 0.0497 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0013 - val_loss: 0.0491 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0013 - val_loss: 0.0497 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0013 - val_loss: 0.0498 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0011 - val_loss: 0.0493 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0013 - val_loss: 0.0499 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0013 - val_loss: 0.0491 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0011 - val_loss: 0.0493 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0012 - val_loss: 0.0493 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.0012 - val_loss: 0.0495 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.2, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - loss: 0.1118 - val_loss: 0.0446 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0018 - val_loss: 0.0501 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0015 - val_loss: 0.0485 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0014 - val_loss: 0.0493 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0012 - val_loss: 0.0491 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0011 - val_loss: 0.0495 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0014 - val_loss: 0.0493 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0012 - val_loss: 0.0494 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0012 - val_loss: 0.0493 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0012 - val_loss: 0.0491 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0013 - val_loss: 0.0492 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.3, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 31ms/step - loss: 0.1362 - val_loss: 0.0206 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0221 - val_loss: 0.0458 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0049 - val_loss: 0.0479 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0036 - val_loss: 0.0485 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0029 - val_loss: 0.0475 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0027 - val_loss: 0.0471 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0024 - val_loss: 0.0472 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0023 - val_loss: 0.0474 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0026 - val_loss: 0.0476 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0021 - val_loss: 0.0476 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0023 - val_loss: 0.0475 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.3, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - loss: 0.1811 - val_loss: 0.0310 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0537 - val_loss: 0.0210 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0226 - val_loss: 0.0502 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.0052 - val_loss: 0.0467 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.0037 - val_loss: 0.0479 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0033 - val_loss: 0.0476 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0035 - val_loss: 0.0461 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0035 - val_loss: 0.0476 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0033 - val_loss: 0.0471 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0032 - val_loss: 0.0477 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0028 - val_loss: 0.0474 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0030 - val_loss: 0.0474 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.3, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - loss: 0.2166 - val_loss: 0.0100 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0738 - val_loss: 0.0209 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0512 - val_loss: 0.0222 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0335 - val_loss: 0.0283 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0125 - val_loss: 0.0391 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0062 - val_loss: 0.0473 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0052 - val_loss: 0.0474 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0050 - val_loss: 0.0470 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0047 - val_loss: 0.0471 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0043 - val_loss: 0.0476 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0046 - val_loss: 0.0474 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.3, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 0.0571 - val_loss: 0.0494 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0020 - val_loss: 0.0510 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0017 - val_loss: 0.0508 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0014 - val_loss: 0.0512 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0014 - val_loss: 0.0490 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0013 - val_loss: 0.0507 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0013 - val_loss: 0.0482 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0012 - val_loss: 0.0497 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0012 - val_loss: 0.0495 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0012 - val_loss: 0.0491 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0013 - val_loss: 0.0495 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0012 - val_loss: 0.0490 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0011 - val_loss: 0.0493 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0012 - val_loss: 0.0492 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0010 - val_loss: 0.0477 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0011 - val_loss: 0.0476 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0011 - val_loss: 0.0474 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0010 - val_loss: 0.0469 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0011 - val_loss: 0.0472 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0012 - val_loss: 0.0488 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0011 - val_loss: 0.0479 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0012 - val_loss: 0.0473 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 9.7550e-04 - val_loss: 0.0474 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0010 - val_loss: 0.0480 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nEpoch 25/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0010 - val_loss: 0.0469 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 26/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0010 - val_loss: 0.0471 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 27/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 9.8785e-04 - val_loss: 0.0470 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 28/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0011 - val_loss: 0.0470 - learning_rate: 1.5625e-05\b\b\b\b\b\b\b\nEpoch 29/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 9.9946e-04 - val_loss: 0.0464 - learning_rate: 1.5625e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 30/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0010 - val_loss: 0.0466 - learning_rate: 1.5625e-05\b\b\b\b\b\b\b\nEpoch 31/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 9.1611e-04 - val_loss: 0.0463 - learning_rate: 1.5625e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 32/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 9.5605e-04 - val_loss: 0.0465 - learning_rate: 1.5625e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 33/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0010 - val_loss: 0.0462 - learning_rate: 1.5625e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 34/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0010 - val_loss: 0.0460 - learning_rate: 1.5625e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 35/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0011 - val_loss: 0.0463 - learning_rate: 1.5625e-05\b\b\b\b\b\b\b\nEpoch 36/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 9.8473e-04 - val_loss: 0.0461 - learning_rate: 1.5625e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 37/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 9.9178e-04 - val_loss: 0.0464 - learning_rate: 1.5625e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 38/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 8.9679e-04 - val_loss: 0.0462 - learning_rate: 7.8125e-06\b\b\b\b\b\b\b\b\b\b\b\nEpoch 39/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 9.6346e-04 - val_loss: 0.0462 - learning_rate: 7.8125e-06\b\b\b\b\b\b\b\b\b\b\b\nEpoch 40/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 9.2029e-04 - val_loss: 0.0458 - learning_rate: 7.8125e-06\b\b\b\b\b\b\b\b\b\b\b\nEpoch 41/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 9.7297e-04 - val_loss: 0.0457 - learning_rate: 7.8125e-06\b\b\b\b\b\b\b\b\b\b\b\nEpoch 42/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 9.5207e-04 - val_loss: 0.0462 - learning_rate: 7.8125e-06\b\b\b\b\b\b\b\b\b\b\b\nEpoch 43/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 9.7410e-04 - val_loss: 0.0462 - learning_rate: 7.8125e-06\b\b\b\b\b\b\b\b\b\b\b\nEpoch 44/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 9.4728e-04 - val_loss: 0.0458 - learning_rate: 3.9063e-06\b\b\b\b\b\b\b\b\b\b\b\nEpoch 45/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0010 - val_loss: 0.0457 - learning_rate: 3.9063e-06\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 46/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0010 - val_loss: 0.0458 - learning_rate: 3.9063e-06\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 47/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0010 - val_loss: 0.0457 - learning_rate: 3.9063e-06\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 48/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0010 - val_loss: 0.0457 - learning_rate: 3.9063e-06\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 49/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0010 - val_loss: 0.0456 - learning_rate: 1.9531e-06\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 50/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 8.3563e-04 - val_loss: 0.0457 - learning_rate: 1.9531e-06\b\b\b\b\b\b\b\b\b\b\b\nEpoch 51/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0010 - val_loss: 0.0454 - learning_rate: 1.9531e-06\b\b\b\b\b\b\b\nEpoch 52/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 9.9047e-04 - val_loss: 0.0458 - learning_rate: 1.9531e-06\b\b\b\b\b\b\b\b\b\b\b\nEpoch 53/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 9.3926e-04 - val_loss: 0.0456 - learning_rate: 1.9531e-06\b\b\b\b\b\b\b\b\b\b\b\nEpoch 54/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 9.3414e-04 - val_loss: 0.0457 - learning_rate: 1.9531e-06\b\b\b\b\b\b\b\b\b\b\b\nEpoch 55/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 9.2370e-04 - val_loss: 0.0457 - learning_rate: 1.0000e-06\b\b\b\b\b\b\b\b\b\b\b\nEpoch 56/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 9.3862e-04 - val_loss: 0.0458 - learning_rate: 1.0000e-06\b\b\b\b\b\b\b\b\b\b\b\nEpoch 57/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 9.3494e-04 - val_loss: 0.0458 - learning_rate: 1.0000e-06\b\b\b\b\b\b\b\b\b\b\b\nEpoch 58/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0011 - val_loss: 0.0458 - learning_rate: 1.0000e-06\b\b\b\b\b\b\b\nEpoch 59/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 9.1066e-04 - val_loss: 0.0457 - learning_rate: 1.0000e-06\b\b\b\b\b\b\b\b\b\b\b\nEpoch 60/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 9.2161e-04 - val_loss: 0.0457 - learning_rate: 1.0000e-06\b\b\b\b\b\b\b\b\b\b\b\nEpoch 61/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 9.6366e-04 - val_loss: 0.0456 - learning_rate: 1.0000e-06\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.3, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 46ms/step - loss: 0.0864 - val_loss: 0.0505 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0023 - val_loss: 0.0494 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0016 - val_loss: 0.0494 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0015 - val_loss: 0.0475 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0016 - val_loss: 0.0483 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.0012 - val_loss: 0.0486 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0013 - val_loss: 0.0492 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0012 - val_loss: 0.0477 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0014 - val_loss: 0.0491 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0011 - val_loss: 0.0484 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0013 - val_loss: 0.0488 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.0013 - val_loss: 0.0485 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0011 - val_loss: 0.0479 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0011 - val_loss: 0.0484 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.3, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - loss: 0.1059 - val_loss: 0.0406 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0036 - val_loss: 0.0479 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0018 - val_loss: 0.0493 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0016 - val_loss: 0.0488 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0016 - val_loss: 0.0496 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0014 - val_loss: 0.0491 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0015 - val_loss: 0.0491 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0013 - val_loss: 0.0490 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0014 - val_loss: 0.0488 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0014 - val_loss: 0.0490 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0016 - val_loss: 0.0489 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.3, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 0.0552 - val_loss: 0.0492 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0015 - val_loss: 0.0508 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0014 - val_loss: 0.0495 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0012 - val_loss: 0.0505 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0015 - val_loss: 0.0495 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0013 - val_loss: 0.0500 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0011 - val_loss: 0.0492 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0011 - val_loss: 0.0502 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0012 - val_loss: 0.0496 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0011 - val_loss: 0.0487 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0013 - val_loss: 0.0493 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0011 - val_loss: 0.0497 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0011 - val_loss: 0.0504 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0011 - val_loss: 0.0474 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0012 - val_loss: 0.0486 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0011 - val_loss: 0.0484 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0010 - val_loss: 0.0480 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0012 - val_loss: 0.0491 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0011 - val_loss: 0.0479 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 9.9905e-04 - val_loss: 0.0474 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0011 - val_loss: 0.0470 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0011 - val_loss: 0.0472 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0011 - val_loss: 0.0473 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0011 - val_loss: 0.0475 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 25/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 9.4345e-04 - val_loss: 0.0468 - learning_rate: 7.8125e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 26/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 9.9096e-04 - val_loss: 0.0470 - learning_rate: 7.8125e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 27/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0010 - val_loss: 0.0469 - learning_rate: 7.8125e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 28/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 9.6505e-04 - val_loss: 0.0462 - learning_rate: 7.8125e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 29/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0010 - val_loss: 0.0464 - learning_rate: 7.8125e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 30/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 9.1537e-04 - val_loss: 0.0468 - learning_rate: 7.8125e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 31/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0011 - val_loss: 0.0470 - learning_rate: 7.8125e-05\b\b\b\b\b\b\b\nEpoch 32/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 9.8221e-04 - val_loss: 0.0466 - learning_rate: 3.9062e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 33/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 8.9597e-04 - val_loss: 0.0469 - learning_rate: 3.9062e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 34/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - loss: 9.8942e-04 - val_loss: 0.0457 - learning_rate: 3.9062e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 35/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0010 - val_loss: 0.0461 - learning_rate: 3.9062e-05\b\b\b\b\b\b\b\nEpoch 36/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0011 - val_loss: 0.0461 - learning_rate: 3.9062e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 37/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0011 - val_loss: 0.0463 - learning_rate: 3.9062e-05\b\b\b\b\b\b\b\nEpoch 38/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 9.5641e-04 - val_loss: 0.0454 - learning_rate: 1.9531e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 39/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 9.6111e-04 - val_loss: 0.0458 - learning_rate: 1.9531e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 40/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 9.0840e-04 - val_loss: 0.0459 - learning_rate: 1.9531e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 41/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 9.7214e-04 - val_loss: 0.0462 - learning_rate: 1.9531e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 42/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0010 - val_loss: 0.0462 - learning_rate: 9.7656e-06\b\b\b\b\b\b\b\nEpoch 43/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 9.5537e-04 - val_loss: 0.0458 - learning_rate: 9.7656e-06\b\b\b\b\b\b\b\b\b\b\b\nEpoch 44/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0010 - val_loss: 0.0456 - learning_rate: 9.7656e-06\b\b\b\b\b\b\b\nEpoch 45/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 8.7885e-04 - val_loss: 0.0457 - learning_rate: 4.8828e-06\b\b\b\b\b\b\b\b\b\b\b\nEpoch 46/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 8.5042e-04 - val_loss: 0.0456 - learning_rate: 4.8828e-06\b\b\b\b\b\b\b\b\b\b\b\nEpoch 47/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 9.9896e-04 - val_loss: 0.0458 - learning_rate: 4.8828e-06\b\b\b\b\b\b\b\b\b\b\b\nEpoch 48/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 9.9308e-04 - val_loss: 0.0457 - learning_rate: 2.4414e-06\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.3, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - loss: 0.1929 - val_loss: 0.0515 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0018 - val_loss: 0.0501 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.0015 - val_loss: 0.0488 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0015 - val_loss: 0.0502 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0014 - val_loss: 0.0506 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.0013 - val_loss: 0.0493 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.0012 - val_loss: 0.0500 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0488 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.0013 - val_loss: 0.0495 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0012 - val_loss: 0.0499 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.0012 - val_loss: 0.0500 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0012 - val_loss: 0.0502 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0012 - val_loss: 0.0500 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0011 - val_loss: 0.0498 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0012 - val_loss: 0.0496 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0012 - val_loss: 0.0494 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0011 - val_loss: 0.0491 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0012 - val_loss: 0.0498 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.3, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 0.1471 - val_loss: 0.0440 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0023 - val_loss: 0.0500 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0014 - val_loss: 0.0494 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0013 - val_loss: 0.0489 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0012 - val_loss: 0.0498 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0012 - val_loss: 0.0495 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0012 - val_loss: 0.0495 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0013 - val_loss: 0.0497 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0012 - val_loss: 0.0499 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0012 - val_loss: 0.0497 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0013 - val_loss: 0.0499 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.5, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 0.1699 - val_loss: 0.0365 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0121 - val_loss: 0.0477 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0060 - val_loss: 0.0492 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0044 - val_loss: 0.0492 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0042 - val_loss: 0.0489 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0038 - val_loss: 0.0499 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0031 - val_loss: 0.0499 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0030 - val_loss: 0.0500 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0026 - val_loss: 0.0501 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0027 - val_loss: 0.0500 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0027 - val_loss: 0.0503 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.5, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 46ms/step - loss: 0.2020 - val_loss: 0.0578 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0885 - val_loss: 0.0398 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0121 - val_loss: 0.0468 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0069 - val_loss: 0.0481 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0062 - val_loss: 0.0487 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0046 - val_loss: 0.0487 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0045 - val_loss: 0.0485 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0044 - val_loss: 0.0493 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0042 - val_loss: 0.0483 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0042 - val_loss: 0.0485 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0039 - val_loss: 0.0492 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.0038 - val_loss: 0.0492 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.5, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - loss: 0.2424 - val_loss: 0.0341 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.1099 - val_loss: 0.0406 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0646 - val_loss: 0.0330 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0178 - val_loss: 0.0522 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0081 - val_loss: 0.0481 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0069 - val_loss: 0.0494 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0060 - val_loss: 0.0486 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0055 - val_loss: 0.0489 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0048 - val_loss: 0.0489 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0048 - val_loss: 0.0486 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0045 - val_loss: 0.0494 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0046 - val_loss: 0.0492 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0043 - val_loss: 0.0490 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.5, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 0.0652 - val_loss: 0.0506 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0020 - val_loss: 0.0498 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0020 - val_loss: 0.0514 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - loss: 0.0016 - val_loss: 0.0537 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0014 - val_loss: 0.0503 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0012 - val_loss: 0.0503 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0012 - val_loss: 0.0506 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0013 - val_loss: 0.0507 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0012 - val_loss: 0.0503 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0010 - val_loss: 0.0517 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0013 - val_loss: 0.0504 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0012 - val_loss: 0.0507 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.5, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - loss: 0.0978 - val_loss: 0.0482 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0023 - val_loss: 0.0523 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.0020 - val_loss: 0.0503 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.0016 - val_loss: 0.0509 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.0017 - val_loss: 0.0506 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0013 - val_loss: 0.0496 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0015 - val_loss: 0.0507 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0013 - val_loss: 0.0500 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0013 - val_loss: 0.0508 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0012 - val_loss: 0.0496 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0012 - val_loss: 0.0502 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.5, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - loss: 0.1268 - val_loss: 0.0522 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0030 - val_loss: 0.0515 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0020 - val_loss: 0.0507 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0019 - val_loss: 0.0507 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0015 - val_loss: 0.0506 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0015 - val_loss: 0.0505 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0014 - val_loss: 0.0506 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - loss: 0.0014 - val_loss: 0.0501 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0012 - val_loss: 0.0504 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0013 - val_loss: 0.0509 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0015 - val_loss: 0.0508 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0013 - val_loss: 0.0503 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0013 - val_loss: 0.0507 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0013 - val_loss: 0.0507 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0013 - val_loss: 0.0508 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0012 - val_loss: 0.0500 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0011 - val_loss: 0.0504 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0012 - val_loss: 0.0503 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0013 - val_loss: 0.0507 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0012 - val_loss: 0.0503 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0011 - val_loss: 0.0504 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0012 - val_loss: 0.0504 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0011 - val_loss: 0.0505 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0012 - val_loss: 0.0505 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\nEpoch 25/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0012 - val_loss: 0.0505 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\nEpoch 26/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0010 - val_loss: 0.0504 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.5, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 0.0571 - val_loss: 0.0522 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0017 - val_loss: 0.0515 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0015 - val_loss: 0.0512 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0013 - val_loss: 0.0529 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0012 - val_loss: 0.0519 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0013 - val_loss: 0.0499 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0017 - val_loss: 0.0499 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0014 - val_loss: 0.0506 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0013 - val_loss: 0.0514 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0013 - val_loss: 0.0510 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0012 - val_loss: 0.0502 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0012 - val_loss: 0.0503 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0012 - val_loss: 0.0503 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0014 - val_loss: 0.0501 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0013 - val_loss: 0.0510 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0012 - val_loss: 0.0509 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0012 - val_loss: 0.0510 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.5, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.1024 - val_loss: 0.0506 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0019 - val_loss: 0.0507 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0016 - val_loss: 0.0507 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0013 - val_loss: 0.0507 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0013 - val_loss: 0.0499 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0012 - val_loss: 0.0502 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0013 - val_loss: 0.0510 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0012 - val_loss: 0.0500 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0013 - val_loss: 0.0508 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0013 - val_loss: 0.0509 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0011 - val_loss: 0.0501 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.0013 - val_loss: 0.0506 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0011 - val_loss: 0.0505 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0011 - val_loss: 0.0506 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0011 - val_loss: 0.0503 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.5, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - loss: 0.1768 - val_loss: 0.0562 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0024 - val_loss: 0.0504 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0016 - val_loss: 0.0505 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0016 - val_loss: 0.0506 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0014 - val_loss: 0.0504 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0014 - val_loss: 0.0506 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0013 - val_loss: 0.0507 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0014 - val_loss: 0.0511 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0012 - val_loss: 0.0506 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0013 - val_loss: 0.0510 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0013 - val_loss: 0.0509 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0011 - val_loss: 0.0503 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0012 - val_loss: 0.0502 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0013 - val_loss: 0.0506 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0013 - val_loss: 0.0514 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0012 - val_loss: 0.0505 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0012 - val_loss: 0.0506 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0011 - val_loss: 0.0505 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0012 - val_loss: 0.0506 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0011 - val_loss: 0.0506 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0012 - val_loss: 0.0506 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0012 - val_loss: 0.0507 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0012 - val_loss: 0.0506 - learning_rate: 7.8125e-05\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.2, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - loss: 0.1160 - val_loss: 0.0200 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0131 - val_loss: 0.0473 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0040 - val_loss: 0.0471 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0029 - val_loss: 0.0471 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0028 - val_loss: 0.0482 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0023 - val_loss: 0.0484 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0023 - val_loss: 0.0485 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0024 - val_loss: 0.0481 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0019 - val_loss: 0.0479 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0020 - val_loss: 0.0477 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0021 - val_loss: 0.0479 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.2, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 66ms/step - loss: 0.1378 - val_loss: 0.0159 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.0310 - val_loss: 0.0194 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0165 - val_loss: 0.0384 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0042 - val_loss: 0.0460 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0037 - val_loss: 0.0452 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0033 - val_loss: 0.0466 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0031 - val_loss: 0.0472 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0030 - val_loss: 0.0468 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0031 - val_loss: 0.0474 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0031 - val_loss: 0.0472 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0027 - val_loss: 0.0473 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.2, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - loss: 0.1707 - val_loss: 0.0208 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0468 - val_loss: 0.0157 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0275 - val_loss: 0.0193 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0195 - val_loss: 0.0288 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0074 - val_loss: 0.0478 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0040 - val_loss: 0.0475 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0042 - val_loss: 0.0475 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0036 - val_loss: 0.0471 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0037 - val_loss: 0.0477 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0033 - val_loss: 0.0478 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0035 - val_loss: 0.0479 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0033 - val_loss: 0.0477 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.2, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - loss: 0.0460 - val_loss: 0.0513 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0018 - val_loss: 0.0513 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0018 - val_loss: 0.0488 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.0016 - val_loss: 0.0468 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0498 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0014 - val_loss: 0.0480 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0014 - val_loss: 0.0497 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0013 - val_loss: 0.0484 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 9.3888e-04 - val_loss: 0.0467 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0012 - val_loss: 0.0480 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0011 - val_loss: 0.0468 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0010 - val_loss: 0.0481 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0479 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0010 - val_loss: 0.0476 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0010 - val_loss: 0.0479 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0010 - val_loss: 0.0468 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0010 - val_loss: 0.0463 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 8.8614e-04 - val_loss: 0.0462 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0011 - val_loss: 0.0446 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0011 - val_loss: 0.0455 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0011 - val_loss: 0.0452 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 9.5780e-04 - val_loss: 0.0439 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 9.1680e-04 - val_loss: 0.0435 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 9.4229e-04 - val_loss: 0.0438 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 25/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 9.5331e-04 - val_loss: 0.0409 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 26/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 9.4012e-04 - val_loss: 0.0425 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 27/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 8.7675e-04 - val_loss: 0.0416 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 28/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 9.8954e-04 - val_loss: 0.0387 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 29/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 8.9341e-04 - val_loss: 0.0384 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 30/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 8.2653e-04 - val_loss: 0.0345 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 31/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 7.7038e-04 - val_loss: 0.0373 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 32/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 7.9168e-04 - val_loss: 0.0366 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 33/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 7.3241e-04 - val_loss: 0.0365 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 34/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 6.9184e-04 - val_loss: 0.0376 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 35/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 7.1746e-04 - val_loss: 0.0407 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 36/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 8.0336e-04 - val_loss: 0.0428 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 37/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 6.4876e-04 - val_loss: 0.0397 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 38/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 5.9912e-04 - val_loss: 0.0372 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 39/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 6.6996e-04 - val_loss: 0.0387 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 40/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 5.6697e-04 - val_loss: 0.0426 - learning_rate: 1.5625e-05\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.2, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 66ms/step - loss: 0.0736 - val_loss: 0.0493 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.0021 - val_loss: 0.0490 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0017 - val_loss: 0.0487 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0015 - val_loss: 0.0471 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0016 - val_loss: 0.0468 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.0016 - val_loss: 0.0471 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.0012 - val_loss: 0.0483 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0012 - val_loss: 0.0471 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.0015 - val_loss: 0.0482 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - loss: 0.0012 - val_loss: 0.0482 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - loss: 0.0013 - val_loss: 0.0471 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0011 - val_loss: 0.0478 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.0012 - val_loss: 0.0480 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.0011 - val_loss: 0.0476 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - loss: 0.0012 - val_loss: 0.0478 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.2, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - loss: 0.0982 - val_loss: 0.0287 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - loss: 0.0073 - val_loss: 0.0470 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0021 - val_loss: 0.0488 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0016 - val_loss: 0.0488 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0017 - val_loss: 0.0490 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0015 - val_loss: 0.0494 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0015 - val_loss: 0.0488 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0016 - val_loss: 0.0490 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0015 - val_loss: 0.0491 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0013 - val_loss: 0.0493 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0015 - val_loss: 0.0484 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.2, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.0948 - val_loss: 0.0482 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0017 - val_loss: 0.0498 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0013 - val_loss: 0.0507 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0013 - val_loss: 0.0496 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0012 - val_loss: 0.0497 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0013 - val_loss: 0.0492 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0011 - val_loss: 0.0497 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0012 - val_loss: 0.0496 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0012 - val_loss: 0.0502 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0012 - val_loss: 0.0504 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0012 - val_loss: 0.0505 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.2, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 63ms/step - loss: 0.1118 - val_loss: 0.0465 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0016 - val_loss: 0.0493 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0015 - val_loss: 0.0498 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0014 - val_loss: 0.0497 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0012 - val_loss: 0.0501 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.0012 - val_loss: 0.0498 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0013 - val_loss: 0.0505 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 9.8366e-04 - val_loss: 0.0498 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0013 - val_loss: 0.0496 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - loss: 0.0011 - val_loss: 0.0501 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.0011 - val_loss: 0.0502 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.2, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - loss: 0.2826 - val_loss: 0.0438 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0036 - val_loss: 0.0464 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0017 - val_loss: 0.0485 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0016 - val_loss: 0.0503 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0014 - val_loss: 0.0499 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0013 - val_loss: 0.0501 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0013 - val_loss: 0.0499 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0013 - val_loss: 0.0503 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0015 - val_loss: 0.0500 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0012 - val_loss: 0.0501 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0012 - val_loss: 0.0503 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.3, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.1489 - val_loss: 0.0243 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0140 - val_loss: 0.0476 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0045 - val_loss: 0.0487 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0038 - val_loss: 0.0484 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0031 - val_loss: 0.0486 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0029 - val_loss: 0.0490 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0028 - val_loss: 0.0492 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0023 - val_loss: 0.0490 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0023 - val_loss: 0.0497 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0022 - val_loss: 0.0488 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0024 - val_loss: 0.0488 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.3, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 66ms/step - loss: 0.1512 - val_loss: 0.0250 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0450 - val_loss: 0.0253 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - loss: 0.0131 - val_loss: 0.0494 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.0051 - val_loss: 0.0487 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - loss: 0.0043 - val_loss: 0.0489 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0037 - val_loss: 0.0493 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0037 - val_loss: 0.0487 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0034 - val_loss: 0.0488 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0031 - val_loss: 0.0493 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0032 - val_loss: 0.0491 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0034 - val_loss: 0.0489 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.3, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 81ms/step - loss: 0.2113 - val_loss: 0.0131 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0623 - val_loss: 0.0199 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0326 - val_loss: 0.0268 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0149 - val_loss: 0.0477 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0056 - val_loss: 0.0490 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0053 - val_loss: 0.0475 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0049 - val_loss: 0.0480 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0046 - val_loss: 0.0482 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0042 - val_loss: 0.0484 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0042 - val_loss: 0.0485 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0039 - val_loss: 0.0484 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.3, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - loss: 0.0469 - val_loss: 0.0482 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0019 - val_loss: 0.0495 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0017 - val_loss: 0.0521 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0015 - val_loss: 0.0512 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0012 - val_loss: 0.0499 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0012 - val_loss: 0.0504 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0012 - val_loss: 0.0503 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0014 - val_loss: 0.0511 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0013 - val_loss: 0.0504 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0012 - val_loss: 0.0505 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0012 - val_loss: 0.0503 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.3, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - loss: 0.0852 - val_loss: 0.0540 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0025 - val_loss: 0.0517 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.0018 - val_loss: 0.0488 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.0017 - val_loss: 0.0518 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0016 - val_loss: 0.0508 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - loss: 0.0015 - val_loss: 0.0515 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.0014 - val_loss: 0.0509 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0013 - val_loss: 0.0496 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0013 - val_loss: 0.0502 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0014 - val_loss: 0.0501 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0012 - val_loss: 0.0506 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - loss: 0.0011 - val_loss: 0.0500 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.0012 - val_loss: 0.0506 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.3, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - loss: 0.1095 - val_loss: 0.0487 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0037 - val_loss: 0.0479 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0020 - val_loss: 0.0490 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0016 - val_loss: 0.0500 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0018 - val_loss: 0.0497 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0015 - val_loss: 0.0506 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0014 - val_loss: 0.0502 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0016 - val_loss: 0.0496 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0015 - val_loss: 0.0498 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0014 - val_loss: 0.0498 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0014 - val_loss: 0.0502 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0013 - val_loss: 0.0497 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.3, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 47ms/step - loss: 0.0721 - val_loss: 0.0500 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0016 - val_loss: 0.0507 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0014 - val_loss: 0.0498 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0013 - val_loss: 0.0498 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.0012 - val_loss: 0.0517 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - loss: 0.0014 - val_loss: 0.0521 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0013 - val_loss: 0.0502 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0011 - val_loss: 0.0501 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - loss: 0.0013 - val_loss: 0.0506 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.0013 - val_loss: 0.0508 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - loss: 0.0011 - val_loss: 0.0503 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0013 - val_loss: 0.0507 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0010 - val_loss: 0.0505 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.3, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 66ms/step - loss: 0.1538 - val_loss: 0.0504 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - loss: 0.0017 - val_loss: 0.0500 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - loss: 0.0014 - val_loss: 0.0500 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - loss: 0.0013 - val_loss: 0.0507 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0015 - val_loss: 0.0506 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0013 - val_loss: 0.0501 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.0013 - val_loss: 0.0499 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.0013 - val_loss: 0.0499 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0012 - val_loss: 0.0498 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0012 - val_loss: 0.0506 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.0012 - val_loss: 0.0502 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0012 - val_loss: 0.0505 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0010 - val_loss: 0.0504 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0012 - val_loss: 0.0508 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0012 - val_loss: 0.0499 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - loss: 0.0012 - val_loss: 0.0502 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0011 - val_loss: 0.0503 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0011 - val_loss: 0.0503 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0011 - val_loss: 0.0503 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.3, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - loss: 0.2691 - val_loss: 0.0458 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0034 - val_loss: 0.0498 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0017 - val_loss: 0.0501 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0016 - val_loss: 0.0509 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0014 - val_loss: 0.0503 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0014 - val_loss: 0.0500 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0014 - val_loss: 0.0505 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0013 - val_loss: 0.0499 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0013 - val_loss: 0.0503 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0015 - val_loss: 0.0503 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0014 - val_loss: 0.0504 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.5, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - loss: 0.1600 - val_loss: 0.0455 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0114 - val_loss: 0.0497 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0070 - val_loss: 0.0493 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0049 - val_loss: 0.0487 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0039 - val_loss: 0.0494 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0035 - val_loss: 0.0493 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0032 - val_loss: 0.0495 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0031 - val_loss: 0.0506 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0030 - val_loss: 0.0502 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0026 - val_loss: 0.0505 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0025 - val_loss: 0.0503 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.5, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 66ms/step - loss: 0.2132 - val_loss: 0.0525 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.0687 - val_loss: 0.0471 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - loss: 0.0101 - val_loss: 0.0466 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0079 - val_loss: 0.0478 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0061 - val_loss: 0.0491 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0048 - val_loss: 0.0490 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0041 - val_loss: 0.0492 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0041 - val_loss: 0.0493 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0038 - val_loss: 0.0495 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0036 - val_loss: 0.0497 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0037 - val_loss: 0.0495 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0031 - val_loss: 0.0497 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.0029 - val_loss: 0.0497 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.5, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - loss: 0.2254 - val_loss: 0.0424 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0889 - val_loss: 0.0273 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0349 - val_loss: 0.0495 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0094 - val_loss: 0.0473 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0084 - val_loss: 0.0485 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0071 - val_loss: 0.0486 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0065 - val_loss: 0.0487 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0058 - val_loss: 0.0492 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0053 - val_loss: 0.0486 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0057 - val_loss: 0.0492 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0051 - val_loss: 0.0495 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0048 - val_loss: 0.0495 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.5, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - loss: 0.0571 - val_loss: 0.0518 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0024 - val_loss: 0.0509 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0018 - val_loss: 0.0513 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0017 - val_loss: 0.0512 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0014 - val_loss: 0.0500 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0017 - val_loss: 0.0508 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0012 - val_loss: 0.0516 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0014 - val_loss: 0.0504 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0011 - val_loss: 0.0501 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0011 - val_loss: 0.0505 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0011 - val_loss: 0.0505 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0011 - val_loss: 0.0508 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0013 - val_loss: 0.0520 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0013 - val_loss: 0.0505 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0012 - val_loss: 0.0510 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.5, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 66ms/step - loss: 0.0860 - val_loss: 0.0494 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0022 - val_loss: 0.0502 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0016 - val_loss: 0.0509 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0014 - val_loss: 0.0527 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0014 - val_loss: 0.0506 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0013 - val_loss: 0.0505 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0014 - val_loss: 0.0501 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0012 - val_loss: 0.0507 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0012 - val_loss: 0.0512 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0013 - val_loss: 0.0509 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0012 - val_loss: 0.0510 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.5, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - loss: 0.1065 - val_loss: 0.0491 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0052 - val_loss: 0.0499 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0022 - val_loss: 0.0511 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0019 - val_loss: 0.0509 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0018 - val_loss: 0.0506 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0018 - val_loss: 0.0508 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0015 - val_loss: 0.0504 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0014 - val_loss: 0.0506 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0013 - val_loss: 0.0509 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0014 - val_loss: 0.0507 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0014 - val_loss: 0.0513 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.5, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - loss: 0.0906 - val_loss: 0.0516 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0018 - val_loss: 0.0513 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0016 - val_loss: 0.0497 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0014 - val_loss: 0.0498 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0015 - val_loss: 0.0509 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0014 - val_loss: 0.0508 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0013 - val_loss: 0.0508 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0012 - val_loss: 0.0510 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0013 - val_loss: 0.0508 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0013 - val_loss: 0.0505 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0013 - val_loss: 0.0511 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0012 - val_loss: 0.0508 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0011 - val_loss: 0.0504 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.5, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - loss: 0.1391 - val_loss: 0.0526 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0022 - val_loss: 0.0502 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.0018 - val_loss: 0.0521 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0014 - val_loss: 0.0523 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.0015 - val_loss: 0.0505 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0014 - val_loss: 0.0511 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0012 - val_loss: 0.0512 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0012 - val_loss: 0.0518 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0015 - val_loss: 0.0509 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0013 - val_loss: 0.0511 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0012 - val_loss: 0.0505 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.0012 - val_loss: 0.0506 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.5, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 81ms/step - loss: 0.2530 - val_loss: 0.0512 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0032 - val_loss: 0.0509 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0019 - val_loss: 0.0511 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0016 - val_loss: 0.0509 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0016 - val_loss: 0.0505 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0014 - val_loss: 0.0508 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0014 - val_loss: 0.0508 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0013 - val_loss: 0.0505 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0014 - val_loss: 0.0510 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0012 - val_loss: 0.0503 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0013 - val_loss: 0.0503 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0014 - val_loss: 0.0507 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0013 - val_loss: 0.0502 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0012 - val_loss: 0.0509 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0012 - val_loss: 0.0518 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0012 - val_loss: 0.0509 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0012 - val_loss: 0.0507 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0012 - val_loss: 0.0510 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0012 - val_loss: 0.0509 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0013 - val_loss: 0.0508 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0011 - val_loss: 0.0509 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0012 - val_loss: 0.0506 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0013 - val_loss: 0.0508 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2024-11-13 14:41:46.865784: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
        }
      ],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731514901207
        }
      },
      "id": "8cb28c39-2653-41a7-95e5-8b486b84dcd8"
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training history of the best model\n",
        "# Plot the loss and validation loss over epochs for the best model\n",
        "plt.plot(best_history.history['loss'], label='Train Loss')\n",
        "plt.plot(best_history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 640x480 with 1 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        }
      ],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1731514901621
        }
      },
      "id": "115214aa-3add-4c98-87a8-e87493aab78b"
    },
    {
      "cell_type": "code",
      "source": [
        "# Output the best model parameters\n",
        "# Print the best hyperparameters found in the grid search\n",
        "print(f\"Best model parameters: Units={best_params[0]}, Layers={best_params[1]}, Dropout={best_params[2]}, Learning Rate={best_params[3]}, Batch Size={best_params[4]}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Best model parameters: Units=150, Layers=2, Dropout=0.2, Learning Rate=0.0001, Batch Size=48\n"
        }
      ],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1731514901920
        }
      },
      "id": "8b3841a0-3f81-4ec1-bf15-ed1ad06b83f6"
    },
    {
      "cell_type": "code",
      "source": [
        "#best_model.save('LL Prediction 1.h5')"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1731514902159
        }
      },
      "id": "042b6d75-62d1-44e2-81c8-ea6138a5290d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing Part"
      ],
      "metadata": {},
      "id": "2e133462-e8a3-4326-953c-f7d0b9ca59d1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1) Load the model"
      ],
      "metadata": {},
      "id": "3e9ef43e-7b23-45d4-86d7-d55be0c5b542"
    },
    {
      "cell_type": "code",
      "source": [
        "best_model"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 26,
          "data": {
            "text/plain": "<Sequential name=sequential_191, built=True>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731514902406
        }
      },
      "id": "8ef1ae10-315f-4645-a08f-e491085e4c8b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2) Window sampling for testing set"
      ],
      "metadata": {},
      "id": "3064e6bc-e88a-4b59-8c3b-bf832807cb88"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Parameters for window sampling\n",
        "input_window_size = 28\n",
        "output_window_size = 1\n",
        "stride = 1\n",
        "\n",
        "# Initialize lists to store the input (X_test) and output (y_test) sequences for testing set\n",
        "X_test, y_test = [], []\n",
        "\n",
        "# Loop through the testing set to create windows of input and output sequences\n",
        "for i in range(0, len(testing_set) - input_window_size - output_window_size + 1, stride):\n",
        "    # Define the input window (20 data points)\n",
        "    input_window = testing_set.iloc[i:i+input_window_size][['Latitude']]\n",
        "    # Define the output window (1 data point immediately following the input window)\n",
        "    output_window = testing_set.iloc[i+input_window_size:i+input_window_size+output_window_size][['Latitude']]\n",
        "    # Append the input window to X_test and the last value of output window to y_test\n",
        "    X_test.append(input_window.values)\n",
        "    y_test.append(output_window.values[-1])\n",
        "\n",
        "# Convert X_test and y_test lists to numpy arrays for model input\n",
        "X_test, y_test = np.array(X_test), np.array(y_test)\n",
        "\n",
        "# Print the number of samples created for testing\n",
        "print(f\"Number of test samples: {X_test.shape[0]}\")\n",
        "print(f\"Test input shape: {X_test.shape}, Test target shape: {y_test.shape}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Number of test samples: 280\nTest input shape: (280, 28, 1), Test target shape: (280, 1)\n"
        }
      ],
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1731514902810
        }
      },
      "id": "21eb4d35-9feb-4cb5-991f-648de6aa57f6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3) Test the Testing Set Using the Imported Model"
      ],
      "metadata": {},
      "id": "f5067a01-5653-4c44-a2e2-55a792560d85"
    },
    {
      "cell_type": "code",
      "source": [
        "best_model"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 28,
          "data": {
            "text/plain": "<Sequential name=sequential_191, built=True>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731514903076
        }
      },
      "id": "5cac2aa7-758b-4fbe-884a-a516f591b3de"
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the testing set\n",
        "y_pred = best_model.predict(X_test)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\r\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 285ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m6/9\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step\n"
        }
      ],
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1731514903422
        }
      },
      "id": "9063ce56-d2b5-4a47-a40c-989f99422ce6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4) Calculate Error on the Testing Set"
      ],
      "metadata": {},
      "id": "b9406b06-7176-4b4b-937e-f2495d76f9f9"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Calculate MSE between predicted and actual values\n",
        "error = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error on the Testing Set: {error}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Mean Squared Error on the Testing Set: 0.005687945014171555\n"
        }
      ],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731514903637
        }
      },
      "id": "8e68e4cc-6596-4a8b-b34a-e36ed460e689"
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the original data for predicted cells and add it to testing set as a new column\n",
        "# Convert predictions to a DataFrame for easier concatenation\n",
        "predictions_df = pd.DataFrame(y_pred, columns=['Predicted_Latitude'])"
      ],
      "outputs": [],
      "execution_count": 31,
      "metadata": {
        "gather": {
          "logged": 1731514903852
        }
      },
      "id": "c96b794c-6223-4bf1-a92d-9aa8fe4f37ae"
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 32,
          "data": {
            "text/plain": "   Predicted_Latitude\n0            0.571015\n1            0.570092\n2            0.568857\n3            0.567482\n4            0.565880",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Predicted_Latitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.571015</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.570092</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.568857</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.567482</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.565880</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 32,
      "metadata": {
        "gather": {
          "logged": 1731514904245
        }
      },
      "id": "be80fb11-820e-4e20-9b61-42581e57b3b0"
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the predictions (y_pred) into a DataFrame for easy handling with timestamps\n",
        "# We assume `testing_set.index[input_window_size:]` matches the `y_pred` in length\n",
        "predicted_latitudes = pd.DataFrame(y_pred, index=testing_set.index[input_window_size:], columns=['Predicted_Latitude'])\n",
        "\n",
        "# Add the 'Latitude' column from `testing_set` as the true values for comparison\n",
        "testing_latitudes = testing_set[['Latitude']].iloc[input_window_size:]  # Skip initial window\n",
        "\n",
        "# Define the months for filtering and specific timestamps for illustration\n",
        "months = {\n",
        "    'June': '2024-06',\n",
        "    'July': '2024-07',\n",
        "    'August': '2024-08'\n",
        "}\n",
        "\n",
        "# Plot each month's data\n",
        "for month_name, month_str in months.items():\n",
        "    # Filter data for the entire month\n",
        "    monthly_actual_data = testing_latitudes[testing_latitudes.index.to_period('M') == month_str]\n",
        "    monthly_predicted_data = predicted_latitudes[predicted_latitudes.index.to_period('M') == month_str]\n",
        "    \n",
        "    # Plot actual vs predicted latitude values for the month\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(monthly_actual_data.index, monthly_actual_data['Latitude'], label='Actual Latitude', color='blue')\n",
        "    plt.plot(monthly_predicted_data.index, monthly_predicted_data['Predicted_Latitude'], label='Predicted Latitude', color='orange')\n",
        "    \n",
        "    # Formatting the plot\n",
        "    plt.title(f'{month_name} 2024 - Latitude vs Predicted Latitude')\n",
        "    plt.xlabel('Received Timestamp')\n",
        "    plt.ylabel('Latitude')\n",
        "    plt.legend()\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 1200x600 with 1 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 1200x600 with 1 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 1200x600 with 1 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        }
      ],
      "execution_count": 33,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731514904692
        }
      },
      "id": "f71e0a33-7995-4be2-aa66-c84152b9ddd5"
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_real = scaler.inverse_transform(y_test)\n",
        "#y_test = y_test.reshape(-1, 1)  # Reshape if necessary\n",
        "#y_pred = y_pred.reshape(-1, 1)  # Reshape if necessary"
      ],
      "outputs": [],
      "execution_count": 34,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731514904964
        }
      },
      "id": "2515526e-3d8f-4202-839e-6303769964c2"
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_real"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 35,
          "data": {
            "text/plain": "array([[25.97180744],\n       [25.77515932],\n       [26.31819316],\n       [25.54576214],\n       [24.60296175],\n       [23.76164734],\n       [22.96193654],\n       [21.98669953],\n       [20.75568528],\n       [19.65923326],\n       [18.933386  ],\n       [17.92575052],\n       [17.28073893],\n       [16.45450674],\n       [15.66919939],\n       [15.16199359],\n       [14.68255261],\n       [14.26538734],\n       [13.91375453],\n       [13.4736939 ],\n       [13.0794517 ],\n       [12.63182437],\n       [12.26528943],\n       [12.08589759],\n       [12.59870332],\n       [13.72820221],\n       [14.84033727],\n       [16.02938198],\n       [16.86632795],\n       [17.69944362],\n       [19.02252439],\n       [20.18296209],\n       [21.27411182],\n       [22.33634928],\n       [23.41942198],\n       [24.48111009],\n       [25.51978358],\n       [26.55880673],\n       [27.44007351],\n       [28.27288094],\n       [29.35977371],\n       [29.81559335],\n       [29.8305722 ],\n       [29.82925217],\n       [29.93503546],\n       [30.40442896],\n       [31.40373171],\n       [32.17269832],\n       [32.95340108],\n       [33.82276864],\n       [34.6766149 ],\n       [35.3603722 ],\n       [35.99117951],\n       [36.82949305],\n       [37.74670324],\n       [37.89869741],\n       [37.90321827],\n       [37.90905362],\n       [37.90904883],\n       [37.90906214],\n       [37.90904233],\n       [37.9090492 ],\n       [37.90904637],\n       [37.90895737],\n       [37.90904257],\n       [37.90904767],\n       [37.89456267],\n       [37.85512335],\n       [37.61705255],\n       [36.47872624],\n       [36.05918617],\n       [36.11845296],\n       [36.17223412],\n       [36.2389844 ],\n       [36.29635722],\n       [36.42792391],\n       [36.90736581],\n       [37.34246841],\n       [37.67504047],\n       [37.8417657 ],\n       [37.83554523],\n       [37.79366672],\n       [37.48249029],\n       [37.15049007],\n       [36.84199088],\n       [36.52769679],\n       [36.22098709],\n       [36.16220477],\n       [36.11772313],\n       [35.98542091],\n       [36.41001103],\n       [36.7521295 ],\n       [37.92895815],\n       [39.07410926],\n       [40.30725376],\n       [41.49882862],\n       [42.9071849 ],\n       [43.91316409],\n       [45.125601  ],\n       [47.15618613],\n       [47.93533769],\n       [49.0460944 ],\n       [50.65910523],\n       [51.48049929],\n       [52.788334  ],\n       [53.409775  ],\n       [54.60749533],\n       [55.56493483],\n       [56.178294  ],\n       [58.03934957],\n       [58.80706937],\n       [60.19677376],\n       [61.16973709],\n       [62.15348245],\n       [63.35740588],\n       [64.4520852 ],\n       [65.6181485 ],\n       [66.75008505],\n       [67.77670566],\n       [68.5368316 ],\n       [69.28158822],\n       [70.13882273],\n       [70.99269468],\n       [71.56326432],\n       [71.94478536],\n       [71.93627815],\n       [71.52974134],\n       [70.94727048],\n       [70.13479914],\n       [69.87890629],\n       [69.89314197],\n       [69.94873472],\n       [69.91707   ],\n       [69.9049946 ],\n       [69.93140206],\n       [69.94531517],\n       [69.952002  ],\n       [69.97760684],\n       [70.0028369 ],\n       [69.95003836],\n       [69.85341374],\n       [69.965124  ],\n       [69.98413026],\n       [69.3415346 ],\n       [69.07990533],\n       [69.07977173],\n       [69.07962264],\n       [69.07979082],\n       [69.10602141],\n       [69.132252  ],\n       [69.67106603],\n       [70.75084381],\n       [72.13776299],\n       [72.7887026 ],\n       [72.98464009],\n       [72.51849651],\n       [72.10129766],\n       [71.60664415],\n       [70.93385025],\n       [70.14471341],\n       [69.38758434],\n       [68.6293749 ],\n       [67.87943602],\n       [66.88742186],\n       [65.79326871],\n       [64.66656706],\n       [63.54355652],\n       [62.43361536],\n       [61.63445791],\n       [60.60991731],\n       [59.740079  ],\n       [58.62941286],\n       [57.27603825],\n       [56.202977  ],\n       [55.0757212 ],\n       [53.64435667],\n       [52.701931  ],\n       [51.32820887],\n       [50.01789229],\n       [48.43841141],\n       [47.38411603],\n       [46.17552956],\n       [45.00653613],\n       [43.22533835],\n       [42.13150411],\n       [40.95535558],\n       [39.68454509],\n       [38.41069005],\n       [37.12113092],\n       [36.37107452],\n       [36.08623093],\n       [35.94742682],\n       [36.11041198],\n       [36.25440316],\n       [36.58772491],\n       [36.9072164 ],\n       [37.28792933],\n       [37.60323909],\n       [37.82792906],\n       [37.83197226],\n       [37.81900123],\n       [37.56716137],\n       [37.16417256],\n       [36.64210927],\n       [36.30706681],\n       [35.98130664],\n       [35.59065287],\n       [35.25808778],\n       [34.84367352],\n       [34.51295765],\n       [34.15567871],\n       [33.75515074],\n       [33.4253165 ],\n       [32.93169502],\n       [32.62095427],\n       [32.24244312],\n       [31.64628448],\n       [31.65498567],\n       [32.29195833],\n       [31.60181909],\n       [31.39104933],\n       [30.79075566],\n       [29.92961582],\n       [28.81783762],\n       [27.69395129],\n       [26.67096923],\n       [25.5467896 ],\n       [24.56110099],\n       [23.37316059],\n       [22.17831506],\n       [21.04481017],\n       [19.98837216],\n       [18.77960728],\n       [17.54824106],\n       [16.87549449],\n       [15.80217704],\n       [14.94722217],\n       [13.43360103],\n       [12.7453095 ],\n       [11.98478167],\n       [12.09908032],\n       [12.68716193],\n       [13.03851219],\n       [13.48452905],\n       [13.80080504],\n       [14.24371968],\n       [13.99655881],\n       [13.65922453],\n       [13.39344   ],\n       [12.98448581],\n       [12.59953683],\n       [12.31013   ],\n       [12.042524  ],\n       [11.65886337],\n       [11.20664917],\n       [10.986243  ],\n       [10.61729957],\n       [10.35302794],\n       [ 9.935642  ],\n       [ 9.72173583],\n       [ 9.41219289],\n       [ 8.70566044],\n       [ 8.28783416],\n       [ 7.8062264 ],\n       [ 7.30322773],\n       [ 6.92693853],\n       [ 6.38611289],\n       [ 5.90523418],\n       [ 5.7471109 ],\n       [ 5.82137745],\n       [ 5.86255647],\n       [ 5.920197  ],\n       [ 5.96118987],\n       [ 6.02148931],\n       [ 6.06308868],\n       [ 6.1067927 ],\n       [ 6.15884184],\n       [ 6.21969509],\n       [ 6.25024784],\n       [ 6.29350524]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 35,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731514905184
        }
      },
      "id": "2ffaa217-ecf8-4a0e-97d7-51e20148d018"
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_real = scaler.inverse_transform(y_pred)\n",
        "y_pred_real"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 36,
          "data": {
            "text/plain": "array([[26.659945 ],\n       [26.560295 ],\n       [26.426886 ],\n       [26.278408 ],\n       [26.105438 ],\n       [25.901299 ],\n       [25.661081 ],\n       [25.384975 ],\n       [25.071465 ],\n       [24.7157   ],\n       [24.31587  ],\n       [23.877956 ],\n       [23.401693 ],\n       [22.894753 ],\n       [22.360071 ],\n       [21.801403 ],\n       [21.227047 ],\n       [20.643892 ],\n       [20.058582 ],\n       [19.477358 ],\n       [18.903309 ],\n       [18.339535 ],\n       [17.787159 ],\n       [17.248291 ],\n       [16.728334 ],\n       [16.244799 ],\n       [15.821243 ],\n       [15.470421 ],\n       [15.202405 ],\n       [15.018369 ],\n       [14.914613 ],\n       [14.893494 ],\n       [14.962895 ],\n       [15.120358 ],\n       [15.360295 ],\n       [15.677387 ],\n       [16.066795 ],\n       [16.523527 ],\n       [17.04039  ],\n       [17.606419 ],\n       [18.214989 ],\n       [18.861336 ],\n       [19.53226  ],\n       [20.208778 ],\n       [20.874943 ],\n       [21.521774 ],\n       [22.149025 ],\n       [22.766127 ],\n       [23.376808 ],\n       [23.984125 ],\n       [24.592691 ],\n       [25.204985 ],\n       [25.819124 ],\n       [26.429865 ],\n       [27.036982 ],\n       [27.644691 ],\n       [28.241653 ],\n       [28.820032 ],\n       [29.372444 ],\n       [29.890661 ],\n       [30.372383 ],\n       [30.816154 ],\n       [31.221468 ],\n       [31.588459 ],\n       [31.918278 ],\n       [32.212574 ],\n       [32.47325  ],\n       [32.703114 ],\n       [32.903973 ],\n       [33.072453 ],\n       [33.195393 ],\n       [33.2772   ],\n       [33.327393 ],\n       [33.35253  ],\n       [33.357117 ],\n       [33.34365  ],\n       [33.319885 ],\n       [33.296947 ],\n       [33.281616 ],\n       [33.277767 ],\n       [33.286106 ],\n       [33.30341  ],\n       [33.32496  ],\n       [33.342697 ],\n       [33.35522  ],\n       [33.358833 ],\n       [33.349945 ],\n       [33.326214 ],\n       [33.290695 ],\n       [33.24591  ],\n       [33.192455 ],\n       [33.141342 ],\n       [33.09872  ],\n       [33.084698 ],\n       [33.11243  ],\n       [33.193214 ],\n       [33.333923 ],\n       [33.54367  ],\n       [33.82451  ],\n       [34.172195 ],\n       [34.59759  ],\n       [35.085743 ],\n       [35.63191  ],\n       [36.23981  ],\n       [36.89522  ],\n       [37.594913 ],\n       [38.32398  ],\n       [39.0825   ],\n       [39.864872 ],\n       [40.66065  ],\n       [41.484425 ],\n       [42.325905 ],\n       [43.18927  ],\n       [44.06815  ],\n       [44.958538 ],\n       [45.86105  ],\n       [46.77206  ],\n       [47.69139  ],\n       [48.618534 ],\n       [49.54745  ],\n       [50.471996 ],\n       [51.382576 ],\n       [52.278473 ],\n       [53.15843  ],\n       [54.017273 ],\n       [54.847107 ],\n       [55.638958 ],\n       [56.376877 ],\n       [57.04359  ],\n       [57.6344   ],\n       [58.1497   ],\n       [58.593903 ],\n       [58.97921  ],\n       [59.30796  ],\n       [59.59009  ],\n       [59.828167 ],\n       [60.02896  ],\n       [60.19905  ],\n       [60.33566  ],\n       [60.449646 ],\n       [60.53931  ],\n       [60.60864  ],\n       [60.662785 ],\n       [60.702553 ],\n       [60.718697 ],\n       [60.711933 ],\n       [60.687527 ],\n       [60.649807 ],\n       [60.603405 ],\n       [60.55135  ],\n       [60.4953   ],\n       [60.44664  ],\n       [60.42441  ],\n       [60.447033 ],\n       [60.51507  ],\n       [60.621758 ],\n       [60.74868  ],\n       [60.883698 ],\n       [61.011177 ],\n       [61.11729  ],\n       [61.191086 ],\n       [61.226337 ],\n       [61.21833  ],\n       [61.164413 ],\n       [61.05931  ],\n       [60.898674 ],\n       [60.679718 ],\n       [60.401615 ],\n       [60.06558  ],\n       [59.67922  ],\n       [59.243217 ],\n       [58.76407  ],\n       [58.246105 ],\n       [57.68397  ],\n       [57.080414 ],\n       [56.4379   ],\n       [55.753624 ],\n       [55.035637 ],\n       [54.281857 ],\n       [53.490578 ],\n       [52.655422 ],\n       [51.78343  ],\n       [50.88254  ],\n       [49.959393 ],\n       [49.00973  ],\n       [48.04083  ],\n       [47.056423 ],\n       [46.05886  ],\n       [45.05008  ],\n       [44.03073  ],\n       [43.011547 ],\n       [42.008392 ],\n       [41.03671  ],\n       [40.112595 ],\n       [39.246536 ],\n       [38.44882  ],\n       [37.725433 ],\n       [37.078903 ],\n       [36.51121  ],\n       [36.018658 ],\n       [35.595085 ],\n       [35.23445  ],\n       [34.923576 ],\n       [34.650562 ],\n       [34.404972 ],\n       [34.177372 ],\n       [33.96503  ],\n       [33.761883 ],\n       [33.56621  ],\n       [33.370632 ],\n       [33.17478  ],\n       [32.976795 ],\n       [32.77838  ],\n       [32.57515  ],\n       [32.364746 ],\n       [32.149258 ],\n       [31.92839  ],\n       [31.698322 ],\n       [31.464407 ],\n       [31.24151  ],\n       [31.017475 ],\n       [30.792738 ],\n       [30.561235 ],\n       [30.312973 ],\n       [30.037298 ],\n       [29.726093 ],\n       [29.37625  ],\n       [28.984304 ],\n       [28.55195  ],\n       [28.076454 ],\n       [27.558037 ],\n       [26.998537 ],\n       [26.401428 ],\n       [25.76565  ],\n       [25.091883 ],\n       [24.39193  ],\n       [23.666845 ],\n       [22.923267 ],\n       [22.153582 ],\n       [21.368656 ],\n       [20.574867 ],\n       [19.792593 ],\n       [19.046158 ],\n       [18.347242 ],\n       [17.707256 ],\n       [17.132273 ],\n       [16.623362 ],\n       [16.166925 ],\n       [15.761193 ],\n       [15.395374 ],\n       [15.062256 ],\n       [14.755682 ],\n       [14.472131 ],\n       [14.207575 ],\n       [13.955904 ],\n       [13.712198 ],\n       [13.475476 ],\n       [13.243861 ],\n       [13.016949 ],\n       [12.791159 ],\n       [12.567419 ],\n       [12.345791 ],\n       [12.118731 ],\n       [11.882751 ],\n       [11.638982 ],\n       [11.384904 ],\n       [11.125898 ],\n       [10.855249 ],\n       [10.5738   ],\n       [10.2827635],\n       [ 9.988802 ],\n       [ 9.700147 ],\n       [ 9.421649 ],\n       [ 9.157759 ],\n       [ 8.910551 ],\n       [ 8.685415 ],\n       [ 8.483125 ],\n       [ 8.303073 ],\n       [ 8.145611 ],\n       [ 8.009156 ]], dtype=float32)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 36,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731514905419
        }
      },
      "id": "3ee7b76b-b5a4-448b-a1f5-97be512b9658"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "a3ef21f8-3a19-4770-af67-6150cb53d9e6"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}