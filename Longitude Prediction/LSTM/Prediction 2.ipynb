{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Training set - 2023 Jan to 2024 May\n",
        "Input window = 28"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "61beb701-6eac-4e45-80c7-4239d4ab2ed0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Import the libraries"
      ],
      "metadata": {},
      "id": "8b7d27d4-1baa-4a30-a352-89e822008ce0"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install matplotlib"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: matplotlib in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (3.9.2)\nRequirement already satisfied: contourpy>=1.0.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib) (1.3.0)\nRequirement already satisfied: cycler>=0.10 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib) (4.54.1)\nRequirement already satisfied: kiwisolver>=1.3.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib) (1.4.7)\nRequirement already satisfied: numpy>=1.23 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib) (2.0.2)\nRequirement already satisfied: packaging>=20.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib) (24.1)\nRequirement already satisfied: pillow>=8 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib) (10.4.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from matplotlib) (2.9.0)\nRequirement already satisfied: six>=1.5 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731532772489
        }
      },
      "id": "08f290a3-fda0-417b-9a9f-aa4034917cfc"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import timedelta\n",
        "import matplotlib.pyplot as plt"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1731532776264
        }
      },
      "id": "127f3d8f-3671-4640-b177-d8e7d2913b6b"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: tensorflow in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (2.18.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (0.37.1)\nRequirement already satisfied: keras>=3.5.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (3.5.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (1.65.4)\nRequirement already satisfied: requests<3,>=2.21.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (2.32.3)\nRequirement already satisfied: numpy<2.1.0,>=1.26.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: h5py>=3.11.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (3.11.0)\nRequirement already satisfied: flatbuffers>=24.3.25 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (24.3.25)\nRequirement already satisfied: opt-einsum>=2.3.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: setuptools in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (68.0.0)\nRequirement already satisfied: astunparse>=1.6.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: libclang>=13.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: packaging in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (24.1)\nRequirement already satisfied: termcolor>=1.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: wrapt>=1.11.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (1.14.1)\nRequirement already satisfied: absl-py>=1.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (2.1.0)\nRequirement already satisfied: six>=1.12.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (0.4.1)\nRequirement already satisfied: google-pasta>=0.1.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: tensorboard<2.19,>=2.18 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (2.18.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (4.12.2)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (0.6.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\nRequirement already satisfied: namex in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\nRequirement already satisfied: optree in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.12.1)\nRequirement already satisfied: rich in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (13.8.1)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.19)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\nRequirement already satisfied: markdown>=2.6.8 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\nRequirement already satisfied: werkzeug>=1.0.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.0.3)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.5)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\nRequirement already satisfied: mdurl~=0.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2024-11-13 21:19:49.503437: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n2024-11-13 21:19:51.677084: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1731532792.424696    3169 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1731532792.635309    3169 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2024-11-13 21:19:54.610774: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731532801960
        }
      },
      "id": "163193b3-3302-43fa-a5fe-a03569386e15"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scipy scikit-learn"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: scipy in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (1.14.1)\nRequirement already satisfied: scikit-learn in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (1.5.2)\nRequirement already satisfied: numpy<2.3,>=1.23.5 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from scipy) (2.0.2)\nRequirement already satisfied: joblib>=1.2.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /anaconda/envs/jupyter_env/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731532802875
        }
      },
      "id": "076892a3-aa54-4cc7-a69a-439bf536527e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Pre processing the dataset"
      ],
      "metadata": {},
      "id": "e4cc4d9f-b792-46c2-8712-666765ac0971"
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "data = pd.read_csv('LL_data.csv')"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1731532803679
        }
      },
      "id": "e256e925-7472-4f1c-9c5f-df13d393783f"
    },
    {
      "cell_type": "code",
      "source": [
        "data.tail()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "         Received_Timestamp  Latitude  Longitude\n796631  2024-08-16 20:26:55  6.301900  94.509340\n796632  2024-08-16 20:41:52  6.304237  94.558950\n796633  2024-08-16 20:44:07  6.304650  94.566895\n796634  2024-08-16 20:44:45  6.304758  94.569090\n796635  2024-08-16 21:01:24  6.306820  94.625694",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Received_Timestamp</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>796631</th>\n      <td>2024-08-16 20:26:55</td>\n      <td>6.301900</td>\n      <td>94.509340</td>\n    </tr>\n    <tr>\n      <th>796632</th>\n      <td>2024-08-16 20:41:52</td>\n      <td>6.304237</td>\n      <td>94.558950</td>\n    </tr>\n    <tr>\n      <th>796633</th>\n      <td>2024-08-16 20:44:07</td>\n      <td>6.304650</td>\n      <td>94.566895</td>\n    </tr>\n    <tr>\n      <th>796634</th>\n      <td>2024-08-16 20:44:45</td>\n      <td>6.304758</td>\n      <td>94.569090</td>\n    </tr>\n    <tr>\n      <th>796635</th>\n      <td>2024-08-16 21:01:24</td>\n      <td>6.306820</td>\n      <td>94.625694</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1731532804021
        }
      },
      "id": "10b13fcb-7cc9-42f7-8a51-2bd13a41a172"
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the 'Longitude' column\n",
        "data = data.drop(columns=['Latitude'])"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731532804341
        }
      },
      "id": "fb42c11a-328a-48cd-9a2a-76268cc3f1ba"
    },
    {
      "cell_type": "code",
      "source": [
        "data.tail()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "         Received_Timestamp  Longitude\n796631  2024-08-16 20:26:55  94.509340\n796632  2024-08-16 20:41:52  94.558950\n796633  2024-08-16 20:44:07  94.566895\n796634  2024-08-16 20:44:45  94.569090\n796635  2024-08-16 21:01:24  94.625694",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Received_Timestamp</th>\n      <th>Longitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>796631</th>\n      <td>2024-08-16 20:26:55</td>\n      <td>94.509340</td>\n    </tr>\n    <tr>\n      <th>796632</th>\n      <td>2024-08-16 20:41:52</td>\n      <td>94.558950</td>\n    </tr>\n    <tr>\n      <th>796633</th>\n      <td>2024-08-16 20:44:07</td>\n      <td>94.566895</td>\n    </tr>\n    <tr>\n      <th>796634</th>\n      <td>2024-08-16 20:44:45</td>\n      <td>94.569090</td>\n    </tr>\n    <tr>\n      <th>796635</th>\n      <td>2024-08-16 21:01:24</td>\n      <td>94.625694</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731532804828
        }
      },
      "id": "e40aaa60-1ac4-4aa1-9e8d-5c87f9d9ad4b"
    },
    {
      "cell_type": "code",
      "source": [
        "data['Received_Timestamp'] = pd.to_datetime(data['Received_Timestamp'])  # Convert to datetime\n",
        "data['Longitude'] = pd.to_numeric(data['Longitude'], errors='coerce')       # Convert to numeric, handling errors\n",
        "#data['Longitude'] = pd.to_numeric(data['Longitude'], errors='coerce')     # Convert to numeric, handling errors\n",
        "data = data.dropna()  # Drop rows with NaN values if any remain"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1731532805140
        }
      },
      "id": "f6c0ae3f-2e49-494c-a64a-2ecb0857965d"
    },
    {
      "cell_type": "code",
      "source": [
        "data.set_index('Received_Timestamp', inplace=True)  # Set datetime as the index"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1731532805445
        }
      },
      "id": "33499773-a2f4-4909-9721-ce54ba7b4d49"
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nDatetimeIndex: 796636 entries, 2023-01-01 00:36:49 to 2024-08-16 21:01:24\nData columns (total 1 columns):\n #   Column     Non-Null Count   Dtype  \n---  ------     --------------   -----  \n 0   Longitude  796636 non-null  float64\ndtypes: float64(1)\nmemory usage: 12.2 MB\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1731532805733
        }
      },
      "id": "22be6e4b-0125-4f16-b479-8c35f7696499"
    },
    {
      "cell_type": "code",
      "source": [
        "# Resample data to six-hour bins, handling empty bins with interpolation\n",
        "data = data.resample('6H').mean()  # Bin by six hours with mean aggregation\n",
        "data = data.interpolate(method='linear')  # Linear interpolation for missing bins"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/tmp/ipykernel_3169/4293368568.py:2: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n  data = data.resample('6H').mean()  # Bin by six hours with mean aggregation\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1731532806025
        }
      },
      "id": "6abe400b-de03-41ed-a463-6ecf09cd28f7"
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "                     Longitude\nReceived_Timestamp            \n2023-01-01 00:00:00  61.666054\n2023-01-01 06:00:00  62.527122\n2023-01-01 12:00:00  63.845577\n2023-01-01 18:00:00  64.817208\n2023-01-02 00:00:00  66.021411",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Longitude</th>\n    </tr>\n    <tr>\n      <th>Received_Timestamp</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2023-01-01 00:00:00</th>\n      <td>61.666054</td>\n    </tr>\n    <tr>\n      <th>2023-01-01 06:00:00</th>\n      <td>62.527122</td>\n    </tr>\n    <tr>\n      <th>2023-01-01 12:00:00</th>\n      <td>63.845577</td>\n    </tr>\n    <tr>\n      <th>2023-01-01 18:00:00</th>\n      <td>64.817208</td>\n    </tr>\n    <tr>\n      <th>2023-01-02 00:00:00</th>\n      <td>66.021411</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1731532806359
        }
      },
      "id": "d49f9023-7d31-46be-b9bf-e58bb7302e7f"
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nDatetimeIndex: 2376 entries, 2023-01-01 00:00:00 to 2024-08-16 18:00:00\nFreq: 6h\nData columns (total 1 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   Longitude  2376 non-null   float64\ndtypes: float64(1)\nmemory usage: 37.1 KB\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1731532806693
        }
      },
      "id": "a31a1b6f-eb1c-4a56-a32d-11b27f098db1"
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "# Ensure 'Latitude' is in a 2D format before scaling\n",
        "data['Longitude'] = scaler.fit_transform(data[['Longitude']])"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1731532806979
        }
      },
      "id": "a31d3de1-0e75-4202-b10f-afcfec093f49"
    },
    {
      "cell_type": "code",
      "source": [
        "# Training set: Entire year of 2023 and up to August 2024\n",
        "training_set = data.loc['2023':'2024-05']\n",
        "\n",
        "# Testing set: Remaining months in 2024, starting from September 2024\n",
        "testing_set = data.loc['2024-06':]\n"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1731532807254
        }
      },
      "id": "c435bd6b-edad-4602-8ab6-952796e778cd"
    },
    {
      "cell_type": "code",
      "source": [
        "training_set.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "                     Longitude\nReceived_Timestamp            \n2023-01-01 00:00:00   0.603455\n2023-01-01 06:00:00   0.609879\n2023-01-01 12:00:00   0.619715\n2023-01-01 18:00:00   0.626964\n2023-01-02 00:00:00   0.635948",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Longitude</th>\n    </tr>\n    <tr>\n      <th>Received_Timestamp</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2023-01-01 00:00:00</th>\n      <td>0.603455</td>\n    </tr>\n    <tr>\n      <th>2023-01-01 06:00:00</th>\n      <td>0.609879</td>\n    </tr>\n    <tr>\n      <th>2023-01-01 12:00:00</th>\n      <td>0.619715</td>\n    </tr>\n    <tr>\n      <th>2023-01-01 18:00:00</th>\n      <td>0.626964</td>\n    </tr>\n    <tr>\n      <th>2023-01-02 00:00:00</th>\n      <td>0.635948</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1731532807556
        }
      },
      "id": "b6d7c039-2321-4ef2-b487-44760a8ecf11"
    },
    {
      "cell_type": "code",
      "source": [
        "testing_set.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "                     Longitude\nReceived_Timestamp            \n2024-06-01 00:00:00   0.553587\n2024-06-01 06:00:00   0.544791\n2024-06-01 12:00:00   0.537876\n2024-06-01 18:00:00   0.530367\n2024-06-02 00:00:00   0.522785",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Longitude</th>\n    </tr>\n    <tr>\n      <th>Received_Timestamp</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2024-06-01 00:00:00</th>\n      <td>0.553587</td>\n    </tr>\n    <tr>\n      <th>2024-06-01 06:00:00</th>\n      <td>0.544791</td>\n    </tr>\n    <tr>\n      <th>2024-06-01 12:00:00</th>\n      <td>0.537876</td>\n    </tr>\n    <tr>\n      <th>2024-06-01 18:00:00</th>\n      <td>0.530367</td>\n    </tr>\n    <tr>\n      <th>2024-06-02 00:00:00</th>\n      <td>0.522785</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1731532807840
        }
      },
      "id": "a6725ebf-dc94-4b4c-aa94-a506d03bd02a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Sliding window approach"
      ],
      "metadata": {},
      "id": "11534071-f383-4583-a99d-1421b3a5b218"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input window size (20 data points)\n",
        "input_window_size = 28\n",
        "# Define the output window size (1 data point)\n",
        "output_window_size = 1\n",
        "# Define the stride, which determines how much to move forward for each new window (1 data point)\n",
        "stride = 1"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1731532808066
        }
      },
      "id": "76efb32f-016a-4de6-9ffd-31dd00dbbd30"
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply sliding window to create sequences\n",
        "# Initialize empty lists to store the input (X) and output (y) sequences\n",
        "X, y = [], []\n",
        "\n",
        "# Loop through the dataset to create windows of input and output sequences\n",
        "for i in range(0, len(training_set) - input_window_size - output_window_size + 1, stride):\n",
        "    # Define the input window, which is a slice of 20 data points\n",
        "    input_window = training_set.iloc[i:i+input_window_size][['Longitude']]\n",
        "    # Define the output window, which is a slice of 1 data point immediately following the input window\n",
        "    output_window = training_set.iloc[i+input_window_size:i+input_window_size+output_window_size][['Longitude']]\n",
        "    # Append the input window data to X and the last value of output window to y\n",
        "    X.append(input_window.values)\n",
        "    y.append(output_window.values[-1])"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1731532808336
        }
      },
      "id": "8f32ba08-62a7-4e23-a81d-d59f6e14722c"
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert X and y lists to numpy arrays for model input\n",
        "X, y = np.array(X), np.array(y)\n",
        "\n",
        "# Print the number of samples created\n",
        "print(f\"Number of samples: {X.shape[0]}\")\n",
        "# Print the shape of the input (X) and output (y) arrays\n",
        "print(f\"Input shape: {X.shape}, Target shape: {y.shape}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Number of samples: 2040\nInput shape: (2040, 28, 1), Target shape: (2040, 1)\n"
        }
      ],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1731532808544
        }
      },
      "id": "8b093cc8-84c1-45a9-a73f-19c77653909b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Define LSTM model architecture"
      ],
      "metadata": {},
      "id": "b8cfcfe8-106f-4e8b-bdf5-e7f7dc1cfe0c"
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary modules\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Define a function to create an LSTM model with specified hyperparameters\n",
        "def build_model(units=50, lstm_layers=2, dropout_rate=0.2, recurrent_dropout=0.2, activation='tanh', learning_rate=0.001):\n",
        "    \"\"\"\n",
        "    Builds an LSTM model with the given parameters.\n",
        "\n",
        "    Parameters:\n",
        "        units (int): Number of units in each LSTM layer.\n",
        "        lstm_layers (int): Number of stacked LSTM layers.\n",
        "        dropout_rate (float): Dropout rate for regularization.\n",
        "        recurrent_dropout (float): Dropout rate for the recurrent connections.\n",
        "        activation (str): Activation function for LSTM layers.\n",
        "        learning_rate (float): Learning rate for the optimizer.\n",
        "\n",
        "    Returns:\n",
        "        model (Sequential): Compiled Keras model ready for training.\n",
        "    \"\"\"\n",
        "    # Initialize a Sequential model\n",
        "    model = Sequential()\n",
        "    \n",
        "    # Add LSTM layers\n",
        "    for i in range(lstm_layers - 1):\n",
        "        # Add intermediate LSTM layers with return_sequences=True for stacking\n",
        "        model.add(LSTM(units=units, activation=activation, return_sequences=True, dropout=dropout_rate, recurrent_dropout=recurrent_dropout))\n",
        "    \n",
        "    # Add the final LSTM layer without return_sequences, as this is a many-to-one model\n",
        "    model.add(LSTM(units=units, activation=activation, dropout=dropout_rate, recurrent_dropout=recurrent_dropout))\n",
        "    \n",
        "    # Add a Dense layer with 1 unit for output (for regression)\n",
        "    model.add(Dense(1))\n",
        "    \n",
        "    # Initialize the Adam optimizer with the specified learning rate\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    \n",
        "    # Compile the model using mean squared error (MSE) as the loss function, which is suitable for regression\n",
        "    model.compile(optimizer=optimizer, loss='mse')\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Initialize variables to keep track of the best model and lowest validation loss\n",
        "best_model = None\n",
        "best_loss = float('inf')  # Start with a high initial loss for comparison\n",
        "\n",
        "# Define hyperparameter grids for tuning\n",
        "units_list = [50, 100, 150]       # Different numbers of units to try in LSTM layers\n",
        "layers_list = [1, 2, 3]           # Different numbers of LSTM layers to try\n",
        "dropout_list = [0.2, 0.3, 0.5]    # Different dropout rates to test for regularization\n",
        "learning_rates = [0.0001, 0.001, 0.005]  # Different learning rates for the optimizer\n",
        "batch_sizes = [16, 32, 48]        # Different batch sizes for training\n",
        "\n",
        "# Perform grid search across all combinations of hyperparameters\n",
        "for units in units_list:\n",
        "    for layers in layers_list:\n",
        "        for dropout in dropout_list:\n",
        "            for lr in learning_rates:\n",
        "                for batch_size in batch_sizes:\n",
        "                    # Print the current combination of hyperparameters being tested\n",
        "                    print(f\"Training model with units={units}, layers={layers}, dropout={dropout}, lr={lr}, batch_size={batch_size}\")\n",
        "                    \n",
        "                    # Build a model with the current set of hyperparameters\n",
        "                    model = build_model(units=units, lstm_layers=layers, dropout_rate=dropout, learning_rate=lr)\n",
        "                    \n",
        "                    # Define early stopping to stop training if validation loss doesn't improve for a number of epochs\n",
        "                    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "                    \n",
        "                    # Define learning rate scheduler to reduce learning rate if validation loss plateaus\n",
        "                    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
        "                    \n",
        "                    # Train the model on the data with a validation split of 30%\n",
        "                    # Early stopping and learning rate scheduler will be used as callbacks\n",
        "                    history = model.fit(X, y, \n",
        "                                        epochs=100, \n",
        "                                        batch_size=batch_size, \n",
        "                                        validation_split=0.3, \n",
        "                                        callbacks=[early_stopping, lr_scheduler], \n",
        "                                        verbose=1)\n",
        "                    \n",
        "                    # Retrieve the minimum validation loss achieved during training\n",
        "                    val_loss = min(history.history['val_loss'])\n",
        "                    \n",
        "                    # Check if the current model has achieved a lower validation loss than the best so far\n",
        "                    if val_loss < best_loss:\n",
        "                        # Update the best model and best loss\n",
        "                        best_loss = val_loss\n",
        "                        best_model = model\n",
        "                        best_params = (units, layers, dropout, lr, batch_size)\n",
        "                        best_history = history\n",
        "\n",
        "# At the end of the search, 'best_model' contains the model with the lowest validation loss\n",
        "# 'best_params' holds the parameters that yielded the best model, and 'best_history' contains the training history\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Training model with units=50, layers=1, dropout=0.2, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.2062 - val_loss: 0.0252 - learning_rate: 1.0000e-04\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0485 - val_loss: 0.0170 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0416 - val_loss: 0.0222 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0278 - val_loss: 0.0343 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0163 - val_loss: 0.0595 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0102 - val_loss: 0.0689 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0076 - val_loss: 0.0736 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0072 - val_loss: 0.0746 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0066 - val_loss: 0.0757 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0064 - val_loss: 0.0769 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0067 - val_loss: 0.0776 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0075 - val_loss: 0.0771 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.2, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.2127 - val_loss: 0.0682 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0722 - val_loss: 0.0137 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0530 - val_loss: 0.0164 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0489 - val_loss: 0.0171 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0377 - val_loss: 0.0204 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0346 - val_loss: 0.0223 - learning_rate: 5.0000e-05\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0334 - val_loss: 0.0253 - learning_rate: 5.0000e-05\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0277 - val_loss: 0.0293 - learning_rate: 5.0000e-05\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0245 - val_loss: 0.0317 - learning_rate: 2.5000e-05\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0227 - val_loss: 0.0343 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0213 - val_loss: 0.0375 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0199 - val_loss: 0.0389 - learning_rate: 1.2500e-05\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.2, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.2589 - val_loss: 0.1627 - learning_rate: 1.0000e-04\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1731 - val_loss: 0.0842 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0939 - val_loss: 0.0271 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0563 - val_loss: 0.0140 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0528 - val_loss: 0.0162 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0538 - val_loss: 0.0159 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0439 - val_loss: 0.0177 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0469 - val_loss: 0.0182 - learning_rate: 5.0000e-05\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0372 - val_loss: 0.0186 - learning_rate: 5.0000e-05\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0418 - val_loss: 0.0195 - learning_rate: 5.0000e-05\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0386 - val_loss: 0.0199 - learning_rate: 2.5000e-05\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0359 - val_loss: 0.0204 - learning_rate: 2.5000e-05\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0391 - val_loss: 0.0211 - learning_rate: 2.5000e-05\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0339 - val_loss: 0.0214 - learning_rate: 1.2500e-05\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.2, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0843 - val_loss: 0.0716 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0054 - val_loss: 0.0790 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0045 - val_loss: 0.0799 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0036 - val_loss: 0.0814 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0035 - val_loss: 0.0782 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0032 - val_loss: 0.0774 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0031 - val_loss: 0.0799 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0028 - val_loss: 0.0745 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0026 - val_loss: 0.0732 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0026 - val_loss: 0.0657 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0028 - val_loss: 0.0753 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0020 - val_loss: 0.0684 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0021 - val_loss: 0.0699 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0020 - val_loss: 0.0692 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0021 - val_loss: 0.0681 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0022 - val_loss: 0.0693 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0018 - val_loss: 0.0681 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0019 - val_loss: 0.0693 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0020 - val_loss: 0.0682 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0019 - val_loss: 0.0678 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.2, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.1304 - val_loss: 0.0251 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0213 - val_loss: 0.0623 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0073 - val_loss: 0.0852 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0050 - val_loss: 0.0820 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0044 - val_loss: 0.0824 - learning_rate: 5.0000e-04\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0040 - val_loss: 0.0880 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0039 - val_loss: 0.0872 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0037 - val_loss: 0.0871 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0035 - val_loss: 0.0845 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0037 - val_loss: 0.0829 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0036 - val_loss: 0.0842 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.2, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.1584 - val_loss: 0.0277 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0300 - val_loss: 0.0351 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0152 - val_loss: 0.0610 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0060 - val_loss: 0.0850 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0049 - val_loss: 0.0855 - learning_rate: 5.0000e-04\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0050 - val_loss: 0.0841 - learning_rate: 5.0000e-04\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0045 - val_loss: 0.0842 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0045 - val_loss: 0.0849 - learning_rate: 2.5000e-04\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0042 - val_loss: 0.0854 - learning_rate: 2.5000e-04\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0045 - val_loss: 0.0860 - learning_rate: 2.5000e-04\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0042 - val_loss: 0.0854 - learning_rate: 1.2500e-04\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.2, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0504 - val_loss: 0.0867 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0038 - val_loss: 0.0895 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0037 - val_loss: 0.0715 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0032 - val_loss: 0.0760 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0022 - val_loss: 0.0738 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0024 - val_loss: 0.0631 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0019 - val_loss: 0.0601 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0016 - val_loss: 0.0689 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0013 - val_loss: 0.0707 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0015 - val_loss: 0.0726 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0715 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 0.0653 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0010 - val_loss: 0.0692 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 0.0660 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0010 - val_loss: 0.0657 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.4125e-04 - val_loss: 0.0644 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 9.4184e-04 - val_loss: 0.0645 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.2, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0804 - val_loss: 0.0691 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0055 - val_loss: 0.0920 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0040 - val_loss: 0.0896 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0037 - val_loss: 0.0877 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0036 - val_loss: 0.0814 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0035 - val_loss: 0.0839 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0036 - val_loss: 0.0855 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0030 - val_loss: 0.0821 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0030 - val_loss: 0.0775 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0030 - val_loss: 0.0806 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0030 - val_loss: 0.0798 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.2, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0714 - val_loss: 0.0535 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0052 - val_loss: 0.0949 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0041 - val_loss: 0.0886 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0037 - val_loss: 0.0849 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0036 - val_loss: 0.0853 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0035 - val_loss: 0.0857 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0035 - val_loss: 0.0801 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0035 - val_loss: 0.0834 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0032 - val_loss: 0.0831 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0033 - val_loss: 0.0810 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0032 - val_loss: 0.0795 - learning_rate: 6.2500e-04\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.3, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.3543 - val_loss: 0.1115 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0879 - val_loss: 0.0279 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0596 - val_loss: 0.0301 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0373 - val_loss: 0.0403 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0239 - val_loss: 0.0610 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0139 - val_loss: 0.0695 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0118 - val_loss: 0.0741 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0097 - val_loss: 0.0775 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0096 - val_loss: 0.0777 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0092 - val_loss: 0.0779 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0085 - val_loss: 0.0779 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0084 - val_loss: 0.0786 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.3, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.1850 - val_loss: 0.0560 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0984 - val_loss: 0.0224 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0741 - val_loss: 0.0227 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0663 - val_loss: 0.0236 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0522 - val_loss: 0.0287 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0390 - val_loss: 0.0339 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0301 - val_loss: 0.0421 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0227 - val_loss: 0.0530 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0174 - val_loss: 0.0577 - learning_rate: 2.5000e-05\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0156 - val_loss: 0.0627 - learning_rate: 2.5000e-05\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0134 - val_loss: 0.0669 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0121 - val_loss: 0.0690 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.3, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.3085 - val_loss: 0.1885 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1951 - val_loss: 0.0988 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1178 - val_loss: 0.0387 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0832 - val_loss: 0.0231 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0710 - val_loss: 0.0235 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0599 - val_loss: 0.0238 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0607 - val_loss: 0.0252 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0475 - val_loss: 0.0261 - learning_rate: 5.0000e-05\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0444 - val_loss: 0.0273 - learning_rate: 5.0000e-05\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0405 - val_loss: 0.0298 - learning_rate: 5.0000e-05\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0408 - val_loss: 0.0309 - learning_rate: 2.5000e-05\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0328 - val_loss: 0.0327 - learning_rate: 2.5000e-05\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0349 - val_loss: 0.0344 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0312 - val_loss: 0.0353 - learning_rate: 1.2500e-05\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.3, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1275 - val_loss: 0.0844 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0054 - val_loss: 0.0889 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0043 - val_loss: 0.0889 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0040 - val_loss: 0.0904 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0036 - val_loss: 0.0852 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0034 - val_loss: 0.0832 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0033 - val_loss: 0.0837 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0031 - val_loss: 0.0830 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0030 - val_loss: 0.0823 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0031 - val_loss: 0.0799 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0027 - val_loss: 0.0811 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0024 - val_loss: 0.0751 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0024 - val_loss: 0.0757 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0023 - val_loss: 0.0766 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0021 - val_loss: 0.0787 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0019 - val_loss: 0.0774 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0020 - val_loss: 0.0783 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0021 - val_loss: 0.0765 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0019 - val_loss: 0.0747 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0017 - val_loss: 0.0740 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0019 - val_loss: 0.0765 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0016 - val_loss: 0.0766 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0019 - val_loss: 0.0734 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0019 - val_loss: 0.0767 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 25/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0018 - val_loss: 0.0776 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 26/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0018 - val_loss: 0.0762 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 27/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0017 - val_loss: 0.0759 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nEpoch 28/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0015 - val_loss: 0.0749 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nEpoch 29/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0020 - val_loss: 0.0761 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nEpoch 30/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0017 - val_loss: 0.0772 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\nEpoch 31/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0017 - val_loss: 0.0746 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\nEpoch 32/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0018 - val_loss: 0.0763 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\nEpoch 33/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0016 - val_loss: 0.0759 - learning_rate: 1.5625e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.3, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.1634 - val_loss: 0.0326 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0198 - val_loss: 0.0871 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0060 - val_loss: 0.0888 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0049 - val_loss: 0.0938 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0043 - val_loss: 0.0925 - learning_rate: 5.0000e-04\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0041 - val_loss: 0.0925 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0041 - val_loss: 0.0906 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0043 - val_loss: 0.0931 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0042 - val_loss: 0.0903 - learning_rate: 2.5000e-04\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0039 - val_loss: 0.0925 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0040 - val_loss: 0.0912 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.3, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.2148 - val_loss: 0.0320 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0360 - val_loss: 0.0609 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0103 - val_loss: 0.0915 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0073 - val_loss: 0.0874 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0060 - val_loss: 0.0863 - learning_rate: 5.0000e-04\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0056 - val_loss: 0.0883 - learning_rate: 5.0000e-04\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0053 - val_loss: 0.0884 - learning_rate: 5.0000e-04\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0051 - val_loss: 0.0898 - learning_rate: 2.5000e-04\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0052 - val_loss: 0.0894 - learning_rate: 2.5000e-04\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0047 - val_loss: 0.0894 - learning_rate: 2.5000e-04\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0046 - val_loss: 0.0891 - learning_rate: 1.2500e-04\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.3, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0516 - val_loss: 0.0901 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0042 - val_loss: 0.0861 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0037 - val_loss: 0.0824 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0035 - val_loss: 0.0898 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0034 - val_loss: 0.0800 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0027 - val_loss: 0.0810 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0023 - val_loss: 0.0840 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0021 - val_loss: 0.0800 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0017 - val_loss: 0.0709 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0017 - val_loss: 0.0782 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0014 - val_loss: 0.0782 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0015 - val_loss: 0.0765 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0015 - val_loss: 0.0782 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0015 - val_loss: 0.0711 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0014 - val_loss: 0.0757 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0015 - val_loss: 0.0787 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0013 - val_loss: 0.0745 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0013 - val_loss: 0.0740 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0014 - val_loss: 0.0760 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.3, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0847 - val_loss: 0.0859 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0043 - val_loss: 0.0921 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0038 - val_loss: 0.0905 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0037 - val_loss: 0.0839 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0033 - val_loss: 0.0810 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0032 - val_loss: 0.0756 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0027 - val_loss: 0.0764 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0024 - val_loss: 0.0851 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0023 - val_loss: 0.0855 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0020 - val_loss: 0.0792 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0021 - val_loss: 0.0827 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0019 - val_loss: 0.0783 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0014 - val_loss: 0.0768 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0019 - val_loss: 0.0749 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0016 - val_loss: 0.0742 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0017 - val_loss: 0.0777 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0016 - val_loss: 0.0752 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - val_loss: 0.0775 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - val_loss: 0.0757 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0016 - val_loss: 0.0750 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0015 - val_loss: 0.0748 - learning_rate: 6.2500e-04\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0017 - val_loss: 0.0779 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - val_loss: 0.0785 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - val_loss: 0.0763 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 25/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0016 - val_loss: 0.0776 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.3, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.1118 - val_loss: 0.0719 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0050 - val_loss: 0.0849 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0043 - val_loss: 0.0912 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0039 - val_loss: 0.0876 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0035 - val_loss: 0.0914 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0036 - val_loss: 0.0894 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0037 - val_loss: 0.0885 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0036 - val_loss: 0.0868 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0036 - val_loss: 0.0863 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0033 - val_loss: 0.0879 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0033 - val_loss: 0.0843 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.5, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.2852 - val_loss: 0.0583 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1136 - val_loss: 0.0357 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0497 - val_loss: 0.0732 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0157 - val_loss: 0.0865 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0122 - val_loss: 0.0901 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0104 - val_loss: 0.0923 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0095 - val_loss: 0.0904 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0092 - val_loss: 0.0928 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0086 - val_loss: 0.0919 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0088 - val_loss: 0.0926 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0079 - val_loss: 0.0923 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0074 - val_loss: 0.0929 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.5, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.2668 - val_loss: 0.1366 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1674 - val_loss: 0.0593 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1232 - val_loss: 0.0424 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0864 - val_loss: 0.0389 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0603 - val_loss: 0.0508 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0218 - val_loss: 0.0826 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0151 - val_loss: 0.0792 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0120 - val_loss: 0.0804 - learning_rate: 5.0000e-05\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0130 - val_loss: 0.0811 - learning_rate: 5.0000e-05\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0101 - val_loss: 0.0819 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0112 - val_loss: 0.0818 - learning_rate: 2.5000e-05\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0102 - val_loss: 0.0825 - learning_rate: 2.5000e-05\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0115 - val_loss: 0.0836 - learning_rate: 2.5000e-05\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0102 - val_loss: 0.0840 - learning_rate: 1.2500e-05\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.5, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.2213 - val_loss: 0.1204 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1728 - val_loss: 0.0692 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1389 - val_loss: 0.0499 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1211 - val_loss: 0.0458 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1012 - val_loss: 0.0408 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0748 - val_loss: 0.0400 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0404 - val_loss: 0.0675 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0148 - val_loss: 0.0788 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0141 - val_loss: 0.0789 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0129 - val_loss: 0.0771 - learning_rate: 5.0000e-05\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0136 - val_loss: 0.0782 - learning_rate: 5.0000e-05\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0125 - val_loss: 0.0788 - learning_rate: 5.0000e-05\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0117 - val_loss: 0.0794 - learning_rate: 2.5000e-05\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0103 - val_loss: 0.0796 - learning_rate: 2.5000e-05\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0109 - val_loss: 0.0792 - learning_rate: 2.5000e-05\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0111 - val_loss: 0.0792 - learning_rate: 1.2500e-05\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.5, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1929 - val_loss: 0.0940 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0062 - val_loss: 0.0902 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0047 - val_loss: 0.0916 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0042 - val_loss: 0.0874 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0041 - val_loss: 0.0900 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0037 - val_loss: 0.0937 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0035 - val_loss: 0.0888 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0032 - val_loss: 0.0909 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0032 - val_loss: 0.0928 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0032 - val_loss: 0.0946 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0030 - val_loss: 0.0940 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0030 - val_loss: 0.0919 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0029 - val_loss: 0.0928 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0030 - val_loss: 0.0932 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.5, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.1562 - val_loss: 0.0983 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0090 - val_loss: 0.0895 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0050 - val_loss: 0.0922 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0044 - val_loss: 0.0912 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0040 - val_loss: 0.0888 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0039 - val_loss: 0.0955 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0038 - val_loss: 0.0917 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0031 - val_loss: 0.0912 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0029 - val_loss: 0.0914 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0029 - val_loss: 0.0927 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0029 - val_loss: 0.0959 - learning_rate: 5.0000e-04\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0030 - val_loss: 0.0949 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0027 - val_loss: 0.0932 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0028 - val_loss: 0.0929 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0027 - val_loss: 0.0943 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.5, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.3821 - val_loss: 0.0325 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0387 - val_loss: 0.0894 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0088 - val_loss: 0.0939 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0075 - val_loss: 0.0908 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0067 - val_loss: 0.0910 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0062 - val_loss: 0.0915 - learning_rate: 5.0000e-04\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0061 - val_loss: 0.0926 - learning_rate: 5.0000e-04\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0062 - val_loss: 0.0925 - learning_rate: 2.5000e-04\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0057 - val_loss: 0.0940 - learning_rate: 2.5000e-04\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0052 - val_loss: 0.0932 - learning_rate: 2.5000e-04\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0053 - val_loss: 0.0933 - learning_rate: 1.2500e-04\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.5, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0504 - val_loss: 0.0948 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0041 - val_loss: 0.0946 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0036 - val_loss: 0.0903 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0037 - val_loss: 0.0944 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0031 - val_loss: 0.0934 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0029 - val_loss: 0.0892 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0027 - val_loss: 0.0929 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0023 - val_loss: 0.1071 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0025 - val_loss: 0.0956 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0024 - val_loss: 0.1033 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0023 - val_loss: 0.0991 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0024 - val_loss: 0.1010 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0022 - val_loss: 0.0986 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0024 - val_loss: 0.0992 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0022 - val_loss: 0.1006 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0023 - val_loss: 0.1023 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.5, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0971 - val_loss: 0.0896 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0043 - val_loss: 0.0969 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0040 - val_loss: 0.0933 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0039 - val_loss: 0.0957 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0037 - val_loss: 0.0910 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0034 - val_loss: 0.0935 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0031 - val_loss: 0.0952 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0032 - val_loss: 0.0937 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0027 - val_loss: 0.0916 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0029 - val_loss: 0.0988 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0027 - val_loss: 0.0950 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=1, dropout=0.5, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.1391 - val_loss: 0.0952 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0051 - val_loss: 0.0951 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0040 - val_loss: 0.0937 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0040 - val_loss: 0.0929 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0038 - val_loss: 0.0966 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0037 - val_loss: 0.0959 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0036 - val_loss: 0.0942 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0033 - val_loss: 0.0951 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0032 - val_loss: 0.0912 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0030 - val_loss: 0.0947 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0030 - val_loss: 0.0962 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0029 - val_loss: 0.0959 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0029 - val_loss: 0.0966 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0028 - val_loss: 0.0952 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0027 - val_loss: 0.0972 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0024 - val_loss: 0.0971 - learning_rate: 6.2500e-04\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0025 - val_loss: 0.0984 - learning_rate: 6.2500e-04\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0025 - val_loss: 0.0965 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0028 - val_loss: 0.0969 - learning_rate: 3.1250e-04\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.2, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.1567 - val_loss: 0.0167 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0466 - val_loss: 0.0241 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0282 - val_loss: 0.0463 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0157 - val_loss: 0.0722 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0092 - val_loss: 0.0788 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0072 - val_loss: 0.0826 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0072 - val_loss: 0.0855 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0065 - val_loss: 0.0859 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0064 - val_loss: 0.0858 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0061 - val_loss: 0.0864 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0058 - val_loss: 0.0871 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.2, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 0.3141 - val_loss: 0.0864 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0856 - val_loss: 0.0123 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0560 - val_loss: 0.0162 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0429 - val_loss: 0.0184 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0414 - val_loss: 0.0229 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0352 - val_loss: 0.0265 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0282 - val_loss: 0.0300 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0275 - val_loss: 0.0349 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0222 - val_loss: 0.0375 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0225 - val_loss: 0.0402 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0188 - val_loss: 0.0432 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0165 - val_loss: 0.0449 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.2, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.3405 - val_loss: 0.1675 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1555 - val_loss: 0.0353 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0583 - val_loss: 0.0152 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0466 - val_loss: 0.0205 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0419 - val_loss: 0.0215 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0334 - val_loss: 0.0255 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0331 - val_loss: 0.0276 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0290 - val_loss: 0.0302 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0256 - val_loss: 0.0333 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0276 - val_loss: 0.0350 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0232 - val_loss: 0.0368 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0242 - val_loss: 0.0388 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0212 - val_loss: 0.0397 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.2, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.1215 - val_loss: 0.0711 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0062 - val_loss: 0.0860 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0048 - val_loss: 0.0834 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0043 - val_loss: 0.0906 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0041 - val_loss: 0.0866 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0040 - val_loss: 0.0840 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0035 - val_loss: 0.0824 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0039 - val_loss: 0.0849 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0034 - val_loss: 0.0842 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0034 - val_loss: 0.0849 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0036 - val_loss: 0.0845 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.2, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 0.1624 - val_loss: 0.0343 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0158 - val_loss: 0.0726 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0062 - val_loss: 0.0878 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0049 - val_loss: 0.0928 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0048 - val_loss: 0.0911 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0045 - val_loss: 0.0922 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0045 - val_loss: 0.0919 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0044 - val_loss: 0.0894 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0042 - val_loss: 0.0876 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0040 - val_loss: 0.0906 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0044 - val_loss: 0.0908 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.2, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.1367 - val_loss: 0.0308 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0189 - val_loss: 0.0607 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0083 - val_loss: 0.0827 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0060 - val_loss: 0.0832 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0051 - val_loss: 0.0871 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0049 - val_loss: 0.0879 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0046 - val_loss: 0.0919 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0043 - val_loss: 0.0877 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0046 - val_loss: 0.0888 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0043 - val_loss: 0.0883 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0041 - val_loss: 0.0885 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.2, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.0611 - val_loss: 0.0891 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0045 - val_loss: 0.0880 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0043 - val_loss: 0.0877 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0038 - val_loss: 0.0989 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0036 - val_loss: 0.0801 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0032 - val_loss: 0.0767 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0024 - val_loss: 0.0879 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0020 - val_loss: 0.1005 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0018 - val_loss: 0.0868 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0014 - val_loss: 0.0790 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0012 - val_loss: 0.0898 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0012 - val_loss: 0.0820 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0012 - val_loss: 0.0791 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0011 - val_loss: 0.0867 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0014 - val_loss: 0.0733 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0013 - val_loss: 0.0761 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0010 - val_loss: 0.0746 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0011 - val_loss: 0.0828 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0011 - val_loss: 0.0772 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0011 - val_loss: 0.0810 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0012 - val_loss: 0.0776 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 9.6570e-04 - val_loss: 0.0781 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0010 - val_loss: 0.0781 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0010 - val_loss: 0.0772 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 25/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0010 - val_loss: 0.0777 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.2, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 0.0702 - val_loss: 0.0923 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0043 - val_loss: 0.0875 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0040 - val_loss: 0.0888 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0044 - val_loss: 0.0889 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0040 - val_loss: 0.0875 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0037 - val_loss: 0.0890 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0033 - val_loss: 0.0863 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0032 - val_loss: 0.0844 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0026 - val_loss: 0.0810 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0022 - val_loss: 0.0881 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0019 - val_loss: 0.0925 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0019 - val_loss: 0.0873 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0017 - val_loss: 0.0803 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0018 - val_loss: 0.0865 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0016 - val_loss: 0.0819 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0016 - val_loss: 0.0839 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0015 - val_loss: 0.0752 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0015 - val_loss: 0.0822 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0013 - val_loss: 0.0823 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0015 - val_loss: 0.0878 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0013 - val_loss: 0.0859 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0013 - val_loss: 0.0808 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0014 - val_loss: 0.0823 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0012 - val_loss: 0.0836 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 25/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0013 - val_loss: 0.0821 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\nEpoch 26/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0012 - val_loss: 0.0815 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\nEpoch 27/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0013 - val_loss: 0.0845 - learning_rate: 7.8125e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.2, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0861 - val_loss: 0.0901 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0048 - val_loss: 0.0939 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0040 - val_loss: 0.0868 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0041 - val_loss: 0.0916 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0041 - val_loss: 0.0882 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0041 - val_loss: 0.0861 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0041 - val_loss: 0.0923 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0037 - val_loss: 0.0902 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0035 - val_loss: 0.0833 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0035 - val_loss: 0.0795 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0032 - val_loss: 0.0828 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0027 - val_loss: 0.0918 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0022 - val_loss: 0.0854 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0018 - val_loss: 0.0764 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0018 - val_loss: 0.0765 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0016 - val_loss: 0.0913 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0015 - val_loss: 0.0878 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0013 - val_loss: 0.0908 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0016 - val_loss: 0.0817 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0014 - val_loss: 0.0890 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0013 - val_loss: 0.0820 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0012 - val_loss: 0.0835 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0013 - val_loss: 0.0850 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0014 - val_loss: 0.0850 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.3, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.2033 - val_loss: 0.0228 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0591 - val_loss: 0.0333 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0272 - val_loss: 0.0710 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0120 - val_loss: 0.0863 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0095 - val_loss: 0.0854 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0095 - val_loss: 0.0864 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0087 - val_loss: 0.0843 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0079 - val_loss: 0.0851 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0076 - val_loss: 0.0866 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0078 - val_loss: 0.0855 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0078 - val_loss: 0.0862 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.3, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 0.3008 - val_loss: 0.0760 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0926 - val_loss: 0.0205 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0641 - val_loss: 0.0256 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0455 - val_loss: 0.0319 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0343 - val_loss: 0.0469 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0228 - val_loss: 0.0562 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0173 - val_loss: 0.0657 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0147 - val_loss: 0.0751 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0130 - val_loss: 0.0780 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0139 - val_loss: 0.0801 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0112 - val_loss: 0.0811 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0109 - val_loss: 0.0808 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.3, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 0.3096 - val_loss: 0.1500 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1456 - val_loss: 0.0313 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0815 - val_loss: 0.0228 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0641 - val_loss: 0.0239 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0579 - val_loss: 0.0255 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0482 - val_loss: 0.0308 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0399 - val_loss: 0.0343 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0310 - val_loss: 0.0383 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0300 - val_loss: 0.0439 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0238 - val_loss: 0.0471 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0211 - val_loss: 0.0502 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0185 - val_loss: 0.0534 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0184 - val_loss: 0.0550 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.3, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.0901 - val_loss: 0.0893 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0056 - val_loss: 0.0931 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0046 - val_loss: 0.0907 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0048 - val_loss: 0.0967 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0043 - val_loss: 0.0898 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0043 - val_loss: 0.0939 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0040 - val_loss: 0.0905 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0040 - val_loss: 0.0882 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0039 - val_loss: 0.0927 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0040 - val_loss: 0.0908 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0038 - val_loss: 0.0914 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0039 - val_loss: 0.0892 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0037 - val_loss: 0.0902 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0040 - val_loss: 0.0913 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0039 - val_loss: 0.0910 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0035 - val_loss: 0.0908 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0038 - val_loss: 0.0922 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0038 - val_loss: 0.0911 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.3, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 0.1223 - val_loss: 0.0681 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0076 - val_loss: 0.0849 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0051 - val_loss: 0.0916 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0046 - val_loss: 0.0927 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0045 - val_loss: 0.0945 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0040 - val_loss: 0.0951 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0041 - val_loss: 0.0955 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0038 - val_loss: 0.0919 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0042 - val_loss: 0.0935 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0041 - val_loss: 0.0945 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0042 - val_loss: 0.0925 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.3, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.1903 - val_loss: 0.0412 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0163 - val_loss: 0.0921 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0064 - val_loss: 0.0907 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0052 - val_loss: 0.0892 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0050 - val_loss: 0.0901 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0049 - val_loss: 0.0918 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0046 - val_loss: 0.0933 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0050 - val_loss: 0.0927 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0047 - val_loss: 0.0913 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0043 - val_loss: 0.0924 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0045 - val_loss: 0.0933 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.3, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.0550 - val_loss: 0.0917 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0042 - val_loss: 0.0957 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0045 - val_loss: 0.1022 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0041 - val_loss: 0.0855 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0037 - val_loss: 0.0893 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0034 - val_loss: 0.0796 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0033 - val_loss: 0.0984 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0023 - val_loss: 0.0818 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0024 - val_loss: 0.1082 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0022 - val_loss: 0.0916 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0020 - val_loss: 0.0877 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0017 - val_loss: 0.0864 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0018 - val_loss: 0.0879 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0018 - val_loss: 0.0892 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0020 - val_loss: 0.0850 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0017 - val_loss: 0.0820 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.3, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 0.0769 - val_loss: 0.0881 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0044 - val_loss: 0.0951 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0043 - val_loss: 0.0923 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0043 - val_loss: 0.0963 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0040 - val_loss: 0.0916 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0040 - val_loss: 0.0910 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0037 - val_loss: 0.0836 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0036 - val_loss: 0.0832 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0037 - val_loss: 0.0953 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0032 - val_loss: 0.0861 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0031 - val_loss: 0.0962 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0028 - val_loss: 0.0894 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0027 - val_loss: 0.0881 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0022 - val_loss: 0.0880 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0021 - val_loss: 0.0839 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0022 - val_loss: 0.0847 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0020 - val_loss: 0.0860 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0020 - val_loss: 0.0886 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.3, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0705 - val_loss: 0.0953 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0044 - val_loss: 0.0927 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0043 - val_loss: 0.0939 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0041 - val_loss: 0.0956 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0042 - val_loss: 0.0885 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0042 - val_loss: 0.0998 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0042 - val_loss: 0.0937 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0039 - val_loss: 0.0900 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0037 - val_loss: 0.0876 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0038 - val_loss: 0.0927 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0034 - val_loss: 0.0892 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0034 - val_loss: 0.0839 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0030 - val_loss: 0.0876 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0029 - val_loss: 0.0883 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0029 - val_loss: 0.0916 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0026 - val_loss: 0.0908 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0024 - val_loss: 0.0912 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0021 - val_loss: 0.0889 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0021 - val_loss: 0.0892 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0024 - val_loss: 0.0866 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0020 - val_loss: 0.0916 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0020 - val_loss: 0.0885 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.5, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.3184 - val_loss: 0.0359 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0973 - val_loss: 0.0438 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0338 - val_loss: 0.0816 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0166 - val_loss: 0.0906 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0136 - val_loss: 0.0916 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0106 - val_loss: 0.0954 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0099 - val_loss: 0.0998 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0093 - val_loss: 0.0955 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0084 - val_loss: 0.0965 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0087 - val_loss: 0.0978 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0086 - val_loss: 0.0968 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.5, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 0.2977 - val_loss: 0.0889 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.1329 - val_loss: 0.0390 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0914 - val_loss: 0.0381 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0511 - val_loss: 0.0663 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0194 - val_loss: 0.0848 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0161 - val_loss: 0.0864 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0146 - val_loss: 0.0878 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0129 - val_loss: 0.0871 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0128 - val_loss: 0.0883 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0115 - val_loss: 0.0895 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0109 - val_loss: 0.0894 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0103 - val_loss: 0.0895 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0109 - val_loss: 0.0898 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.5, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 32ms/step - loss: 0.2809 - val_loss: 0.1210 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1623 - val_loss: 0.0488 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.1255 - val_loss: 0.0413 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.1009 - val_loss: 0.0364 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0633 - val_loss: 0.0473 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0326 - val_loss: 0.0741 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0179 - val_loss: 0.0838 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0165 - val_loss: 0.0834 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0153 - val_loss: 0.0855 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0134 - val_loss: 0.0856 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0125 - val_loss: 0.0864 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0135 - val_loss: 0.0875 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0128 - val_loss: 0.0874 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0140 - val_loss: 0.0873 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.5, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.1164 - val_loss: 0.0998 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0054 - val_loss: 0.0945 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0047 - val_loss: 0.1015 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0043 - val_loss: 0.0996 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0044 - val_loss: 0.0939 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0043 - val_loss: 0.1028 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0045 - val_loss: 0.0990 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0046 - val_loss: 0.0940 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0042 - val_loss: 0.0933 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0042 - val_loss: 0.0946 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0040 - val_loss: 0.0955 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0041 - val_loss: 0.0953 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0040 - val_loss: 0.0945 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0039 - val_loss: 0.0959 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0039 - val_loss: 0.0979 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0038 - val_loss: 0.0939 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0039 - val_loss: 0.0967 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0040 - val_loss: 0.0959 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0037 - val_loss: 0.0946 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.5, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 0.1438 - val_loss: 0.1045 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0071 - val_loss: 0.0936 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0052 - val_loss: 0.0968 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0049 - val_loss: 0.1008 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0048 - val_loss: 0.1023 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0048 - val_loss: 0.0973 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0045 - val_loss: 0.0941 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0042 - val_loss: 0.0986 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0041 - val_loss: 0.0986 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0043 - val_loss: 0.0977 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0041 - val_loss: 0.0950 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0040 - val_loss: 0.0937 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.5, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.1621 - val_loss: 0.1039 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0123 - val_loss: 0.0875 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0072 - val_loss: 0.0925 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0062 - val_loss: 0.0984 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0061 - val_loss: 0.0937 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0047 - val_loss: 0.0929 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0048 - val_loss: 0.0957 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0050 - val_loss: 0.0944 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0047 - val_loss: 0.0950 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0046 - val_loss: 0.0938 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0045 - val_loss: 0.0950 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0043 - val_loss: 0.0954 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.5, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 0.0427 - val_loss: 0.0912 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0049 - val_loss: 0.0941 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0044 - val_loss: 0.0983 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0046 - val_loss: 0.0940 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0041 - val_loss: 0.0910 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0041 - val_loss: 0.0951 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0040 - val_loss: 0.0928 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0043 - val_loss: 0.0922 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0039 - val_loss: 0.0964 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0039 - val_loss: 0.0955 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0039 - val_loss: 0.0937 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0036 - val_loss: 0.1035 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0038 - val_loss: 0.0970 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0036 - val_loss: 0.0967 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0032 - val_loss: 0.0942 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.5, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 0.0917 - val_loss: 0.0914 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0046 - val_loss: 0.0970 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0042 - val_loss: 0.0953 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0042 - val_loss: 0.0994 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0043 - val_loss: 0.0922 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0043 - val_loss: 0.0911 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0043 - val_loss: 0.0940 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0042 - val_loss: 0.0937 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0042 - val_loss: 0.0951 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0040 - val_loss: 0.0968 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0040 - val_loss: 0.0975 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0041 - val_loss: 0.0947 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0041 - val_loss: 0.0937 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0040 - val_loss: 0.0976 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0041 - val_loss: 0.0974 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0039 - val_loss: 0.0962 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=2, dropout=0.5, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.1156 - val_loss: 0.1030 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0048 - val_loss: 0.0987 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0042 - val_loss: 0.0986 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0044 - val_loss: 0.0972 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0042 - val_loss: 0.0946 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0043 - val_loss: 0.0972 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0042 - val_loss: 0.0927 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0041 - val_loss: 0.0939 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0041 - val_loss: 0.1013 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0043 - val_loss: 0.0940 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0041 - val_loss: 0.0933 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0041 - val_loss: 0.0986 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0040 - val_loss: 0.0945 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0038 - val_loss: 0.0940 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0039 - val_loss: 0.0933 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0041 - val_loss: 0.0957 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0039 - val_loss: 0.0956 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.2, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 0.2168 - val_loss: 0.0189 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0464 - val_loss: 0.0309 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0272 - val_loss: 0.0537 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0138 - val_loss: 0.0745 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0093 - val_loss: 0.0783 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0079 - val_loss: 0.0839 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0069 - val_loss: 0.0868 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0082 - val_loss: 0.0854 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0074 - val_loss: 0.0881 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0070 - val_loss: 0.0893 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0070 - val_loss: 0.0883 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.2, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - loss: 0.2914 - val_loss: 0.0658 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0613 - val_loss: 0.0197 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0422 - val_loss: 0.0254 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0285 - val_loss: 0.0361 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0223 - val_loss: 0.0496 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0167 - val_loss: 0.0571 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0128 - val_loss: 0.0647 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0113 - val_loss: 0.0715 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0103 - val_loss: 0.0752 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0089 - val_loss: 0.0778 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0089 - val_loss: 0.0786 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0075 - val_loss: 0.0800 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.2, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - loss: 0.2646 - val_loss: 0.0847 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0849 - val_loss: 0.0138 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0511 - val_loss: 0.0202 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0409 - val_loss: 0.0235 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0337 - val_loss: 0.0290 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0309 - val_loss: 0.0326 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0252 - val_loss: 0.0362 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0245 - val_loss: 0.0407 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0209 - val_loss: 0.0429 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0213 - val_loss: 0.0448 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0192 - val_loss: 0.0472 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0195 - val_loss: 0.0486 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.2, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 0.0801 - val_loss: 0.0842 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0061 - val_loss: 0.0877 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0049 - val_loss: 0.0908 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0045 - val_loss: 0.0958 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0046 - val_loss: 0.0954 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0043 - val_loss: 0.0903 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0039 - val_loss: 0.0935 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0038 - val_loss: 0.0912 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0037 - val_loss: 0.0902 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0039 - val_loss: 0.0878 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0039 - val_loss: 0.0910 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.2, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.1041 - val_loss: 0.0580 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0096 - val_loss: 0.0856 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0059 - val_loss: 0.0897 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0049 - val_loss: 0.0925 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0044 - val_loss: 0.0943 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0048 - val_loss: 0.0899 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0044 - val_loss: 0.0923 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0042 - val_loss: 0.0912 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0042 - val_loss: 0.0925 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0043 - val_loss: 0.0922 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0043 - val_loss: 0.0921 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.2, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - loss: 0.1379 - val_loss: 0.0411 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0156 - val_loss: 0.0753 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0070 - val_loss: 0.0888 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0060 - val_loss: 0.0877 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0052 - val_loss: 0.0904 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0048 - val_loss: 0.0906 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0048 - val_loss: 0.0933 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0048 - val_loss: 0.0933 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0045 - val_loss: 0.0921 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0043 - val_loss: 0.0919 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0044 - val_loss: 0.0914 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.2, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 0.0443 - val_loss: 0.0888 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0047 - val_loss: 0.0968 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0045 - val_loss: 0.0917 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0040 - val_loss: 0.1003 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0045 - val_loss: 0.0881 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0037 - val_loss: 0.0977 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0038 - val_loss: 0.0967 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0035 - val_loss: 0.1040 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0033 - val_loss: 0.0777 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0022 - val_loss: 0.0783 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0021 - val_loss: 0.0778 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0018 - val_loss: 0.0796 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0016 - val_loss: 0.0781 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0017 - val_loss: 0.0821 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0016 - val_loss: 0.0889 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0015 - val_loss: 0.0825 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0017 - val_loss: 0.0854 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0015 - val_loss: 0.0841 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0013 - val_loss: 0.0811 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.2, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0489 - val_loss: 0.1015 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0049 - val_loss: 0.0963 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0044 - val_loss: 0.0903 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0041 - val_loss: 0.0853 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0051 - val_loss: 0.0863 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0044 - val_loss: 0.0931 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0039 - val_loss: 0.0924 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0038 - val_loss: 0.0932 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0032 - val_loss: 0.0911 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0028 - val_loss: 0.0981 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0025 - val_loss: 0.0924 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0019 - val_loss: 0.0854 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0020 - val_loss: 0.0928 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0017 - val_loss: 0.0843 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0018 - val_loss: 0.0833 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0016 - val_loss: 0.0874 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0017 - val_loss: 0.0863 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0016 - val_loss: 0.0907 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0015 - val_loss: 0.0880 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0015 - val_loss: 0.0879 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0015 - val_loss: 0.0831 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0014 - val_loss: 0.0871 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0016 - val_loss: 0.0854 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0017 - val_loss: 0.0813 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 25/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0014 - val_loss: 0.0870 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 26/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0015 - val_loss: 0.0824 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 27/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0017 - val_loss: 0.0859 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 28/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0015 - val_loss: 0.0825 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\nEpoch 29/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0016 - val_loss: 0.0871 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\nEpoch 30/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0013 - val_loss: 0.0850 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\nEpoch 31/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0014 - val_loss: 0.0865 - learning_rate: 7.8125e-05\b\b\b\b\b\b\b\nEpoch 32/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0014 - val_loss: 0.0828 - learning_rate: 7.8125e-05\b\b\b\b\b\b\b\nEpoch 33/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0013 - val_loss: 0.0847 - learning_rate: 7.8125e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 34/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0015 - val_loss: 0.0858 - learning_rate: 3.9062e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.2, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - loss: 0.1026 - val_loss: 0.0778 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0053 - val_loss: 0.0887 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0045 - val_loss: 0.0884 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0040 - val_loss: 0.0931 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0039 - val_loss: 0.0920 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0041 - val_loss: 0.0908 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0042 - val_loss: 0.0925 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0039 - val_loss: 0.0911 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0039 - val_loss: 0.0913 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0039 - val_loss: 0.0902 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0041 - val_loss: 0.0910 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.3, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - loss: 0.2406 - val_loss: 0.0243 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0546 - val_loss: 0.0370 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0282 - val_loss: 0.0649 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0133 - val_loss: 0.0827 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0107 - val_loss: 0.0886 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0088 - val_loss: 0.0906 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0088 - val_loss: 0.0911 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0069 - val_loss: 0.0918 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0077 - val_loss: 0.0924 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0069 - val_loss: 0.0935 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0066 - val_loss: 0.0929 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.3, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - loss: 0.2661 - val_loss: 0.0408 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0781 - val_loss: 0.0270 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0481 - val_loss: 0.0373 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0291 - val_loss: 0.0553 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0170 - val_loss: 0.0735 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0128 - val_loss: 0.0763 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0101 - val_loss: 0.0827 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0099 - val_loss: 0.0865 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0096 - val_loss: 0.0872 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0090 - val_loss: 0.0882 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0088 - val_loss: 0.0885 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0082 - val_loss: 0.0895 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.3, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 0.2628 - val_loss: 0.0786 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.1018 - val_loss: 0.0219 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0638 - val_loss: 0.0267 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0550 - val_loss: 0.0349 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0365 - val_loss: 0.0487 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0256 - val_loss: 0.0569 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0198 - val_loss: 0.0633 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0169 - val_loss: 0.0704 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0147 - val_loss: 0.0735 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0151 - val_loss: 0.0757 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0141 - val_loss: 0.0780 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0141 - val_loss: 0.0795 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.3, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - loss: 0.0875 - val_loss: 0.0906 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0056 - val_loss: 0.0981 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0047 - val_loss: 0.0989 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0042 - val_loss: 0.0927 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0042 - val_loss: 0.0986 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0042 - val_loss: 0.0936 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0044 - val_loss: 0.0924 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0042 - val_loss: 0.0982 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0041 - val_loss: 0.0961 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0041 - val_loss: 0.0961 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0041 - val_loss: 0.0970 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.3, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0950 - val_loss: 0.0958 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0057 - val_loss: 0.0933 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0051 - val_loss: 0.0951 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0046 - val_loss: 0.0931 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0044 - val_loss: 0.0988 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0044 - val_loss: 0.0962 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0043 - val_loss: 0.0943 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0043 - val_loss: 0.0909 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0043 - val_loss: 0.0961 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0043 - val_loss: 0.0975 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0042 - val_loss: 0.0955 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0042 - val_loss: 0.0976 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0040 - val_loss: 0.0932 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0041 - val_loss: 0.0969 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0041 - val_loss: 0.0970 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0040 - val_loss: 0.0975 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0039 - val_loss: 0.0923 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0044 - val_loss: 0.0935 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.3, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 46ms/step - loss: 0.1441 - val_loss: 0.0668 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0110 - val_loss: 0.0945 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0053 - val_loss: 0.0905 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0054 - val_loss: 0.0963 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0048 - val_loss: 0.0941 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0044 - val_loss: 0.0964 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0045 - val_loss: 0.0985 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0046 - val_loss: 0.0973 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0044 - val_loss: 0.0953 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0046 - val_loss: 0.0937 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0043 - val_loss: 0.0963 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.3, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - loss: 0.0399 - val_loss: 0.0957 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0049 - val_loss: 0.0939 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0057 - val_loss: 0.0957 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0042 - val_loss: 0.0904 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0044 - val_loss: 0.0919 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0047 - val_loss: 0.0886 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0041 - val_loss: 0.0919 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0039 - val_loss: 0.1015 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0045 - val_loss: 0.0951 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0041 - val_loss: 0.0952 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0041 - val_loss: 0.0973 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0037 - val_loss: 0.0893 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0032 - val_loss: 0.0922 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0031 - val_loss: 0.0907 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0026 - val_loss: 0.0871 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0022 - val_loss: 0.0877 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0022 - val_loss: 0.0947 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0021 - val_loss: 0.0899 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0021 - val_loss: 0.0878 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0020 - val_loss: 0.0913 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0022 - val_loss: 0.0913 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0020 - val_loss: 0.0892 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0018 - val_loss: 0.0939 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0019 - val_loss: 0.0935 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 25/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0022 - val_loss: 0.0925 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.3, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.0839 - val_loss: 0.1001 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0047 - val_loss: 0.0964 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0045 - val_loss: 0.0937 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0043 - val_loss: 0.0964 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0041 - val_loss: 0.0912 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0043 - val_loss: 0.0965 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0042 - val_loss: 0.1010 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0041 - val_loss: 0.0922 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0040 - val_loss: 0.0939 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0041 - val_loss: 0.0956 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0039 - val_loss: 0.0951 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0039 - val_loss: 0.0895 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0040 - val_loss: 0.0947 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0036 - val_loss: 0.0907 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0038 - val_loss: 0.0915 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0037 - val_loss: 0.0943 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0033 - val_loss: 0.0905 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0033 - val_loss: 0.0953 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0031 - val_loss: 0.0928 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0031 - val_loss: 0.0911 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0030 - val_loss: 0.0934 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0029 - val_loss: 0.0938 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.3, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - loss: 0.1170 - val_loss: 0.0960 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0052 - val_loss: 0.0939 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0044 - val_loss: 0.0924 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0046 - val_loss: 0.0900 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0042 - val_loss: 0.0918 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0043 - val_loss: 0.0962 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0042 - val_loss: 0.0924 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0040 - val_loss: 0.0949 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0041 - val_loss: 0.0935 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0039 - val_loss: 0.0899 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0041 - val_loss: 0.0959 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0039 - val_loss: 0.0922 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0040 - val_loss: 0.0953 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0039 - val_loss: 0.0942 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0039 - val_loss: 0.0924 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0038 - val_loss: 0.0979 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0040 - val_loss: 0.0961 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0040 - val_loss: 0.0946 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0039 - val_loss: 0.0950 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0040 - val_loss: 0.0943 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.5, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - loss: 0.2918 - val_loss: 0.0263 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0755 - val_loss: 0.0587 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0249 - val_loss: 0.0882 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0170 - val_loss: 0.0935 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0118 - val_loss: 0.0959 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0109 - val_loss: 0.0974 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0100 - val_loss: 0.0981 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0097 - val_loss: 0.0970 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0091 - val_loss: 0.0981 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0083 - val_loss: 0.0994 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0080 - val_loss: 0.0985 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.5, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - loss: 0.3649 - val_loss: 0.1184 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.1545 - val_loss: 0.0266 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0886 - val_loss: 0.0425 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0437 - val_loss: 0.0687 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0241 - val_loss: 0.0851 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0178 - val_loss: 0.0912 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0143 - val_loss: 0.0956 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0128 - val_loss: 0.0991 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0114 - val_loss: 0.0996 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0098 - val_loss: 0.0992 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0097 - val_loss: 0.1004 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0093 - val_loss: 0.1012 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.5, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - loss: 0.3277 - val_loss: 0.1424 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.1800 - val_loss: 0.0264 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.1134 - val_loss: 0.0303 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0737 - val_loss: 0.0447 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0448 - val_loss: 0.0656 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0277 - val_loss: 0.0737 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0234 - val_loss: 0.0827 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0197 - val_loss: 0.0829 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0193 - val_loss: 0.0879 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0179 - val_loss: 0.0886 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0149 - val_loss: 0.0917 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0141 - val_loss: 0.0919 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.5, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - loss: 0.0875 - val_loss: 0.0988 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0065 - val_loss: 0.0917 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0051 - val_loss: 0.0952 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0047 - val_loss: 0.1037 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0043 - val_loss: 0.0982 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0042 - val_loss: 0.0954 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0044 - val_loss: 0.0968 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0042 - val_loss: 0.0934 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0041 - val_loss: 0.1001 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0044 - val_loss: 0.1001 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0040 - val_loss: 0.0976 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0042 - val_loss: 0.0954 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.5, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.1459 - val_loss: 0.1052 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0067 - val_loss: 0.1002 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0053 - val_loss: 0.0983 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0048 - val_loss: 0.1006 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0047 - val_loss: 0.0967 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0046 - val_loss: 0.0968 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0044 - val_loss: 0.0966 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0043 - val_loss: 0.1026 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0043 - val_loss: 0.0960 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0040 - val_loss: 0.1002 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0043 - val_loss: 0.0967 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0043 - val_loss: 0.0939 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0041 - val_loss: 0.0970 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0041 - val_loss: 0.0962 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0043 - val_loss: 0.0982 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0044 - val_loss: 0.0971 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0042 - val_loss: 0.0973 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0042 - val_loss: 0.0960 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0042 - val_loss: 0.0972 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0041 - val_loss: 0.0970 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0041 - val_loss: 0.0965 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0042 - val_loss: 0.0978 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.5, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - loss: 0.1690 - val_loss: 0.1062 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0094 - val_loss: 0.1003 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0052 - val_loss: 0.1010 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0051 - val_loss: 0.1022 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0046 - val_loss: 0.1004 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0047 - val_loss: 0.1011 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0047 - val_loss: 0.0995 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0045 - val_loss: 0.1002 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0046 - val_loss: 0.0987 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0046 - val_loss: 0.1018 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0043 - val_loss: 0.1016 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0044 - val_loss: 0.0941 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0046 - val_loss: 0.1005 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0042 - val_loss: 0.1005 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0044 - val_loss: 0.1028 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0044 - val_loss: 0.1002 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0043 - val_loss: 0.0990 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0040 - val_loss: 0.0977 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0042 - val_loss: 0.0995 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0041 - val_loss: 0.0993 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0042 - val_loss: 0.0989 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0044 - val_loss: 0.0986 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.5, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - loss: 0.0510 - val_loss: 0.0903 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0048 - val_loss: 0.0966 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0043 - val_loss: 0.0900 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0047 - val_loss: 0.0888 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0052 - val_loss: 0.0917 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0044 - val_loss: 0.0908 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0044 - val_loss: 0.0946 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0044 - val_loss: 0.0945 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0042 - val_loss: 0.0981 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0043 - val_loss: 0.0950 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0041 - val_loss: 0.0969 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0041 - val_loss: 0.0937 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0041 - val_loss: 0.0974 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0040 - val_loss: 0.0934 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.5, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - loss: 0.0870 - val_loss: 0.0974 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0047 - val_loss: 0.0973 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0044 - val_loss: 0.0948 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0045 - val_loss: 0.0949 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0044 - val_loss: 0.0981 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0042 - val_loss: 0.0974 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0041 - val_loss: 0.0999 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0044 - val_loss: 0.0997 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0043 - val_loss: 0.0946 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0044 - val_loss: 0.0922 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0044 - val_loss: 0.0964 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0042 - val_loss: 0.0934 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0041 - val_loss: 0.0952 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0040 - val_loss: 0.0960 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0038 - val_loss: 0.0988 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0042 - val_loss: 0.0963 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0040 - val_loss: 0.0970 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0040 - val_loss: 0.0929 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0041 - val_loss: 0.0969 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0039 - val_loss: 0.0959 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nTraining model with units=50, layers=3, dropout=0.5, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - loss: 0.0908 - val_loss: 0.0990 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0048 - val_loss: 0.1015 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0048 - val_loss: 0.1034 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0047 - val_loss: 0.0955 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0045 - val_loss: 0.1006 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0044 - val_loss: 0.0927 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0042 - val_loss: 0.0989 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0042 - val_loss: 0.1000 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0045 - val_loss: 0.1017 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0044 - val_loss: 0.0976 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0043 - val_loss: 0.0956 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0041 - val_loss: 0.0984 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0040 - val_loss: 0.0956 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0042 - val_loss: 0.0971 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0040 - val_loss: 0.0968 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0041 - val_loss: 0.0981 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.2, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.1877 - val_loss: 0.0170 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0510 - val_loss: 0.0194 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0304 - val_loss: 0.0350 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0151 - val_loss: 0.0715 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0075 - val_loss: 0.0771 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0065 - val_loss: 0.0767 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0059 - val_loss: 0.0777 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0056 - val_loss: 0.0820 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0051 - val_loss: 0.0804 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0054 - val_loss: 0.0803 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0053 - val_loss: 0.0803 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.2, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.2781 - val_loss: 0.0418 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0664 - val_loss: 0.0179 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0530 - val_loss: 0.0166 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0409 - val_loss: 0.0212 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0351 - val_loss: 0.0290 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0238 - val_loss: 0.0413 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0159 - val_loss: 0.0504 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0138 - val_loss: 0.0609 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0106 - val_loss: 0.0695 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0094 - val_loss: 0.0734 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0083 - val_loss: 0.0765 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0088 - val_loss: 0.0769 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0079 - val_loss: 0.0777 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.2, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.2796 - val_loss: 0.1026 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0919 - val_loss: 0.0089 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0549 - val_loss: 0.0157 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0504 - val_loss: 0.0146 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0454 - val_loss: 0.0168 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0423 - val_loss: 0.0184 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0375 - val_loss: 0.0210 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0294 - val_loss: 0.0242 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0230 - val_loss: 0.0264 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0248 - val_loss: 0.0286 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0214 - val_loss: 0.0313 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0215 - val_loss: 0.0330 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.2, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0562 - val_loss: 0.0892 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0039 - val_loss: 0.0752 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0030 - val_loss: 0.0685 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0031 - val_loss: 0.0800 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0026 - val_loss: 0.0759 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0023 - val_loss: 0.0720 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0019 - val_loss: 0.0696 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0016 - val_loss: 0.0709 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0015 - val_loss: 0.0650 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0016 - val_loss: 0.0665 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0014 - val_loss: 0.0618 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0635 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0015 - val_loss: 0.0705 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0015 - val_loss: 0.0597 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0670 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0014 - val_loss: 0.0643 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0013 - val_loss: 0.0647 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0621 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0668 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0012 - val_loss: 0.0640 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0010 - val_loss: 0.0651 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0013 - val_loss: 0.0623 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0675 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0657 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.2, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.1511 - val_loss: 0.0253 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0175 - val_loss: 0.0786 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0045 - val_loss: 0.0820 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0043 - val_loss: 0.0885 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0036 - val_loss: 0.0853 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0038 - val_loss: 0.0906 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0034 - val_loss: 0.0830 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0032 - val_loss: 0.0833 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0032 - val_loss: 0.0816 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0032 - val_loss: 0.0807 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0030 - val_loss: 0.0811 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.2, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.1333 - val_loss: 0.0180 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0223 - val_loss: 0.0491 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0077 - val_loss: 0.0828 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0040 - val_loss: 0.0835 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0038 - val_loss: 0.0873 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0036 - val_loss: 0.0874 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0034 - val_loss: 0.0851 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0034 - val_loss: 0.0859 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0033 - val_loss: 0.0835 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0035 - val_loss: 0.0875 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0034 - val_loss: 0.0855 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.2, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0667 - val_loss: 0.0836 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0041 - val_loss: 0.0877 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0038 - val_loss: 0.0907 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0036 - val_loss: 0.0735 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0025 - val_loss: 0.0610 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0022 - val_loss: 0.0744 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0019 - val_loss: 0.0699 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0015 - val_loss: 0.0730 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0013 - val_loss: 0.0603 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0014 - val_loss: 0.0706 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0679 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0617 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0735 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 9.9071e-04 - val_loss: 0.0664 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0745 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 9.5481e-04 - val_loss: 0.0738 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0724 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0012 - val_loss: 0.0661 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0722 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.2, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0665 - val_loss: 0.1004 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0038 - val_loss: 0.0846 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0036 - val_loss: 0.0815 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0036 - val_loss: 0.0761 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0031 - val_loss: 0.0747 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0025 - val_loss: 0.0649 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0024 - val_loss: 0.0855 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0017 - val_loss: 0.0749 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0015 - val_loss: 0.0770 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0014 - val_loss: 0.0681 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0013 - val_loss: 0.0736 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0013 - val_loss: 0.0715 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0011 - val_loss: 0.0763 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0012 - val_loss: 0.0733 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0012 - val_loss: 0.0705 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0013 - val_loss: 0.0717 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.2, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 0.0987 - val_loss: 0.0596 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0060 - val_loss: 0.0904 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0037 - val_loss: 0.0938 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0037 - val_loss: 0.0889 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0036 - val_loss: 0.0921 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0035 - val_loss: 0.0853 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0035 - val_loss: 0.0896 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0035 - val_loss: 0.0875 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0033 - val_loss: 0.0807 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0034 - val_loss: 0.0850 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0031 - val_loss: 0.0805 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.3, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.2079 - val_loss: 0.0257 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0642 - val_loss: 0.0318 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0245 - val_loss: 0.0781 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0100 - val_loss: 0.0822 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0075 - val_loss: 0.0829 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0073 - val_loss: 0.0797 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0063 - val_loss: 0.0820 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0053 - val_loss: 0.0844 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0056 - val_loss: 0.0827 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0059 - val_loss: 0.0833 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0052 - val_loss: 0.0829 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.3, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.2660 - val_loss: 0.0530 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0808 - val_loss: 0.0227 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0679 - val_loss: 0.0239 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0466 - val_loss: 0.0367 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0231 - val_loss: 0.0764 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0099 - val_loss: 0.0816 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0088 - val_loss: 0.0818 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0083 - val_loss: 0.0819 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0076 - val_loss: 0.0832 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0076 - val_loss: 0.0820 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0076 - val_loss: 0.0822 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0075 - val_loss: 0.0822 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.3, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.4138 - val_loss: 0.2090 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1842 - val_loss: 0.0429 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0844 - val_loss: 0.0269 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0677 - val_loss: 0.0257 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0560 - val_loss: 0.0276 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0481 - val_loss: 0.0310 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0400 - val_loss: 0.0379 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0294 - val_loss: 0.0440 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0224 - val_loss: 0.0515 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0179 - val_loss: 0.0598 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0166 - val_loss: 0.0639 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0133 - val_loss: 0.0683 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0118 - val_loss: 0.0718 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0118 - val_loss: 0.0733 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.3, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.1055 - val_loss: 0.0875 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0046 - val_loss: 0.0878 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0039 - val_loss: 0.0857 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0035 - val_loss: 0.0867 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0033 - val_loss: 0.0838 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0031 - val_loss: 0.0785 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0026 - val_loss: 0.0716 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0023 - val_loss: 0.0837 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0021 - val_loss: 0.0813 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0021 - val_loss: 0.0876 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0018 - val_loss: 0.0795 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0019 - val_loss: 0.0775 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0019 - val_loss: 0.0758 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0015 - val_loss: 0.0825 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0016 - val_loss: 0.0793 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0017 - val_loss: 0.0783 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0017 - val_loss: 0.0774 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.3, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.1595 - val_loss: 0.0403 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0133 - val_loss: 0.0903 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0049 - val_loss: 0.0875 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0043 - val_loss: 0.0873 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0041 - val_loss: 0.0861 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0041 - val_loss: 0.0920 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0038 - val_loss: 0.0884 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0037 - val_loss: 0.0857 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0037 - val_loss: 0.0872 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0036 - val_loss: 0.0861 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0035 - val_loss: 0.0891 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.3, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.1212 - val_loss: 0.0278 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0190 - val_loss: 0.0908 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0047 - val_loss: 0.0934 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0038 - val_loss: 0.0884 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0037 - val_loss: 0.0891 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0037 - val_loss: 0.0892 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0036 - val_loss: 0.0892 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0036 - val_loss: 0.0878 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0035 - val_loss: 0.0876 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0036 - val_loss: 0.0859 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0034 - val_loss: 0.0865 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.3, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0575 - val_loss: 0.0845 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0040 - val_loss: 0.0912 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0038 - val_loss: 0.0783 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0035 - val_loss: 0.0721 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0030 - val_loss: 0.0868 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0024 - val_loss: 0.0793 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0020 - val_loss: 0.0893 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0018 - val_loss: 0.0836 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0017 - val_loss: 0.0741 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0016 - val_loss: 0.0790 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0014 - val_loss: 0.0774 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0016 - val_loss: 0.0765 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0017 - val_loss: 0.0756 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0015 - val_loss: 0.0759 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.3, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0865 - val_loss: 0.0910 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0043 - val_loss: 0.0911 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0038 - val_loss: 0.0885 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0037 - val_loss: 0.0838 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0036 - val_loss: 0.0845 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0036 - val_loss: 0.0841 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0037 - val_loss: 0.0775 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0033 - val_loss: 0.0789 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0035 - val_loss: 0.0718 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0027 - val_loss: 0.0755 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0022 - val_loss: 0.0757 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0022 - val_loss: 0.0872 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0018 - val_loss: 0.0785 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0016 - val_loss: 0.0774 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0017 - val_loss: 0.0789 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0017 - val_loss: 0.0770 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0017 - val_loss: 0.0775 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0015 - val_loss: 0.0759 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0015 - val_loss: 0.0786 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.3, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.1159 - val_loss: 0.0870 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0044 - val_loss: 0.0946 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0041 - val_loss: 0.0930 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0039 - val_loss: 0.0941 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0037 - val_loss: 0.0891 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0036 - val_loss: 0.0922 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0037 - val_loss: 0.0900 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0035 - val_loss: 0.0918 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0035 - val_loss: 0.0881 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0036 - val_loss: 0.0868 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0033 - val_loss: 0.0861 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0035 - val_loss: 0.0933 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0033 - val_loss: 0.0879 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0034 - val_loss: 0.0898 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0033 - val_loss: 0.0870 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0032 - val_loss: 0.0864 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0033 - val_loss: 0.0878 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0031 - val_loss: 0.0835 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0031 - val_loss: 0.0867 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0031 - val_loss: 0.0863 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0031 - val_loss: 0.0827 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0031 - val_loss: 0.0838 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0031 - val_loss: 0.0840 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0029 - val_loss: 0.0834 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 25/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0030 - val_loss: 0.0842 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\nEpoch 26/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0029 - val_loss: 0.0834 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\nEpoch 27/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0030 - val_loss: 0.0835 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\nEpoch 28/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0030 - val_loss: 0.0823 - learning_rate: 7.8125e-05\b\b\b\b\b\b\b\nEpoch 29/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0027 - val_loss: 0.0815 - learning_rate: 7.8125e-05\b\b\b\b\b\b\b\nEpoch 30/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0028 - val_loss: 0.0821 - learning_rate: 7.8125e-05\b\b\b\b\b\b\b\nEpoch 31/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0030 - val_loss: 0.0825 - learning_rate: 7.8125e-05\b\b\b\b\b\b\b\nEpoch 32/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0025 - val_loss: 0.0829 - learning_rate: 7.8125e-05\b\b\b\b\b\b\b\nEpoch 33/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0027 - val_loss: 0.0813 - learning_rate: 3.9062e-05\b\b\b\b\b\b\b\nEpoch 34/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0028 - val_loss: 0.0814 - learning_rate: 3.9062e-05\b\b\b\b\b\b\b\nEpoch 35/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0028 - val_loss: 0.0821 - learning_rate: 3.9062e-05\b\b\b\b\b\b\b\nEpoch 36/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0027 - val_loss: 0.0819 - learning_rate: 3.9062e-05\b\b\b\b\b\b\b\nEpoch 37/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0028 - val_loss: 0.0821 - learning_rate: 1.9531e-05\b\b\b\b\b\b\b\nEpoch 38/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0028 - val_loss: 0.0815 - learning_rate: 1.9531e-05\b\b\b\b\b\b\b\nEpoch 39/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0027 - val_loss: 0.0812 - learning_rate: 1.9531e-05\b\b\b\b\b\b\b\nEpoch 40/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0026 - val_loss: 0.0811 - learning_rate: 1.9531e-05\b\b\b\b\b\b\b\nEpoch 41/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0028 - val_loss: 0.0807 - learning_rate: 1.9531e-05\b\b\b\b\b\b\b\nEpoch 42/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0029 - val_loss: 0.0810 - learning_rate: 1.9531e-05\b\b\b\b\b\b\b\nEpoch 43/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0027 - val_loss: 0.0808 - learning_rate: 1.9531e-05\b\b\b\b\b\b\b\nEpoch 44/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0028 - val_loss: 0.0810 - learning_rate: 1.9531e-05\b\b\b\b\b\b\b\nEpoch 45/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0026 - val_loss: 0.0807 - learning_rate: 9.7656e-06\b\b\b\b\b\b\b\nEpoch 46/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0027 - val_loss: 0.0805 - learning_rate: 9.7656e-06\b\b\b\b\b\b\b\nEpoch 47/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0026 - val_loss: 0.0806 - learning_rate: 9.7656e-06\b\b\b\b\b\b\b\nEpoch 48/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0027 - val_loss: 0.0805 - learning_rate: 9.7656e-06\b\b\b\b\b\b\b\nEpoch 49/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0027 - val_loss: 0.0803 - learning_rate: 9.7656e-06\b\b\b\b\b\b\b\nEpoch 50/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0027 - val_loss: 0.0806 - learning_rate: 9.7656e-06\b\b\b\b\b\b\b\nEpoch 51/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0028 - val_loss: 0.0806 - learning_rate: 9.7656e-06\b\b\b\b\b\b\b\nEpoch 52/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0028 - val_loss: 0.0808 - learning_rate: 9.7656e-06\b\b\b\b\b\b\b\nEpoch 53/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0027 - val_loss: 0.0808 - learning_rate: 4.8828e-06\b\b\b\b\b\b\b\nEpoch 54/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0027 - val_loss: 0.0807 - learning_rate: 4.8828e-06\b\b\b\b\b\b\b\nEpoch 55/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0032 - val_loss: 0.0806 - learning_rate: 4.8828e-06\b\b\b\b\b\b\b\nEpoch 56/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0029 - val_loss: 0.0807 - learning_rate: 2.4414e-06\b\b\b\b\b\b\b\nEpoch 57/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0029 - val_loss: 0.0808 - learning_rate: 2.4414e-06\b\b\b\b\b\b\b\nEpoch 58/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0026 - val_loss: 0.0808 - learning_rate: 2.4414e-06\b\b\b\b\b\b\b\nEpoch 59/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0025 - val_loss: 0.0807 - learning_rate: 1.2207e-06\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.5, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.2048 - val_loss: 0.0513 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0884 - val_loss: 0.0897 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0122 - val_loss: 0.0856 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0091 - val_loss: 0.0896 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0070 - val_loss: 0.0870 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0074 - val_loss: 0.0867 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0068 - val_loss: 0.0883 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0062 - val_loss: 0.0892 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0064 - val_loss: 0.0899 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0056 - val_loss: 0.0881 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0057 - val_loss: 0.0891 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.5, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.2095 - val_loss: 0.0496 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.1348 - val_loss: 0.0423 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0879 - val_loss: 0.0500 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0221 - val_loss: 0.0818 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0114 - val_loss: 0.0854 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0101 - val_loss: 0.0854 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0091 - val_loss: 0.0872 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0088 - val_loss: 0.0872 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0088 - val_loss: 0.0876 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0085 - val_loss: 0.0869 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0084 - val_loss: 0.0871 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0078 - val_loss: 0.0865 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.5, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.3474 - val_loss: 0.1566 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1674 - val_loss: 0.0519 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1354 - val_loss: 0.0504 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1025 - val_loss: 0.0419 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0720 - val_loss: 0.0429 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0406 - val_loss: 0.0689 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0156 - val_loss: 0.0893 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0142 - val_loss: 0.0870 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0115 - val_loss: 0.0867 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0104 - val_loss: 0.0868 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0115 - val_loss: 0.0859 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0106 - val_loss: 0.0860 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0109 - val_loss: 0.0866 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0098 - val_loss: 0.0870 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.5, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0831 - val_loss: 0.0892 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0044 - val_loss: 0.0829 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0037 - val_loss: 0.0916 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0039 - val_loss: 0.0973 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0032 - val_loss: 0.0902 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0031 - val_loss: 0.0954 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0029 - val_loss: 0.0932 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0029 - val_loss: 0.0941 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0026 - val_loss: 0.0947 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0024 - val_loss: 0.0942 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0022 - val_loss: 0.0968 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0023 - val_loss: 0.0968 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.5, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.1319 - val_loss: 0.1051 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0055 - val_loss: 0.0917 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0049 - val_loss: 0.0906 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0043 - val_loss: 0.0965 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0042 - val_loss: 0.0967 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0036 - val_loss: 0.0931 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0035 - val_loss: 0.0921 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0035 - val_loss: 0.0959 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0035 - val_loss: 0.0885 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0032 - val_loss: 0.0931 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0032 - val_loss: 0.0855 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0033 - val_loss: 0.0902 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0030 - val_loss: 0.0871 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0029 - val_loss: 0.0974 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0029 - val_loss: 0.0926 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0027 - val_loss: 0.0947 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0026 - val_loss: 0.0953 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0027 - val_loss: 0.0958 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0027 - val_loss: 0.0938 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0029 - val_loss: 0.0941 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0024 - val_loss: 0.0957 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.5, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.1636 - val_loss: 0.0908 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0084 - val_loss: 0.0904 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0049 - val_loss: 0.0939 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0047 - val_loss: 0.0941 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0041 - val_loss: 0.0932 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0038 - val_loss: 0.0918 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0038 - val_loss: 0.0930 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0039 - val_loss: 0.0918 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0037 - val_loss: 0.0935 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0038 - val_loss: 0.0919 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0036 - val_loss: 0.0915 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0035 - val_loss: 0.0921 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.5, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0732 - val_loss: 0.0880 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0044 - val_loss: 0.1001 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0039 - val_loss: 0.0967 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0039 - val_loss: 0.0946 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0030 - val_loss: 0.0927 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0029 - val_loss: 0.0968 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0028 - val_loss: 0.0988 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0027 - val_loss: 0.0976 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0026 - val_loss: 0.0990 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0023 - val_loss: 0.1005 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0024 - val_loss: 0.0985 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.5, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0681 - val_loss: 0.0949 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0039 - val_loss: 0.0922 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0041 - val_loss: 0.0904 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0039 - val_loss: 0.0931 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0035 - val_loss: 0.1057 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0035 - val_loss: 0.0869 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0033 - val_loss: 0.0857 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0034 - val_loss: 0.0944 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0028 - val_loss: 0.0937 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0028 - val_loss: 0.1000 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0023 - val_loss: 0.1052 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0024 - val_loss: 0.1014 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0025 - val_loss: 0.1006 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0022 - val_loss: 0.0990 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0025 - val_loss: 0.1001 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0020 - val_loss: 0.0999 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0020 - val_loss: 0.1024 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=1, dropout=0.5, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0971 - val_loss: 0.0839 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0043 - val_loss: 0.0916 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0039 - val_loss: 0.0963 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0040 - val_loss: 0.0932 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0041 - val_loss: 0.0934 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0038 - val_loss: 0.0955 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0042 - val_loss: 0.0971 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0037 - val_loss: 0.0909 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0036 - val_loss: 0.0925 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0034 - val_loss: 0.0959 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0035 - val_loss: 0.0923 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.2, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 0.1690 - val_loss: 0.0153 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0411 - val_loss: 0.0353 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0149 - val_loss: 0.0809 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0075 - val_loss: 0.0882 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0063 - val_loss: 0.0849 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0062 - val_loss: 0.0878 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0059 - val_loss: 0.0888 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0053 - val_loss: 0.0866 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0051 - val_loss: 0.0867 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0051 - val_loss: 0.0856 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0048 - val_loss: 0.0861 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.2, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 0.2183 - val_loss: 0.0090 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0471 - val_loss: 0.0157 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0402 - val_loss: 0.0229 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0272 - val_loss: 0.0379 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0172 - val_loss: 0.0516 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0112 - val_loss: 0.0682 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0089 - val_loss: 0.0810 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0079 - val_loss: 0.0821 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0072 - val_loss: 0.0819 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0075 - val_loss: 0.0822 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0075 - val_loss: 0.0825 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.2, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - loss: 0.2787 - val_loss: 0.0184 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0672 - val_loss: 0.0202 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0521 - val_loss: 0.0157 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0405 - val_loss: 0.0179 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0329 - val_loss: 0.0237 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0283 - val_loss: 0.0333 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0202 - val_loss: 0.0391 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0163 - val_loss: 0.0464 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0139 - val_loss: 0.0564 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0102 - val_loss: 0.0617 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0104 - val_loss: 0.0664 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0083 - val_loss: 0.0710 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0085 - val_loss: 0.0734 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.2, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 0.0698 - val_loss: 0.1087 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0056 - val_loss: 0.0916 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0043 - val_loss: 0.0793 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0039 - val_loss: 0.0815 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0043 - val_loss: 0.0778 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0032 - val_loss: 0.0811 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0028 - val_loss: 0.0798 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0030 - val_loss: 0.0721 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0022 - val_loss: 0.0873 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0018 - val_loss: 0.0754 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0019 - val_loss: 0.0880 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0017 - val_loss: 0.0809 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0015 - val_loss: 0.0608 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0016 - val_loss: 0.0777 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0016 - val_loss: 0.0751 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0016 - val_loss: 0.0895 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0014 - val_loss: 0.0823 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0014 - val_loss: 0.0725 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0014 - val_loss: 0.0712 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0014 - val_loss: 0.0797 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0013 - val_loss: 0.0739 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0012 - val_loss: 0.0786 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0014 - val_loss: 0.0787 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.2, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 0.1000 - val_loss: 0.0640 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0059 - val_loss: 0.0874 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0044 - val_loss: 0.0925 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0039 - val_loss: 0.0872 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0038 - val_loss: 0.0907 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0036 - val_loss: 0.0884 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0038 - val_loss: 0.0830 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0037 - val_loss: 0.0835 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - loss: 0.0032 - val_loss: 0.0842 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0032 - val_loss: 0.0800 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0033 - val_loss: 0.0805 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.2, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - loss: 0.1310 - val_loss: 0.0302 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0164 - val_loss: 0.0752 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0049 - val_loss: 0.0847 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0045 - val_loss: 0.0865 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0044 - val_loss: 0.0893 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0041 - val_loss: 0.0861 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0042 - val_loss: 0.0909 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0039 - val_loss: 0.0865 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0040 - val_loss: 0.0861 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0039 - val_loss: 0.0854 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0038 - val_loss: 0.0864 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.2, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 0.0426 - val_loss: 0.0904 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0046 - val_loss: 0.0785 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0035 - val_loss: 0.0874 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0030 - val_loss: 0.0708 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0026 - val_loss: 0.0652 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0021 - val_loss: 0.0764 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0014 - val_loss: 0.0686 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0019 - val_loss: 0.0887 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0013 - val_loss: 0.0767 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0014 - val_loss: 0.0802 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0012 - val_loss: 0.0730 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0011 - val_loss: 0.0719 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0010 - val_loss: 0.0786 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0011 - val_loss: 0.0828 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0013 - val_loss: 0.0768 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.2, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 0.0620 - val_loss: 0.0840 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0041 - val_loss: 0.0900 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0042 - val_loss: 0.0942 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0036 - val_loss: 0.0851 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0033 - val_loss: 0.0702 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0032 - val_loss: 0.1038 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0028 - val_loss: 0.0726 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0022 - val_loss: 0.0824 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0014 - val_loss: 0.0843 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0017 - val_loss: 0.0790 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0014 - val_loss: 0.0738 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0016 - val_loss: 0.0732 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0014 - val_loss: 0.0773 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0014 - val_loss: 0.0791 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0015 - val_loss: 0.0718 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.2, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - loss: 0.0826 - val_loss: 0.0964 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0045 - val_loss: 0.0860 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0043 - val_loss: 0.0884 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0040 - val_loss: 0.0887 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0036 - val_loss: 0.0825 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0039 - val_loss: 0.0807 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0034 - val_loss: 0.0744 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0030 - val_loss: 0.0843 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0023 - val_loss: 0.0686 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0021 - val_loss: 0.0681 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0019 - val_loss: 0.0726 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0017 - val_loss: 0.0847 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0016 - val_loss: 0.0785 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0014 - val_loss: 0.0787 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0011 - val_loss: 0.0812 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0013 - val_loss: 0.0735 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0012 - val_loss: 0.0870 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0013 - val_loss: 0.0777 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0013 - val_loss: 0.0731 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0012 - val_loss: 0.0795 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.3, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - loss: 0.1614 - val_loss: 0.0238 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0409 - val_loss: 0.0849 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0107 - val_loss: 0.0863 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0074 - val_loss: 0.0897 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0075 - val_loss: 0.0877 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0072 - val_loss: 0.0872 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0064 - val_loss: 0.0879 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0057 - val_loss: 0.0864 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0058 - val_loss: 0.0861 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0054 - val_loss: 0.0876 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0061 - val_loss: 0.0883 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.3, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 0.2513 - val_loss: 0.0117 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0710 - val_loss: 0.0231 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0491 - val_loss: 0.0429 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0192 - val_loss: 0.0856 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0101 - val_loss: 0.0857 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0097 - val_loss: 0.0841 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0087 - val_loss: 0.0865 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0084 - val_loss: 0.0865 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0078 - val_loss: 0.0867 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0084 - val_loss: 0.0879 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0084 - val_loss: 0.0866 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.3, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - loss: 0.2419 - val_loss: 0.0157 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0920 - val_loss: 0.0274 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0671 - val_loss: 0.0230 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0493 - val_loss: 0.0295 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0349 - val_loss: 0.0384 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0243 - val_loss: 0.0524 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0172 - val_loss: 0.0718 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0109 - val_loss: 0.0790 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0097 - val_loss: 0.0819 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0095 - val_loss: 0.0826 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0097 - val_loss: 0.0836 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.3, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 0.0888 - val_loss: 0.0898 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0049 - val_loss: 0.0920 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0047 - val_loss: 0.0873 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0045 - val_loss: 0.0974 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0039 - val_loss: 0.0965 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0036 - val_loss: 0.0848 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0035 - val_loss: 0.0703 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0034 - val_loss: 0.0973 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0031 - val_loss: 0.0863 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0029 - val_loss: 0.0931 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0026 - val_loss: 0.0835 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0021 - val_loss: 0.0848 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0023 - val_loss: 0.0840 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0021 - val_loss: 0.0939 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0023 - val_loss: 0.0876 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0022 - val_loss: 0.0820 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0019 - val_loss: 0.0868 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.3, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 0.0936 - val_loss: 0.0997 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0051 - val_loss: 0.0882 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0046 - val_loss: 0.0882 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0044 - val_loss: 0.0844 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0038 - val_loss: 0.0844 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0041 - val_loss: 0.0829 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0043 - val_loss: 0.0860 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0034 - val_loss: 0.0923 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0036 - val_loss: 0.0811 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0033 - val_loss: 0.0800 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0034 - val_loss: 0.0856 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0027 - val_loss: 0.0942 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0030 - val_loss: 0.1003 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0033 - val_loss: 0.0884 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0025 - val_loss: 0.0843 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0023 - val_loss: 0.0814 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0024 - val_loss: 0.0889 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0022 - val_loss: 0.0907 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0020 - val_loss: 0.0837 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0021 - val_loss: 0.0870 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.3, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - loss: 0.1205 - val_loss: 0.0536 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0084 - val_loss: 0.0918 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0050 - val_loss: 0.0939 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0045 - val_loss: 0.0881 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0042 - val_loss: 0.0899 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0042 - val_loss: 0.0900 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0044 - val_loss: 0.0895 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0041 - val_loss: 0.0919 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0041 - val_loss: 0.0914 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0042 - val_loss: 0.0912 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0041 - val_loss: 0.0918 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.3, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - loss: 0.0462 - val_loss: 0.0922 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0045 - val_loss: 0.0958 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0043 - val_loss: 0.0921 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0047 - val_loss: 0.0920 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0042 - val_loss: 0.0887 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0038 - val_loss: 0.0984 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0035 - val_loss: 0.0773 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0031 - val_loss: 0.0820 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0022 - val_loss: 0.0926 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0023 - val_loss: 0.0957 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0020 - val_loss: 0.0973 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0018 - val_loss: 0.0984 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0018 - val_loss: 0.0855 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0018 - val_loss: 0.0903 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0017 - val_loss: 0.0917 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0015 - val_loss: 0.0920 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0016 - val_loss: 0.0891 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.3, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 0.0970 - val_loss: 0.0938 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0045 - val_loss: 0.0935 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0043 - val_loss: 0.0931 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0045 - val_loss: 0.0950 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0039 - val_loss: 0.0899 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0038 - val_loss: 0.0870 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0037 - val_loss: 0.0884 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0035 - val_loss: 0.0917 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0045 - val_loss: 0.0880 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0039 - val_loss: 0.0861 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0039 - val_loss: 0.0933 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0038 - val_loss: 0.0899 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0035 - val_loss: 0.0893 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0034 - val_loss: 0.0859 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0032 - val_loss: 0.0842 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0028 - val_loss: 0.0879 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0029 - val_loss: 0.0867 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0025 - val_loss: 0.0881 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0024 - val_loss: 0.0876 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0024 - val_loss: 0.0866 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0022 - val_loss: 0.0971 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0022 - val_loss: 0.0903 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0021 - val_loss: 0.0879 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0019 - val_loss: 0.0903 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 25/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0020 - val_loss: 0.0885 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.3, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - loss: 0.0885 - val_loss: 0.1003 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0051 - val_loss: 0.0881 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0043 - val_loss: 0.0940 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0040 - val_loss: 0.0907 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0040 - val_loss: 0.0943 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0040 - val_loss: 0.0963 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0040 - val_loss: 0.0895 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0039 - val_loss: 0.0885 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0039 - val_loss: 0.0928 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0038 - val_loss: 0.0892 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0039 - val_loss: 0.0878 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0038 - val_loss: 0.0904 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0038 - val_loss: 0.0953 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0035 - val_loss: 0.0892 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0035 - val_loss: 0.0908 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0034 - val_loss: 0.0865 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0033 - val_loss: 0.0843 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0033 - val_loss: 0.0856 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0034 - val_loss: 0.0884 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0027 - val_loss: 0.0859 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0030 - val_loss: 0.0856 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0029 - val_loss: 0.0891 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0027 - val_loss: 0.0876 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0029 - val_loss: 0.0894 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\nEpoch 25/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0026 - val_loss: 0.0883 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\nEpoch 26/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0027 - val_loss: 0.0883 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\nEpoch 27/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0026 - val_loss: 0.0896 - learning_rate: 7.8125e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.5, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 0.2015 - val_loss: 0.0354 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0404 - val_loss: 0.0819 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0115 - val_loss: 0.0916 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0104 - val_loss: 0.0946 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0080 - val_loss: 0.0926 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0074 - val_loss: 0.0942 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0071 - val_loss: 0.0931 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0068 - val_loss: 0.0946 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0066 - val_loss: 0.0942 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0061 - val_loss: 0.0941 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0065 - val_loss: 0.0942 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.5, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 0.2545 - val_loss: 0.0410 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.1170 - val_loss: 0.0364 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0597 - val_loss: 0.0794 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0140 - val_loss: 0.0880 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0113 - val_loss: 0.0896 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0094 - val_loss: 0.0916 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0084 - val_loss: 0.0891 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0084 - val_loss: 0.0898 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0082 - val_loss: 0.0924 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0084 - val_loss: 0.0918 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0073 - val_loss: 0.0914 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0080 - val_loss: 0.0912 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.5, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - loss: 0.2450 - val_loss: 0.0386 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.1426 - val_loss: 0.0445 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0974 - val_loss: 0.0411 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0330 - val_loss: 0.0902 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0148 - val_loss: 0.0877 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0135 - val_loss: 0.0888 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0120 - val_loss: 0.0873 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0107 - val_loss: 0.0883 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0108 - val_loss: 0.0884 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0106 - val_loss: 0.0897 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0097 - val_loss: 0.0891 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.5, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 0.0921 - val_loss: 0.0934 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0054 - val_loss: 0.0929 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0050 - val_loss: 0.0963 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0046 - val_loss: 0.0926 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0045 - val_loss: 0.0927 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0044 - val_loss: 0.0936 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0044 - val_loss: 0.0858 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0041 - val_loss: 0.1016 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0042 - val_loss: 0.0944 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0038 - val_loss: 0.0911 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0037 - val_loss: 0.0973 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0034 - val_loss: 0.0925 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0034 - val_loss: 0.0879 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0033 - val_loss: 0.0978 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0033 - val_loss: 0.0968 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0028 - val_loss: 0.0959 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0030 - val_loss: 0.0945 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.5, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 0.1179 - val_loss: 0.0880 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0061 - val_loss: 0.0938 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0047 - val_loss: 0.0944 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0045 - val_loss: 0.0949 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0041 - val_loss: 0.0942 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0044 - val_loss: 0.0930 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0041 - val_loss: 0.0915 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0042 - val_loss: 0.0968 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0041 - val_loss: 0.0964 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0040 - val_loss: 0.0944 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0041 - val_loss: 0.0944 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.5, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - loss: 0.1626 - val_loss: 0.1066 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0077 - val_loss: 0.0915 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0054 - val_loss: 0.0922 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0053 - val_loss: 0.0941 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0047 - val_loss: 0.0903 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0046 - val_loss: 0.0901 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0046 - val_loss: 0.0996 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0045 - val_loss: 0.0912 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0043 - val_loss: 0.0980 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0043 - val_loss: 0.0960 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0043 - val_loss: 0.0927 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0041 - val_loss: 0.0933 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0040 - val_loss: 0.0971 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0040 - val_loss: 0.0943 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0040 - val_loss: 0.0945 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0040 - val_loss: 0.0939 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.5, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 0.0655 - val_loss: 0.0910 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0047 - val_loss: 0.0921 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0046 - val_loss: 0.0957 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0044 - val_loss: 0.0969 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0044 - val_loss: 0.0918 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0042 - val_loss: 0.0896 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0038 - val_loss: 0.0905 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0043 - val_loss: 0.0980 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0040 - val_loss: 0.0968 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0037 - val_loss: 0.0966 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0033 - val_loss: 0.0942 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0033 - val_loss: 0.0999 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0028 - val_loss: 0.0942 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0028 - val_loss: 0.0975 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0029 - val_loss: 0.0990 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0027 - val_loss: 0.0998 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.5, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - loss: 0.1172 - val_loss: 0.0893 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0049 - val_loss: 0.0972 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0048 - val_loss: 0.0991 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0047 - val_loss: 0.0947 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0042 - val_loss: 0.0976 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0042 - val_loss: 0.0929 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0043 - val_loss: 0.0926 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0041 - val_loss: 0.0939 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0041 - val_loss: 0.0917 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0039 - val_loss: 0.1002 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0041 - val_loss: 0.0939 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=2, dropout=0.5, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - loss: 0.1148 - val_loss: 0.1059 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0049 - val_loss: 0.0931 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0047 - val_loss: 0.1002 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0044 - val_loss: 0.0945 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0040 - val_loss: 0.0980 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0043 - val_loss: 0.0971 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0044 - val_loss: 0.0957 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0041 - val_loss: 0.0927 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0041 - val_loss: 0.0949 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0040 - val_loss: 0.0940 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0041 - val_loss: 0.0904 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0042 - val_loss: 0.0930 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0037 - val_loss: 0.0965 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0040 - val_loss: 0.0989 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0041 - val_loss: 0.0977 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0037 - val_loss: 0.0941 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0036 - val_loss: 0.0970 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0037 - val_loss: 0.0953 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0033 - val_loss: 0.0952 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0036 - val_loss: 0.0945 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0032 - val_loss: 0.0939 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.2, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - loss: 0.1806 - val_loss: 0.0212 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0305 - val_loss: 0.0485 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0127 - val_loss: 0.0825 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0078 - val_loss: 0.0860 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0069 - val_loss: 0.0887 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0060 - val_loss: 0.0866 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0064 - val_loss: 0.0892 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0054 - val_loss: 0.0878 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0059 - val_loss: 0.0901 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0058 - val_loss: 0.0881 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0055 - val_loss: 0.0880 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.2, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - loss: 0.1903 - val_loss: 0.0204 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0523 - val_loss: 0.0210 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0321 - val_loss: 0.0343 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0197 - val_loss: 0.0632 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0095 - val_loss: 0.0791 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0085 - val_loss: 0.0837 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0071 - val_loss: 0.0872 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0074 - val_loss: 0.0863 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0064 - val_loss: 0.0865 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0065 - val_loss: 0.0874 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0062 - val_loss: 0.0879 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.2, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 64ms/step - loss: 0.2262 - val_loss: 0.0086 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0592 - val_loss: 0.0181 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0410 - val_loss: 0.0230 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0327 - val_loss: 0.0337 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0207 - val_loss: 0.0411 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0170 - val_loss: 0.0521 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0128 - val_loss: 0.0660 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0094 - val_loss: 0.0707 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0089 - val_loss: 0.0758 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0090 - val_loss: 0.0807 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0079 - val_loss: 0.0817 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.2, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - loss: 0.0627 - val_loss: 0.0875 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0050 - val_loss: 0.0782 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0052 - val_loss: 0.0783 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0043 - val_loss: 0.0864 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0039 - val_loss: 0.0851 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0033 - val_loss: 0.0956 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0031 - val_loss: 0.0731 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0032 - val_loss: 0.0768 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0024 - val_loss: 0.0791 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0025 - val_loss: 0.0896 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0020 - val_loss: 0.0912 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0020 - val_loss: 0.0864 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0019 - val_loss: 0.0831 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0018 - val_loss: 0.0817 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0019 - val_loss: 0.0803 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0017 - val_loss: 0.0791 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0016 - val_loss: 0.0819 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.2, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 54ms/step - loss: 0.0943 - val_loss: 0.0827 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0057 - val_loss: 0.0865 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0046 - val_loss: 0.0915 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0046 - val_loss: 0.0933 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0042 - val_loss: 0.0881 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0038 - val_loss: 0.0911 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0041 - val_loss: 0.0911 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0036 - val_loss: 0.0862 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0037 - val_loss: 0.0873 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0038 - val_loss: 0.0923 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0034 - val_loss: 0.0887 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.2, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 66ms/step - loss: 0.1172 - val_loss: 0.0516 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0102 - val_loss: 0.0957 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0053 - val_loss: 0.0883 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0048 - val_loss: 0.0926 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0046 - val_loss: 0.0868 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0046 - val_loss: 0.0917 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0045 - val_loss: 0.0897 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0040 - val_loss: 0.0927 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0040 - val_loss: 0.0906 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0041 - val_loss: 0.0883 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0041 - val_loss: 0.0893 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.2, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 0.0846 - val_loss: 0.0881 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0045 - val_loss: 0.0965 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0041 - val_loss: 0.0869 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0041 - val_loss: 0.0866 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0038 - val_loss: 0.0901 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0039 - val_loss: 0.0766 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0026 - val_loss: 0.0774 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0019 - val_loss: 0.0831 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0016 - val_loss: 0.0918 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0016 - val_loss: 0.0804 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0016 - val_loss: 0.0803 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0013 - val_loss: 0.0795 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0014 - val_loss: 0.0779 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0015 - val_loss: 0.0753 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0013 - val_loss: 0.0807 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0014 - val_loss: 0.0781 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0013 - val_loss: 0.0817 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0012 - val_loss: 0.0770 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0012 - val_loss: 0.0789 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0012 - val_loss: 0.0802 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0011 - val_loss: 0.0761 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 0.0011 - val_loss: 0.0772 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0010 - val_loss: 0.0787 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0011 - val_loss: 0.0824 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.2, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - loss: 0.2590 - val_loss: 0.0804 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0050 - val_loss: 0.0903 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0047 - val_loss: 0.0909 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0045 - val_loss: 0.0912 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0044 - val_loss: 0.0888 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0040 - val_loss: 0.0921 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0039 - val_loss: 0.0893 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0039 - val_loss: 0.0901 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0039 - val_loss: 0.0893 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0038 - val_loss: 0.0894 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0037 - val_loss: 0.0892 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.2, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 66ms/step - loss: 0.0899 - val_loss: 0.0824 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0049 - val_loss: 0.0925 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0044 - val_loss: 0.0915 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0042 - val_loss: 0.0975 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0041 - val_loss: 0.0920 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0042 - val_loss: 0.0916 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0040 - val_loss: 0.0938 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0040 - val_loss: 0.0907 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0038 - val_loss: 0.0894 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0039 - val_loss: 0.0883 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0037 - val_loss: 0.0938 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.3, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - loss: 0.1763 - val_loss: 0.0306 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0277 - val_loss: 0.0889 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0106 - val_loss: 0.0879 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0080 - val_loss: 0.0900 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0075 - val_loss: 0.0917 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0070 - val_loss: 0.0925 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0062 - val_loss: 0.0915 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0065 - val_loss: 0.0926 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0059 - val_loss: 0.0922 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0055 - val_loss: 0.0932 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0065 - val_loss: 0.0920 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.3, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - loss: 0.2351 - val_loss: 0.0213 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0632 - val_loss: 0.0294 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0366 - val_loss: 0.0536 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0159 - val_loss: 0.0898 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0104 - val_loss: 0.0887 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0090 - val_loss: 0.0897 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0083 - val_loss: 0.0894 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0083 - val_loss: 0.0904 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0086 - val_loss: 0.0915 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0077 - val_loss: 0.0907 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0077 - val_loss: 0.0904 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.3, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 66ms/step - loss: 0.2721 - val_loss: 0.0139 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0884 - val_loss: 0.0274 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0561 - val_loss: 0.0287 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0381 - val_loss: 0.0455 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0209 - val_loss: 0.0588 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0142 - val_loss: 0.0739 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0118 - val_loss: 0.0836 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0104 - val_loss: 0.0856 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0092 - val_loss: 0.0886 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0101 - val_loss: 0.0882 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0093 - val_loss: 0.0884 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.3, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - loss: 0.0718 - val_loss: 0.0947 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0049 - val_loss: 0.0928 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0047 - val_loss: 0.0943 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0047 - val_loss: 0.0931 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0043 - val_loss: 0.0878 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0039 - val_loss: 0.0921 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0039 - val_loss: 0.0822 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0041 - val_loss: 0.0909 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0033 - val_loss: 0.1064 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0032 - val_loss: 0.0945 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0029 - val_loss: 0.0981 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0028 - val_loss: 0.0838 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0025 - val_loss: 0.0950 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0022 - val_loss: 0.0889 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0020 - val_loss: 0.0916 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0021 - val_loss: 0.0960 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0020 - val_loss: 0.0900 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.3, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - loss: 0.1043 - val_loss: 0.1012 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0059 - val_loss: 0.0901 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0052 - val_loss: 0.0930 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0048 - val_loss: 0.0922 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0043 - val_loss: 0.0922 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0041 - val_loss: 0.0930 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0042 - val_loss: 0.0976 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0045 - val_loss: 0.0965 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0042 - val_loss: 0.0905 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0037 - val_loss: 0.0937 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0039 - val_loss: 0.0951 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0038 - val_loss: 0.0932 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.3, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 65ms/step - loss: 0.1142 - val_loss: 0.0701 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0084 - val_loss: 0.0984 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0056 - val_loss: 0.0933 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0049 - val_loss: 0.0925 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0043 - val_loss: 0.0939 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0045 - val_loss: 0.0934 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0045 - val_loss: 0.0920 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0047 - val_loss: 0.0930 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0043 - val_loss: 0.0958 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0043 - val_loss: 0.0933 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0042 - val_loss: 0.0918 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.3, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - loss: 0.0574 - val_loss: 0.0986 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0046 - val_loss: 0.0955 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0042 - val_loss: 0.0985 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0041 - val_loss: 0.0970 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0042 - val_loss: 0.0904 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0041 - val_loss: 0.0868 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0036 - val_loss: 0.0983 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0047 - val_loss: 0.0980 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0039 - val_loss: 0.1034 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0042 - val_loss: 0.0901 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0040 - val_loss: 0.0930 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0043 - val_loss: 0.0939 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0038 - val_loss: 0.0977 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0026 - val_loss: 0.0880 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0023 - val_loss: 0.0840 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0021 - val_loss: 0.0847 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0023 - val_loss: 0.0922 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0020 - val_loss: 0.0901 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0020 - val_loss: 0.0944 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0017 - val_loss: 0.0919 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0017 - val_loss: 0.0896 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0017 - val_loss: 0.0928 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0018 - val_loss: 0.0910 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0018 - val_loss: 0.0950 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 25/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0016 - val_loss: 0.0891 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.3, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - loss: 0.0781 - val_loss: 0.0897 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0048 - val_loss: 0.0956 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0045 - val_loss: 0.0921 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0044 - val_loss: 0.0926 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0042 - val_loss: 0.0926 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0040 - val_loss: 0.1004 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0041 - val_loss: 0.0982 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0039 - val_loss: 0.0963 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0036 - val_loss: 0.0893 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0036 - val_loss: 0.0919 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0034 - val_loss: 0.0953 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0027 - val_loss: 0.0934 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0028 - val_loss: 0.0931 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0027 - val_loss: 0.0964 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0026 - val_loss: 0.0936 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0024 - val_loss: 0.0918 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0024 - val_loss: 0.0890 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0023 - val_loss: 0.0926 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0023 - val_loss: 0.0925 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0022 - val_loss: 0.0907 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0022 - val_loss: 0.0918 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0021 - val_loss: 0.0919 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0023 - val_loss: 0.0921 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0020 - val_loss: 0.0927 - learning_rate: 7.8125e-05\b\b\b\b\b\b\b\nEpoch 25/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0020 - val_loss: 0.0905 - learning_rate: 7.8125e-05\b\b\b\b\b\b\b\nEpoch 26/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0020 - val_loss: 0.0901 - learning_rate: 7.8125e-05\b\b\b\b\b\b\b\nEpoch 27/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0019 - val_loss: 0.0922 - learning_rate: 3.9062e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.3, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 0.0988 - val_loss: 0.0949 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0047 - val_loss: 0.0977 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0046 - val_loss: 0.0943 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0041 - val_loss: 0.0938 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0041 - val_loss: 0.0950 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0042 - val_loss: 0.0948 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0043 - val_loss: 0.0930 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0040 - val_loss: 0.0973 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0039 - val_loss: 0.0949 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0037 - val_loss: 0.0918 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0037 - val_loss: 0.0877 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0030 - val_loss: 0.0951 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0029 - val_loss: 0.0950 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0030 - val_loss: 0.0948 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0020 - val_loss: 0.0939 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0021 - val_loss: 0.0915 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0021 - val_loss: 0.0917 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0019 - val_loss: 0.0928 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0018 - val_loss: 0.0936 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0017 - val_loss: 0.0933 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0018 - val_loss: 0.0950 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.5, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - loss: 0.2181 - val_loss: 0.0431 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0310 - val_loss: 0.0896 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0138 - val_loss: 0.0885 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0104 - val_loss: 0.0918 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0086 - val_loss: 0.0955 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0078 - val_loss: 0.0959 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0080 - val_loss: 0.0941 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0068 - val_loss: 0.0945 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0067 - val_loss: 0.0952 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0063 - val_loss: 0.0952 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0062 - val_loss: 0.0936 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.5, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 51ms/step - loss: 0.2457 - val_loss: 0.0395 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.1058 - val_loss: 0.0446 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0293 - val_loss: 0.0898 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0142 - val_loss: 0.0899 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0122 - val_loss: 0.0914 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0125 - val_loss: 0.0910 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0102 - val_loss: 0.0939 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0089 - val_loss: 0.0948 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0092 - val_loss: 0.0927 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0084 - val_loss: 0.0931 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0083 - val_loss: 0.0945 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.5, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 65ms/step - loss: 0.2770 - val_loss: 0.0381 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.1388 - val_loss: 0.0381 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0813 - val_loss: 0.0445 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0325 - val_loss: 0.0906 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0165 - val_loss: 0.0879 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0136 - val_loss: 0.0863 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0140 - val_loss: 0.0882 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0122 - val_loss: 0.0886 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0116 - val_loss: 0.0896 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0119 - val_loss: 0.0900 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0121 - val_loss: 0.0908 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0117 - val_loss: 0.0912 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.5, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - loss: 0.0763 - val_loss: 0.0973 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0050 - val_loss: 0.0894 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0053 - val_loss: 0.0953 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0047 - val_loss: 0.0886 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 0.0048 - val_loss: 0.0919 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0050 - val_loss: 0.0932 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 0.0042 - val_loss: 0.0990 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0043 - val_loss: 0.0969 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0041 - val_loss: 0.0946 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0041 - val_loss: 0.0939 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0039 - val_loss: 0.0950 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0038 - val_loss: 0.0955 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0040 - val_loss: 0.0925 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0039 - val_loss: 0.0949 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.5, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 52ms/step - loss: 0.1074 - val_loss: 0.0965 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0061 - val_loss: 0.0929 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0052 - val_loss: 0.0973 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0048 - val_loss: 0.0961 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0047 - val_loss: 0.0953 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0043 - val_loss: 0.0974 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0044 - val_loss: 0.0984 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0042 - val_loss: 0.0946 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0044 - val_loss: 0.0952 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0040 - val_loss: 0.0955 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0042 - val_loss: 0.0992 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0042 - val_loss: 0.0964 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.5, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 69ms/step - loss: 0.1357 - val_loss: 0.1099 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0066 - val_loss: 0.0919 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0052 - val_loss: 0.0998 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0047 - val_loss: 0.0938 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0049 - val_loss: 0.0944 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0043 - val_loss: 0.0943 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0046 - val_loss: 0.0916 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0044 - val_loss: 0.0949 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0043 - val_loss: 0.0991 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0043 - val_loss: 0.0964 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0042 - val_loss: 0.0954 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0041 - val_loss: 0.0992 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0040 - val_loss: 0.0957 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0041 - val_loss: 0.0987 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0043 - val_loss: 0.0980 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0041 - val_loss: 0.0995 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0042 - val_loss: 0.0967 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.5, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - loss: 0.0606 - val_loss: 0.0940 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0049 - val_loss: 0.0980 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0045 - val_loss: 0.0965 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0044 - val_loss: 0.0953 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0040 - val_loss: 0.0964 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0042 - val_loss: 0.1046 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0043 - val_loss: 0.0978 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0041 - val_loss: 0.0938 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0039 - val_loss: 0.0973 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0038 - val_loss: 0.0972 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0039 - val_loss: 0.0939 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - loss: 0.0040 - val_loss: 0.0957 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0038 - val_loss: 0.0945 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0039 - val_loss: 0.0970 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0038 - val_loss: 0.0949 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0037 - val_loss: 0.0963 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0038 - val_loss: 0.0930 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0037 - val_loss: 0.0953 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0033 - val_loss: 0.0986 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0035 - val_loss: 0.0947 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0034 - val_loss: 0.0952 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0034 - val_loss: 0.0933 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0037 - val_loss: 0.0953 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0035 - val_loss: 0.0951 - learning_rate: 7.8125e-05\b\b\b\b\b\b\b\nEpoch 25/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0033 - val_loss: 0.0961 - learning_rate: 7.8125e-05\b\b\b\b\b\b\b\nEpoch 26/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0032 - val_loss: 0.0965 - learning_rate: 7.8125e-05\b\b\b\b\b\b\b\nEpoch 27/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 0.0034 - val_loss: 0.0956 - learning_rate: 3.9062e-05\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.5, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 53ms/step - loss: 0.0926 - val_loss: 0.0992 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0047 - val_loss: 0.0942 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0044 - val_loss: 0.0915 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0044 - val_loss: 0.0970 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0043 - val_loss: 0.0951 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0045 - val_loss: 0.0937 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0041 - val_loss: 0.0932 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0041 - val_loss: 0.0956 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0042 - val_loss: 0.1000 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0041 - val_loss: 0.0964 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.0041 - val_loss: 0.0952 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0039 - val_loss: 0.0966 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0045 - val_loss: 0.0949 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=100, layers=3, dropout=0.5, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 66ms/step - loss: 0.1140 - val_loss: 0.1079 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0057 - val_loss: 0.0987 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0045 - val_loss: 0.0962 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 0.0043 - val_loss: 0.0974 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - loss: 0.0045 - val_loss: 0.0940 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0042 - val_loss: 0.0963 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0041 - val_loss: 0.0968 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0046 - val_loss: 0.0975 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0042 - val_loss: 0.0971 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0042 - val_loss: 0.0938 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0040 - val_loss: 0.0964 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0042 - val_loss: 0.0957 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0042 - val_loss: 0.0929 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0040 - val_loss: 0.0937 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0040 - val_loss: 0.0910 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0042 - val_loss: 0.0948 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0040 - val_loss: 0.0931 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0040 - val_loss: 0.0982 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0044 - val_loss: 0.0930 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0042 - val_loss: 0.0937 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0038 - val_loss: 0.0947 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0040 - val_loss: 0.0931 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0039 - val_loss: 0.0944 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0039 - val_loss: 0.0958 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 25/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0040 - val_loss: 0.0964 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.2, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.2307 - val_loss: 0.0145 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0444 - val_loss: 0.0201 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0249 - val_loss: 0.0531 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0086 - val_loss: 0.0825 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0058 - val_loss: 0.0824 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0056 - val_loss: 0.0796 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0051 - val_loss: 0.0799 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0047 - val_loss: 0.0806 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0050 - val_loss: 0.0818 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0042 - val_loss: 0.0859 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0045 - val_loss: 0.0821 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.2, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.2458 - val_loss: 0.0101 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0608 - val_loss: 0.0150 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0424 - val_loss: 0.0160 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0326 - val_loss: 0.0267 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0256 - val_loss: 0.0360 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0150 - val_loss: 0.0506 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0097 - val_loss: 0.0704 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0079 - val_loss: 0.0751 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0082 - val_loss: 0.0808 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0076 - val_loss: 0.0789 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0066 - val_loss: 0.0800 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.2, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 0.2970 - val_loss: 0.0663 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0732 - val_loss: 0.0115 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0526 - val_loss: 0.0136 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0460 - val_loss: 0.0153 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0398 - val_loss: 0.0182 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0334 - val_loss: 0.0208 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0303 - val_loss: 0.0240 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0247 - val_loss: 0.0287 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0222 - val_loss: 0.0319 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0194 - val_loss: 0.0360 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0156 - val_loss: 0.0406 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0143 - val_loss: 0.0433 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.2, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0617 - val_loss: 0.0761 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0040 - val_loss: 0.0834 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0034 - val_loss: 0.0721 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0033 - val_loss: 0.0744 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0030 - val_loss: 0.0635 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0023 - val_loss: 0.0684 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0021 - val_loss: 0.0729 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0018 - val_loss: 0.0703 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0016 - val_loss: 0.0651 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0014 - val_loss: 0.0700 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0014 - val_loss: 0.0636 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0014 - val_loss: 0.0707 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0013 - val_loss: 0.0731 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0013 - val_loss: 0.0693 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0011 - val_loss: 0.0667 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.2, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0949 - val_loss: 0.0350 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0096 - val_loss: 0.0780 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0039 - val_loss: 0.0817 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0035 - val_loss: 0.0796 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0037 - val_loss: 0.0886 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0035 - val_loss: 0.0872 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0031 - val_loss: 0.0813 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0031 - val_loss: 0.0821 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0030 - val_loss: 0.0771 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0027 - val_loss: 0.0777 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0028 - val_loss: 0.0759 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.2, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.1454 - val_loss: 0.0183 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0262 - val_loss: 0.0588 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0053 - val_loss: 0.0846 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0041 - val_loss: 0.0858 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0036 - val_loss: 0.0873 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0035 - val_loss: 0.0864 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0034 - val_loss: 0.0849 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0034 - val_loss: 0.0836 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0035 - val_loss: 0.0836 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0035 - val_loss: 0.0834 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0033 - val_loss: 0.0823 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.2, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0312 - val_loss: 0.0841 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0041 - val_loss: 0.0920 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0036 - val_loss: 0.0781 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0030 - val_loss: 0.0780 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0023 - val_loss: 0.0620 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0017 - val_loss: 0.0719 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0016 - val_loss: 0.0769 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0013 - val_loss: 0.0741 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0012 - val_loss: 0.0624 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0013 - val_loss: 0.0721 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0011 - val_loss: 0.0677 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 8.8610e-04 - val_loss: 0.0713 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 9.5186e-04 - val_loss: 0.0612 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 9.1946e-04 - val_loss: 0.0713 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 8.0145e-04 - val_loss: 0.0781 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 8.5058e-04 - val_loss: 0.0727 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 9.7428e-04 - val_loss: 0.0708 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0010 - val_loss: 0.0695 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0010 - val_loss: 0.0736 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 9.1396e-04 - val_loss: 0.0734 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 9.4882e-04 - val_loss: 0.0702 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 8.3121e-04 - val_loss: 0.0682 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 8.2608e-04 - val_loss: 0.0710 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.2, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0574 - val_loss: 0.0903 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0037 - val_loss: 0.0829 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0034 - val_loss: 0.0818 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0027 - val_loss: 0.0829 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0020 - val_loss: 0.0626 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0018 - val_loss: 0.0719 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0019 - val_loss: 0.0697 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0015 - val_loss: 0.0889 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0014 - val_loss: 0.0722 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0011 - val_loss: 0.0690 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0012 - val_loss: 0.0676 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0011 - val_loss: 0.0745 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0011 - val_loss: 0.0673 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 9.7198e-04 - val_loss: 0.0649 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 9.9748e-04 - val_loss: 0.0688 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.2, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.1267 - val_loss: 0.0552 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0066 - val_loss: 0.0945 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0040 - val_loss: 0.0876 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0036 - val_loss: 0.0953 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0039 - val_loss: 0.0902 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0036 - val_loss: 0.0928 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0035 - val_loss: 0.0843 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0034 - val_loss: 0.0879 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0035 - val_loss: 0.0856 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0034 - val_loss: 0.0833 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0031 - val_loss: 0.0845 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.3, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.1993 - val_loss: 0.0212 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0540 - val_loss: 0.0584 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0102 - val_loss: 0.0821 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0068 - val_loss: 0.0826 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0062 - val_loss: 0.0898 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0061 - val_loss: 0.0842 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0054 - val_loss: 0.0865 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0057 - val_loss: 0.0843 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0054 - val_loss: 0.0847 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0051 - val_loss: 0.0858 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0049 - val_loss: 0.0864 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.3, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.2250 - val_loss: 0.0141 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0791 - val_loss: 0.0207 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0529 - val_loss: 0.0305 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0254 - val_loss: 0.0859 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0094 - val_loss: 0.0800 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0080 - val_loss: 0.0816 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0067 - val_loss: 0.0843 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0074 - val_loss: 0.0844 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0068 - val_loss: 0.0840 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0071 - val_loss: 0.0837 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0063 - val_loss: 0.0835 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.3, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.2986 - val_loss: 0.0745 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0965 - val_loss: 0.0236 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0726 - val_loss: 0.0213 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0589 - val_loss: 0.0231 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0481 - val_loss: 0.0317 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0281 - val_loss: 0.0579 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0117 - val_loss: 0.0772 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0095 - val_loss: 0.0847 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0091 - val_loss: 0.0857 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0080 - val_loss: 0.0863 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0077 - val_loss: 0.0853 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0071 - val_loss: 0.0822 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0073 - val_loss: 0.0834 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.3, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0819 - val_loss: 0.0845 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0042 - val_loss: 0.0898 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0036 - val_loss: 0.0945 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0035 - val_loss: 0.0891 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0027 - val_loss: 0.0829 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0020 - val_loss: 0.0871 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0022 - val_loss: 0.0816 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0022 - val_loss: 0.0887 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0020 - val_loss: 0.0813 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0023 - val_loss: 0.0813 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0016 - val_loss: 0.0764 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0020 - val_loss: 0.0850 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0016 - val_loss: 0.0733 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0016 - val_loss: 0.0906 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0018 - val_loss: 0.0799 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0016 - val_loss: 0.0890 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0015 - val_loss: 0.0831 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0014 - val_loss: 0.0789 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0016 - val_loss: 0.0774 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0014 - val_loss: 0.0835 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0014 - val_loss: 0.0799 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0014 - val_loss: 0.0807 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0015 - val_loss: 0.0821 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.3, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.1116 - val_loss: 0.1049 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0054 - val_loss: 0.0889 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0043 - val_loss: 0.0810 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0036 - val_loss: 0.0840 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0034 - val_loss: 0.0786 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0032 - val_loss: 0.0784 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0028 - val_loss: 0.0859 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0024 - val_loss: 0.0790 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0024 - val_loss: 0.0892 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0022 - val_loss: 0.0840 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0021 - val_loss: 0.0830 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0020 - val_loss: 0.0785 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0019 - val_loss: 0.0772 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0018 - val_loss: 0.0764 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0017 - val_loss: 0.0821 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0016 - val_loss: 0.0772 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0017 - val_loss: 0.0796 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0017 - val_loss: 0.0768 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0016 - val_loss: 0.0786 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0019 - val_loss: 0.0747 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0020 - val_loss: 0.0774 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0020 - val_loss: 0.0773 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0018 - val_loss: 0.0799 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0017 - val_loss: 0.0796 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nEpoch 25/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0016 - val_loss: 0.0798 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nEpoch 26/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0015 - val_loss: 0.0776 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nEpoch 27/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0017 - val_loss: 0.0805 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\nEpoch 28/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0016 - val_loss: 0.0780 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\nEpoch 29/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0016 - val_loss: 0.0782 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\nEpoch 30/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0017 - val_loss: 0.0783 - learning_rate: 1.5625e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.3, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.1336 - val_loss: 0.0322 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0167 - val_loss: 0.0884 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0042 - val_loss: 0.0930 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0040 - val_loss: 0.0914 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0037 - val_loss: 0.0880 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0037 - val_loss: 0.0885 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0035 - val_loss: 0.0884 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0035 - val_loss: 0.0904 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0034 - val_loss: 0.0885 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0035 - val_loss: 0.0863 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0034 - val_loss: 0.0844 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.3, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0645 - val_loss: 0.0920 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0038 - val_loss: 0.0871 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0037 - val_loss: 0.0952 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0037 - val_loss: 0.0807 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0027 - val_loss: 0.0860 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0026 - val_loss: 0.0888 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0024 - val_loss: 0.0810 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0019 - val_loss: 0.0853 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0016 - val_loss: 0.0762 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0016 - val_loss: 0.0825 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0016 - val_loss: 0.0857 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0016 - val_loss: 0.0784 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0015 - val_loss: 0.0770 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0015 - val_loss: 0.0826 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0015 - val_loss: 0.0841 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0015 - val_loss: 0.0783 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0014 - val_loss: 0.0771 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0014 - val_loss: 0.0774 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0015 - val_loss: 0.0810 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.3, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0599 - val_loss: 0.0845 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0039 - val_loss: 0.0965 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0041 - val_loss: 0.0868 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0031 - val_loss: 0.0769 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0025 - val_loss: 0.0868 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0023 - val_loss: 0.0808 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0020 - val_loss: 0.0822 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0018 - val_loss: 0.0801 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0019 - val_loss: 0.0808 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0017 - val_loss: 0.0821 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0019 - val_loss: 0.0811 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0015 - val_loss: 0.0841 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0016 - val_loss: 0.0792 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0013 - val_loss: 0.0831 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.3, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.2252 - val_loss: 0.0741 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0072 - val_loss: 0.0922 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0041 - val_loss: 0.0893 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0041 - val_loss: 0.0889 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0039 - val_loss: 0.0908 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0038 - val_loss: 0.0956 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0039 - val_loss: 0.0926 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0038 - val_loss: 0.0927 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0039 - val_loss: 0.0920 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0038 - val_loss: 0.0914 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0038 - val_loss: 0.0909 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.5, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.2547 - val_loss: 0.0453 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0610 - val_loss: 0.0855 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0103 - val_loss: 0.0959 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0088 - val_loss: 0.0896 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0062 - val_loss: 0.0867 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0067 - val_loss: 0.0891 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0060 - val_loss: 0.0912 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0055 - val_loss: 0.0888 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0059 - val_loss: 0.0887 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0051 - val_loss: 0.0895 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0051 - val_loss: 0.0911 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.5, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.2530 - val_loss: 0.0483 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1274 - val_loss: 0.0399 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0731 - val_loss: 0.0875 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0115 - val_loss: 0.0842 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0087 - val_loss: 0.0887 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0076 - val_loss: 0.0879 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0075 - val_loss: 0.0899 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0075 - val_loss: 0.0894 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0067 - val_loss: 0.0914 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0073 - val_loss: 0.0892 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0069 - val_loss: 0.0889 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0066 - val_loss: 0.0891 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.5, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.3359 - val_loss: 0.1033 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1489 - val_loss: 0.0581 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.1145 - val_loss: 0.0461 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0913 - val_loss: 0.0369 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0480 - val_loss: 0.0747 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0128 - val_loss: 0.0909 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0109 - val_loss: 0.0870 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0097 - val_loss: 0.0866 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0088 - val_loss: 0.0859 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0081 - val_loss: 0.0884 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0085 - val_loss: 0.0894 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0085 - val_loss: 0.0888 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0076 - val_loss: 0.0891 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0081 - val_loss: 0.0893 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.5, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0989 - val_loss: 0.0866 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0043 - val_loss: 0.0932 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0041 - val_loss: 0.0881 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0036 - val_loss: 0.0872 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0034 - val_loss: 0.0927 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0028 - val_loss: 0.0949 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0028 - val_loss: 0.0955 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0025 - val_loss: 0.1000 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0023 - val_loss: 0.0940 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0025 - val_loss: 0.0961 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0023 - val_loss: 0.0955 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.5, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.1487 - val_loss: 0.0906 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0052 - val_loss: 0.0948 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0041 - val_loss: 0.0916 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0037 - val_loss: 0.0878 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0039 - val_loss: 0.0905 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0038 - val_loss: 0.0904 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0037 - val_loss: 0.0924 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0033 - val_loss: 0.0954 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0032 - val_loss: 0.0884 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0028 - val_loss: 0.0906 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0029 - val_loss: 0.0941 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0028 - val_loss: 0.0923 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0027 - val_loss: 0.0951 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0027 - val_loss: 0.0945 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.5, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.1563 - val_loss: 0.1067 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0062 - val_loss: 0.0973 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0046 - val_loss: 0.0966 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0043 - val_loss: 0.0909 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0040 - val_loss: 0.0951 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0039 - val_loss: 0.0951 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0037 - val_loss: 0.0915 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0034 - val_loss: 0.0934 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0036 - val_loss: 0.0980 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0036 - val_loss: 0.0914 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0032 - val_loss: 0.0898 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0033 - val_loss: 0.0929 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0029 - val_loss: 0.0914 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0031 - val_loss: 0.0891 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0028 - val_loss: 0.0908 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0032 - val_loss: 0.0919 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0030 - val_loss: 0.0925 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0029 - val_loss: 0.0916 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0028 - val_loss: 0.0914 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0029 - val_loss: 0.0926 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0029 - val_loss: 0.0920 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0028 - val_loss: 0.0928 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0027 - val_loss: 0.0911 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0027 - val_loss: 0.0926 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.5, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0561 - val_loss: 0.0891 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0037 - val_loss: 0.0865 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0038 - val_loss: 0.0851 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0041 - val_loss: 0.1008 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0036 - val_loss: 0.0978 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0031 - val_loss: 0.0989 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0024 - val_loss: 0.1017 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0026 - val_loss: 0.1051 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0022 - val_loss: 0.1114 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0024 - val_loss: 0.1036 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0025 - val_loss: 0.1008 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0024 - val_loss: 0.1027 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0022 - val_loss: 0.0996 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.5, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0959 - val_loss: 0.0895 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0044 - val_loss: 0.0894 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0043 - val_loss: 0.0935 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0036 - val_loss: 0.0899 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0037 - val_loss: 0.0958 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0037 - val_loss: 0.0919 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0036 - val_loss: 0.0902 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0037 - val_loss: 0.0906 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0034 - val_loss: 0.0930 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0034 - val_loss: 0.0948 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0035 - val_loss: 0.0907 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0032 - val_loss: 0.0908 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=1, dropout=0.5, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.1077 - val_loss: 0.0887 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0044 - val_loss: 0.0950 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0041 - val_loss: 0.0990 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0039 - val_loss: 0.0918 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0039 - val_loss: 0.0954 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0040 - val_loss: 0.0911 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0039 - val_loss: 0.0921 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0037 - val_loss: 0.0956 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0038 - val_loss: 0.0936 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0037 - val_loss: 0.0930 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0036 - val_loss: 0.0954 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.2, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 0.1267 - val_loss: 0.0175 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0260 - val_loss: 0.0894 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0065 - val_loss: 0.0872 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0053 - val_loss: 0.0809 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0048 - val_loss: 0.0852 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0045 - val_loss: 0.0840 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0040 - val_loss: 0.0847 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0042 - val_loss: 0.0845 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0045 - val_loss: 0.0846 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0041 - val_loss: 0.0838 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0037 - val_loss: 0.0829 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.2, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - loss: 0.2030 - val_loss: 0.0185 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0528 - val_loss: 0.0182 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0356 - val_loss: 0.0285 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0183 - val_loss: 0.0658 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0069 - val_loss: 0.0926 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0061 - val_loss: 0.0887 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0057 - val_loss: 0.0888 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0056 - val_loss: 0.0835 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0055 - val_loss: 0.0859 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0057 - val_loss: 0.0861 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0054 - val_loss: 0.0861 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0047 - val_loss: 0.0853 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.2, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - loss: 0.2062 - val_loss: 0.0059 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0561 - val_loss: 0.0139 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0445 - val_loss: 0.0187 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0351 - val_loss: 0.0263 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0233 - val_loss: 0.0340 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0176 - val_loss: 0.0491 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0111 - val_loss: 0.0699 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0077 - val_loss: 0.0793 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0073 - val_loss: 0.0827 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0068 - val_loss: 0.0856 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0065 - val_loss: 0.0857 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.2, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 0.0549 - val_loss: 0.0841 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0047 - val_loss: 0.0857 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0044 - val_loss: 0.0920 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0033 - val_loss: 0.0748 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0035 - val_loss: 0.0838 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0025 - val_loss: 0.0760 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0025 - val_loss: 0.0761 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0022 - val_loss: 0.0768 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0018 - val_loss: 0.0695 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0019 - val_loss: 0.0708 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0016 - val_loss: 0.0691 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0016 - val_loss: 0.0711 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0019 - val_loss: 0.0784 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0016 - val_loss: 0.0792 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0014 - val_loss: 0.0683 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0013 - val_loss: 0.0738 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0015 - val_loss: 0.0748 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0014 - val_loss: 0.0716 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0015 - val_loss: 0.0774 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0013 - val_loss: 0.0786 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0014 - val_loss: 0.0773 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0014 - val_loss: 0.0789 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0012 - val_loss: 0.0735 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0014 - val_loss: 0.0786 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nEpoch 25/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0014 - val_loss: 0.0760 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.2, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - loss: 0.0944 - val_loss: 0.0625 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0050 - val_loss: 0.0858 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0042 - val_loss: 0.0811 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0040 - val_loss: 0.0875 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0032 - val_loss: 0.0840 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0033 - val_loss: 0.0848 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0033 - val_loss: 0.0742 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0031 - val_loss: 0.0782 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0027 - val_loss: 0.0766 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0029 - val_loss: 0.0749 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0025 - val_loss: 0.0766 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.2, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - loss: 0.1047 - val_loss: 0.0433 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0095 - val_loss: 0.0823 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0042 - val_loss: 0.0940 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0046 - val_loss: 0.0869 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0037 - val_loss: 0.0840 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0036 - val_loss: 0.0905 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0035 - val_loss: 0.0861 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0035 - val_loss: 0.0849 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0032 - val_loss: 0.0843 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0032 - val_loss: 0.0861 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0034 - val_loss: 0.0829 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.2, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 0.0637 - val_loss: 0.0827 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0043 - val_loss: 0.0909 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0050 - val_loss: 0.0910 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0039 - val_loss: 0.0797 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0038 - val_loss: 0.0832 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0031 - val_loss: 0.0809 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0026 - val_loss: 0.0853 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0016 - val_loss: 0.0754 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0014 - val_loss: 0.0735 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0014 - val_loss: 0.0776 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0014 - val_loss: 0.0781 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0013 - val_loss: 0.0895 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0011 - val_loss: 0.0754 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0012 - val_loss: 0.0734 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0010 - val_loss: 0.0833 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0012 - val_loss: 0.0782 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0012 - val_loss: 0.0838 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0012 - val_loss: 0.0819 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0011 - val_loss: 0.0734 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0011 - val_loss: 0.0813 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0010 - val_loss: 0.0853 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0011 - val_loss: 0.0800 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 9.5960e-04 - val_loss: 0.0780 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0010 - val_loss: 0.0780 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 25/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 8.4549e-04 - val_loss: 0.0797 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 26/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 9.9373e-04 - val_loss: 0.0763 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\b\b\b\b\nEpoch 27/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0010 - val_loss: 0.0781 - learning_rate: 7.8125e-05\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 28/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0011 - val_loss: 0.0838 - learning_rate: 7.8125e-05\b\b\b\b\b\b\b\b\b\b\b\nEpoch 29/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 9.8973e-04 - val_loss: 0.0816 - learning_rate: 7.8125e-05\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.2, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.1060 - val_loss: 0.0890 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0043 - val_loss: 0.0902 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0039 - val_loss: 0.0894 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0038 - val_loss: 0.0852 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0037 - val_loss: 0.0863 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0036 - val_loss: 0.0852 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0036 - val_loss: 0.0818 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0031 - val_loss: 0.0787 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0025 - val_loss: 0.0715 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0022 - val_loss: 0.0842 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0018 - val_loss: 0.0893 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0015 - val_loss: 0.0763 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0014 - val_loss: 0.0791 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0013 - val_loss: 0.0781 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0014 - val_loss: 0.0759 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0013 - val_loss: 0.0753 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0011 - val_loss: 0.0829 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0012 - val_loss: 0.0746 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0014 - val_loss: 0.0807 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.2, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - loss: 0.2492 - val_loss: 0.0549 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0085 - val_loss: 0.0811 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0045 - val_loss: 0.0906 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0041 - val_loss: 0.0931 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0043 - val_loss: 0.0868 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0043 - val_loss: 0.0902 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0040 - val_loss: 0.0923 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0038 - val_loss: 0.0921 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0039 - val_loss: 0.0893 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0036 - val_loss: 0.0892 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0038 - val_loss: 0.0899 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.3, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 0.1716 - val_loss: 0.0239 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0315 - val_loss: 0.0881 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0074 - val_loss: 0.0871 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0066 - val_loss: 0.0903 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0055 - val_loss: 0.0918 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0049 - val_loss: 0.0853 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0048 - val_loss: 0.0848 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0047 - val_loss: 0.0890 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0047 - val_loss: 0.0887 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0044 - val_loss: 0.0878 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0049 - val_loss: 0.0862 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.3, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - loss: 0.1981 - val_loss: 0.0262 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0651 - val_loss: 0.0268 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0330 - val_loss: 0.0820 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0085 - val_loss: 0.0875 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0073 - val_loss: 0.0874 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0068 - val_loss: 0.0910 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0065 - val_loss: 0.0851 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0071 - val_loss: 0.0880 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0057 - val_loss: 0.0877 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0059 - val_loss: 0.0887 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0055 - val_loss: 0.0880 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.3, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 0.2537 - val_loss: 0.0086 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0862 - val_loss: 0.0247 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0590 - val_loss: 0.0270 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0369 - val_loss: 0.0431 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0178 - val_loss: 0.0683 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0089 - val_loss: 0.0901 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0091 - val_loss: 0.0870 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0080 - val_loss: 0.0864 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0074 - val_loss: 0.0867 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0083 - val_loss: 0.0867 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0070 - val_loss: 0.0868 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.3, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 0.0669 - val_loss: 0.0854 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0045 - val_loss: 0.0999 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0047 - val_loss: 0.0889 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0039 - val_loss: 0.0855 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0034 - val_loss: 0.0797 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0033 - val_loss: 0.0861 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0028 - val_loss: 0.0838 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0029 - val_loss: 0.0846 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0026 - val_loss: 0.0830 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0024 - val_loss: 0.0873 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0022 - val_loss: 0.0889 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0025 - val_loss: 0.0802 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0023 - val_loss: 0.0897 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0020 - val_loss: 0.0854 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0024 - val_loss: 0.0843 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.3, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.1014 - val_loss: 0.0908 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0047 - val_loss: 0.0922 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0047 - val_loss: 0.0879 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0039 - val_loss: 0.0922 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0040 - val_loss: 0.0892 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0036 - val_loss: 0.0937 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0036 - val_loss: 0.0924 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0034 - val_loss: 0.0850 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0035 - val_loss: 0.0842 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0031 - val_loss: 0.0896 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0029 - val_loss: 0.0889 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0028 - val_loss: 0.0834 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0027 - val_loss: 0.0963 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0029 - val_loss: 0.0967 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0030 - val_loss: 0.1025 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0027 - val_loss: 0.0810 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0022 - val_loss: 0.0897 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0023 - val_loss: 0.0887 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0024 - val_loss: 0.0820 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0022 - val_loss: 0.0873 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0021 - val_loss: 0.0872 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0022 - val_loss: 0.0829 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0021 - val_loss: 0.0877 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0018 - val_loss: 0.0863 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nEpoch 25/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0019 - val_loss: 0.0854 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nEpoch 26/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0021 - val_loss: 0.0892 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.3, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 56ms/step - loss: 0.1119 - val_loss: 0.0733 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0067 - val_loss: 0.0792 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0052 - val_loss: 0.0951 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0041 - val_loss: 0.0967 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0042 - val_loss: 0.0901 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0038 - val_loss: 0.0910 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0043 - val_loss: 0.0904 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0039 - val_loss: 0.0901 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0038 - val_loss: 0.0900 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0039 - val_loss: 0.0913 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0038 - val_loss: 0.0899 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.3, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - loss: 0.0861 - val_loss: 0.0908 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0046 - val_loss: 0.0873 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0044 - val_loss: 0.1007 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0038 - val_loss: 0.0953 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0054 - val_loss: 0.0910 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0049 - val_loss: 0.0922 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0041 - val_loss: 0.0882 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0040 - val_loss: 0.0941 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0042 - val_loss: 0.0884 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0039 - val_loss: 0.0879 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0039 - val_loss: 0.0830 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0043 - val_loss: 0.0840 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0037 - val_loss: 0.0915 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0035 - val_loss: 0.0900 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0029 - val_loss: 0.0894 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0030 - val_loss: 0.0937 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0029 - val_loss: 0.0926 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0022 - val_loss: 0.0936 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0024 - val_loss: 0.0861 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0025 - val_loss: 0.0947 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0022 - val_loss: 0.0905 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.3, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 46ms/step - loss: 0.1662 - val_loss: 0.0907 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0047 - val_loss: 0.0913 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0043 - val_loss: 0.0928 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0042 - val_loss: 0.0923 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0042 - val_loss: 0.0901 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0038 - val_loss: 0.0928 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0039 - val_loss: 0.0915 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0041 - val_loss: 0.0952 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0038 - val_loss: 0.0873 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0037 - val_loss: 0.0877 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0036 - val_loss: 0.0911 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0034 - val_loss: 0.0933 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0032 - val_loss: 0.0890 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0030 - val_loss: 0.0838 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0033 - val_loss: 0.0868 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0028 - val_loss: 0.0851 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0029 - val_loss: 0.0855 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0026 - val_loss: 0.0943 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0026 - val_loss: 0.0908 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0024 - val_loss: 0.0918 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0024 - val_loss: 0.0883 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0024 - val_loss: 0.0856 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0024 - val_loss: 0.0883 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0021 - val_loss: 0.0883 - learning_rate: 7.8125e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.3, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - loss: 0.1778 - val_loss: 0.0816 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0050 - val_loss: 0.0911 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0045 - val_loss: 0.0938 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0042 - val_loss: 0.0972 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0045 - val_loss: 0.0922 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0042 - val_loss: 0.0919 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0041 - val_loss: 0.0907 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0040 - val_loss: 0.0930 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0039 - val_loss: 0.0907 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0041 - val_loss: 0.0909 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0038 - val_loss: 0.0936 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.5, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 0.1733 - val_loss: 0.0643 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0143 - val_loss: 0.0881 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0086 - val_loss: 0.0908 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0076 - val_loss: 0.0946 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0064 - val_loss: 0.0902 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0065 - val_loss: 0.0902 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0061 - val_loss: 0.0919 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0054 - val_loss: 0.0919 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0056 - val_loss: 0.0933 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0056 - val_loss: 0.0919 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0054 - val_loss: 0.0932 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.5, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - loss: 0.2622 - val_loss: 0.0579 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0974 - val_loss: 0.0513 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.0198 - val_loss: 0.0837 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0119 - val_loss: 0.0889 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0082 - val_loss: 0.0890 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0084 - val_loss: 0.0898 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0083 - val_loss: 0.0894 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0080 - val_loss: 0.0914 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0073 - val_loss: 0.0905 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0075 - val_loss: 0.0930 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0068 - val_loss: 0.0927 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0067 - val_loss: 0.0921 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.5, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - loss: 0.2809 - val_loss: 0.0406 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.1311 - val_loss: 0.0419 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0772 - val_loss: 0.0525 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0191 - val_loss: 0.0943 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0112 - val_loss: 0.0888 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0108 - val_loss: 0.0895 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0097 - val_loss: 0.0894 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0090 - val_loss: 0.0899 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0087 - val_loss: 0.0901 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0088 - val_loss: 0.0901 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0082 - val_loss: 0.0904 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.5, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 0.0731 - val_loss: 0.0894 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0047 - val_loss: 0.0884 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0049 - val_loss: 0.0973 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0046 - val_loss: 0.0927 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0048 - val_loss: 0.0928 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0038 - val_loss: 0.0988 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0043 - val_loss: 0.0997 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0041 - val_loss: 0.0886 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0037 - val_loss: 0.0931 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0034 - val_loss: 0.0960 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0034 - val_loss: 0.0926 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0035 - val_loss: 0.0916 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.5, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - loss: 0.1246 - val_loss: 0.0904 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0060 - val_loss: 0.0947 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0051 - val_loss: 0.0940 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0047 - val_loss: 0.0915 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0042 - val_loss: 0.0966 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0041 - val_loss: 0.0901 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0043 - val_loss: 0.0961 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0041 - val_loss: 0.0937 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0043 - val_loss: 0.0921 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0042 - val_loss: 0.0895 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0041 - val_loss: 0.0942 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0037 - val_loss: 0.0926 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0040 - val_loss: 0.0961 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0039 - val_loss: 0.0946 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0039 - val_loss: 0.0953 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0040 - val_loss: 0.0932 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0038 - val_loss: 0.0931 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0035 - val_loss: 0.0947 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0038 - val_loss: 0.0954 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0038 - val_loss: 0.0917 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.5, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - loss: 0.1277 - val_loss: 0.0802 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0070 - val_loss: 0.0886 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0054 - val_loss: 0.0962 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0049 - val_loss: 0.0932 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0045 - val_loss: 0.0964 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0045 - val_loss: 0.0939 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0046 - val_loss: 0.0910 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0042 - val_loss: 0.0924 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0042 - val_loss: 0.0948 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0037 - val_loss: 0.0941 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0040 - val_loss: 0.0926 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.5, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 0.0816 - val_loss: 0.0964 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0046 - val_loss: 0.0890 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0059 - val_loss: 0.0959 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0041 - val_loss: 0.0948 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0044 - val_loss: 0.0979 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0044 - val_loss: 0.0962 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0040 - val_loss: 0.0949 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0040 - val_loss: 0.0926 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0036 - val_loss: 0.0942 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0032 - val_loss: 0.0925 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0035 - val_loss: 0.0874 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0030 - val_loss: 0.0967 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0030 - val_loss: 0.0942 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0027 - val_loss: 0.0937 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0026 - val_loss: 0.1010 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0023 - val_loss: 0.0998 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0027 - val_loss: 0.0950 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0025 - val_loss: 0.0994 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0025 - val_loss: 0.0979 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0025 - val_loss: 0.0949 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0024 - val_loss: 0.0976 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.5, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.1643 - val_loss: 0.0950 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0052 - val_loss: 0.1006 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0044 - val_loss: 0.0929 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0043 - val_loss: 0.0949 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0042 - val_loss: 0.0962 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0041 - val_loss: 0.0968 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0041 - val_loss: 0.0940 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0044 - val_loss: 0.0980 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0041 - val_loss: 0.0956 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0039 - val_loss: 0.0920 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0043 - val_loss: 0.0925 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0039 - val_loss: 0.0900 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0039 - val_loss: 0.0932 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0035 - val_loss: 0.0942 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0038 - val_loss: 0.0977 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0037 - val_loss: 0.0924 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0034 - val_loss: 0.0920 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0036 - val_loss: 0.0944 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0035 - val_loss: 0.0948 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0033 - val_loss: 0.0948 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0034 - val_loss: 0.0955 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0032 - val_loss: 0.0972 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=2, dropout=0.5, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - loss: 0.1350 - val_loss: 0.0867 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0050 - val_loss: 0.0912 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0047 - val_loss: 0.0926 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0045 - val_loss: 0.0981 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0042 - val_loss: 0.0972 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0044 - val_loss: 0.0957 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 0.0042 - val_loss: 0.0950 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0043 - val_loss: 0.0965 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0044 - val_loss: 0.0955 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0040 - val_loss: 0.0931 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0040 - val_loss: 0.0959 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.2, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 0.1440 - val_loss: 0.0257 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0215 - val_loss: 0.0833 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0066 - val_loss: 0.0905 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0062 - val_loss: 0.0895 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0052 - val_loss: 0.0874 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0057 - val_loss: 0.0879 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0052 - val_loss: 0.0892 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0048 - val_loss: 0.0869 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0043 - val_loss: 0.0887 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0048 - val_loss: 0.0866 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0047 - val_loss: 0.0882 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.2, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - loss: 0.1853 - val_loss: 0.0215 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0398 - val_loss: 0.0263 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0229 - val_loss: 0.0531 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0100 - val_loss: 0.0934 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0067 - val_loss: 0.0869 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0067 - val_loss: 0.0884 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0065 - val_loss: 0.0854 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0059 - val_loss: 0.0858 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0059 - val_loss: 0.0897 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0055 - val_loss: 0.0898 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0056 - val_loss: 0.0881 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.2, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - loss: 0.2545 - val_loss: 0.0086 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0560 - val_loss: 0.0158 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0394 - val_loss: 0.0258 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0273 - val_loss: 0.0402 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0159 - val_loss: 0.0523 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0106 - val_loss: 0.0705 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0082 - val_loss: 0.0844 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0071 - val_loss: 0.0877 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0065 - val_loss: 0.0878 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0069 - val_loss: 0.0871 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0074 - val_loss: 0.0874 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.2, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - loss: 0.0654 - val_loss: 0.0960 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0044 - val_loss: 0.0884 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0048 - val_loss: 0.0847 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0038 - val_loss: 0.0882 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0037 - val_loss: 0.0922 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0033 - val_loss: 0.0913 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0023 - val_loss: 0.0966 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0033 - val_loss: 0.0848 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0022 - val_loss: 0.0842 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0022 - val_loss: 0.0761 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0019 - val_loss: 0.0715 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0021 - val_loss: 0.0822 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0018 - val_loss: 0.0707 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0018 - val_loss: 0.0829 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0017 - val_loss: 0.0704 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0018 - val_loss: 0.0913 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0017 - val_loss: 0.0736 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0018 - val_loss: 0.0923 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0017 - val_loss: 0.0761 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 20/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0014 - val_loss: 0.0732 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 21/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0015 - val_loss: 0.0762 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 22/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - loss: 0.0015 - val_loss: 0.0837 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 23/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0014 - val_loss: 0.0846 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 24/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0014 - val_loss: 0.0812 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 25/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0012 - val_loss: 0.0775 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.2, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - loss: 0.0849 - val_loss: 0.0836 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0051 - val_loss: 0.0857 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0047 - val_loss: 0.0881 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0042 - val_loss: 0.0991 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0040 - val_loss: 0.0851 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0040 - val_loss: 0.0889 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0037 - val_loss: 0.0846 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0033 - val_loss: 0.0875 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0031 - val_loss: 0.0772 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0033 - val_loss: 0.0790 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0032 - val_loss: 0.0922 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0029 - val_loss: 0.0830 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0028 - val_loss: 0.0925 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0025 - val_loss: 0.0816 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0027 - val_loss: 0.0789 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0024 - val_loss: 0.0848 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0023 - val_loss: 0.0835 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0022 - val_loss: 0.0801 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0023 - val_loss: 0.0857 - learning_rate: 3.1250e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.2, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 81ms/step - loss: 0.1177 - val_loss: 0.0561 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0105 - val_loss: 0.0949 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0044 - val_loss: 0.0909 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0044 - val_loss: 0.0920 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0043 - val_loss: 0.0955 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0041 - val_loss: 0.0903 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0041 - val_loss: 0.0883 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0040 - val_loss: 0.0897 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0039 - val_loss: 0.0875 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0041 - val_loss: 0.0867 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0039 - val_loss: 0.0899 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.2, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - loss: 0.1010 - val_loss: 0.0897 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0045 - val_loss: 0.0848 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0044 - val_loss: 0.0976 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0045 - val_loss: 0.0883 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0039 - val_loss: 0.0863 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0030 - val_loss: 0.0875 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0028 - val_loss: 0.0999 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0018 - val_loss: 0.0670 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0025 - val_loss: 0.0914 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0017 - val_loss: 0.0756 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0020 - val_loss: 0.0776 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0019 - val_loss: 0.0791 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0014 - val_loss: 0.0815 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0015 - val_loss: 0.0887 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0013 - val_loss: 0.0810 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0015 - val_loss: 0.0853 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0013 - val_loss: 0.0794 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0012 - val_loss: 0.0809 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.2, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 64ms/step - loss: 0.1650 - val_loss: 0.0855 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0045 - val_loss: 0.0866 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0044 - val_loss: 0.0900 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0041 - val_loss: 0.0879 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0040 - val_loss: 0.0908 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0041 - val_loss: 0.0904 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0041 - val_loss: 0.0916 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0039 - val_loss: 0.0975 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0038 - val_loss: 0.0888 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0035 - val_loss: 0.0932 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0035 - val_loss: 0.0910 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.2, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - loss: 0.3030 - val_loss: 0.0773 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0060 - val_loss: 0.0856 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0042 - val_loss: 0.0912 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0043 - val_loss: 0.0891 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0040 - val_loss: 0.0895 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0040 - val_loss: 0.0906 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0042 - val_loss: 0.0938 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0040 - val_loss: 0.0920 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0040 - val_loss: 0.0917 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0040 - val_loss: 0.0911 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0040 - val_loss: 0.0919 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.3, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - loss: 0.1562 - val_loss: 0.0379 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0169 - val_loss: 0.0930 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0080 - val_loss: 0.0908 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0067 - val_loss: 0.0900 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0055 - val_loss: 0.0911 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0051 - val_loss: 0.0899 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0053 - val_loss: 0.0880 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0049 - val_loss: 0.0908 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0053 - val_loss: 0.0929 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0051 - val_loss: 0.0925 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0049 - val_loss: 0.0920 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.3, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - loss: 0.2005 - val_loss: 0.0299 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0499 - val_loss: 0.0417 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0183 - val_loss: 0.0951 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0081 - val_loss: 0.0915 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0073 - val_loss: 0.0895 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0068 - val_loss: 0.0915 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0067 - val_loss: 0.0938 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0064 - val_loss: 0.0909 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0064 - val_loss: 0.0906 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0059 - val_loss: 0.0893 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0059 - val_loss: 0.0903 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.3, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - loss: 0.2106 - val_loss: 0.0225 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0707 - val_loss: 0.0255 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0431 - val_loss: 0.0498 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0149 - val_loss: 0.0947 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0094 - val_loss: 0.0869 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0078 - val_loss: 0.0870 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0078 - val_loss: 0.0885 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0077 - val_loss: 0.0891 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0075 - val_loss: 0.0890 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0071 - val_loss: 0.0909 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0064 - val_loss: 0.0905 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.3, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - loss: 0.0538 - val_loss: 0.0871 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0055 - val_loss: 0.0980 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0045 - val_loss: 0.0853 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0045 - val_loss: 0.0882 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0041 - val_loss: 0.0940 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0041 - val_loss: 0.0929 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0047 - val_loss: 0.0990 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0032 - val_loss: 0.0944 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0029 - val_loss: 0.0838 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - loss: 0.0026 - val_loss: 0.0970 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0022 - val_loss: 0.0889 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0025 - val_loss: 0.0915 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0022 - val_loss: 0.0953 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0021 - val_loss: 0.0848 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0020 - val_loss: 0.0912 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0020 - val_loss: 0.0876 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0019 - val_loss: 0.0893 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0018 - val_loss: 0.0893 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0020 - val_loss: 0.0914 - learning_rate: 6.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.3, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 63ms/step - loss: 0.0862 - val_loss: 0.0906 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0054 - val_loss: 0.0948 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0051 - val_loss: 0.0879 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0048 - val_loss: 0.1003 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0044 - val_loss: 0.0968 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0041 - val_loss: 0.0850 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0042 - val_loss: 0.0913 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0037 - val_loss: 0.0946 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0039 - val_loss: 0.0930 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0032 - val_loss: 0.0920 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0031 - val_loss: 0.0900 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0030 - val_loss: 0.0920 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0029 - val_loss: 0.0868 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0028 - val_loss: 0.0898 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0028 - val_loss: 0.0888 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0025 - val_loss: 0.0958 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.3, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 81ms/step - loss: 0.1198 - val_loss: 0.0926 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0060 - val_loss: 0.0885 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0048 - val_loss: 0.0948 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0045 - val_loss: 0.0850 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0051 - val_loss: 0.0858 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0048 - val_loss: 0.0885 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0044 - val_loss: 0.0976 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0041 - val_loss: 0.0938 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0039 - val_loss: 0.0940 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0038 - val_loss: 0.0926 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0038 - val_loss: 0.0906 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0038 - val_loss: 0.0907 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0034 - val_loss: 0.0892 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0036 - val_loss: 0.0922 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.3, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - loss: 0.1083 - val_loss: 0.0929 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - loss: 0.0046 - val_loss: 0.0966 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0048 - val_loss: 0.0847 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0046 - val_loss: 0.0969 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0044 - val_loss: 0.1041 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0039 - val_loss: 0.0888 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0034 - val_loss: 0.0914 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0027 - val_loss: 0.0965 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - loss: 0.0024 - val_loss: 0.0955 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0023 - val_loss: 0.0950 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0021 - val_loss: 0.0915 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0020 - val_loss: 0.0898 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0018 - val_loss: 0.0918 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.3, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 65ms/step - loss: 0.2700 - val_loss: 0.0903 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0048 - val_loss: 0.0939 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0046 - val_loss: 0.0954 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0047 - val_loss: 0.0935 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0042 - val_loss: 0.0900 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0042 - val_loss: 0.0898 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0040 - val_loss: 0.0978 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0038 - val_loss: 0.0892 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0041 - val_loss: 0.0933 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0039 - val_loss: 0.0908 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0038 - val_loss: 0.0943 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0036 - val_loss: 0.0924 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0035 - val_loss: 0.0983 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0035 - val_loss: 0.0942 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0031 - val_loss: 0.0904 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0032 - val_loss: 0.0907 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0030 - val_loss: 0.0892 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0029 - val_loss: 0.0910 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.3, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - loss: 0.2190 - val_loss: 0.1025 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0064 - val_loss: 0.0924 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0045 - val_loss: 0.0915 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0042 - val_loss: 0.0956 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0043 - val_loss: 0.0881 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0047 - val_loss: 0.0955 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - loss: 0.0040 - val_loss: 0.0924 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0041 - val_loss: 0.0954 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0042 - val_loss: 0.0959 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0040 - val_loss: 0.0893 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0042 - val_loss: 0.0958 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0040 - val_loss: 0.0921 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0038 - val_loss: 0.0938 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - loss: 0.0040 - val_loss: 0.0934 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0038 - val_loss: 0.0955 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.5, lr=0.0001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - loss: 0.1807 - val_loss: 0.0803 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0139 - val_loss: 0.0871 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.0099 - val_loss: 0.0898 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.0072 - val_loss: 0.0964 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0067 - val_loss: 0.0954 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0064 - val_loss: 0.0947 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0060 - val_loss: 0.0917 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0057 - val_loss: 0.0954 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0054 - val_loss: 0.0938 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0052 - val_loss: 0.0968 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.0052 - val_loss: 0.0961 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.5, lr=0.0001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - loss: 0.2487 - val_loss: 0.0471 - learning_rate: 1.0000e-04\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - loss: 0.0761 - val_loss: 0.0894 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0165 - val_loss: 0.0883 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0116 - val_loss: 0.0922 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.0102 - val_loss: 0.0915 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0096 - val_loss: 0.0894 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0080 - val_loss: 0.0935 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0073 - val_loss: 0.0923 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0082 - val_loss: 0.0913 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.0075 - val_loss: 0.0932 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - loss: 0.0079 - val_loss: 0.0936 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.5, lr=0.0001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 85ms/step - loss: 0.2510 - val_loss: 0.0359 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.1096 - val_loss: 0.0364 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0419 - val_loss: 0.0978 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0143 - val_loss: 0.0870 - learning_rate: 1.0000e-04\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0130 - val_loss: 0.0899 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0110 - val_loss: 0.0898 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0098 - val_loss: 0.0888 - learning_rate: 5.0000e-05\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0089 - val_loss: 0.0911 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0101 - val_loss: 0.0902 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0091 - val_loss: 0.0914 - learning_rate: 2.5000e-05\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0083 - val_loss: 0.0913 - learning_rate: 1.2500e-05\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.5, lr=0.001, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 50ms/step - loss: 0.0739 - val_loss: 0.1056 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.0066 - val_loss: 0.1011 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - loss: 0.0052 - val_loss: 0.0954 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.0044 - val_loss: 0.0947 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.0047 - val_loss: 0.0998 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0044 - val_loss: 0.0946 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0045 - val_loss: 0.0906 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.0042 - val_loss: 0.0950 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0044 - val_loss: 0.1049 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0048 - val_loss: 0.0941 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0039 - val_loss: 0.0983 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0038 - val_loss: 0.0952 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.0038 - val_loss: 0.0935 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0035 - val_loss: 0.0931 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0035 - val_loss: 0.0953 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0033 - val_loss: 0.0941 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0033 - val_loss: 0.0967 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.5, lr=0.001, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 69ms/step - loss: 0.1122 - val_loss: 0.0863 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.0064 - val_loss: 0.0955 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - loss: 0.0050 - val_loss: 0.0948 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.0049 - val_loss: 0.0930 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.0046 - val_loss: 0.0947 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0048 - val_loss: 0.0899 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.0043 - val_loss: 0.0932 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - loss: 0.0042 - val_loss: 0.0936 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0043 - val_loss: 0.0951 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0041 - val_loss: 0.0934 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0041 - val_loss: 0.0926 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.5, lr=0.001, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - loss: 0.1311 - val_loss: 0.0927 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0069 - val_loss: 0.0984 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0053 - val_loss: 0.0987 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0051 - val_loss: 0.0938 - learning_rate: 0.0010\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0048 - val_loss: 0.0941 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0048 - val_loss: 0.0953 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0044 - val_loss: 0.0960 - learning_rate: 5.0000e-04\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0040 - val_loss: 0.0958 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0042 - val_loss: 0.0981 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0040 - val_loss: 0.0976 - learning_rate: 2.5000e-04\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0041 - val_loss: 0.0960 - learning_rate: 1.2500e-04\b\b\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.5, lr=0.005, batch_size=16\nEpoch 1/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - loss: 0.0790 - val_loss: 0.0907 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0048 - val_loss: 0.1043 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0050 - val_loss: 0.0938 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0047 - val_loss: 0.0923 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0043 - val_loss: 0.0911 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - loss: 0.0043 - val_loss: 0.0983 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0042 - val_loss: 0.0950 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0043 - val_loss: 0.0926 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0043 - val_loss: 0.0885 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0041 - val_loss: 0.0974 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0041 - val_loss: 0.0964 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0040 - val_loss: 0.0969 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - loss: 0.0040 - val_loss: 0.0959 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0039 - val_loss: 0.0981 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 0.0039 - val_loss: 0.0946 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0039 - val_loss: 0.0956 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0038 - val_loss: 0.0947 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 18/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0035 - val_loss: 0.0958 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\nEpoch 19/100\n\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - loss: 0.0037 - val_loss: 0.0965 - learning_rate: 1.5625e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.5, lr=0.005, batch_size=32\nEpoch 1/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 68ms/step - loss: 0.1275 - val_loss: 0.0948 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.0052 - val_loss: 0.0906 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.0046 - val_loss: 0.0943 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - loss: 0.0043 - val_loss: 0.0964 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - loss: 0.0047 - val_loss: 0.0947 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.0043 - val_loss: 0.0922 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - loss: 0.0043 - val_loss: 0.0933 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - loss: 0.0043 - val_loss: 0.0920 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - loss: 0.0044 - val_loss: 0.0966 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - loss: 0.0041 - val_loss: 0.0939 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - loss: 0.0041 - val_loss: 0.0966 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - loss: 0.0040 - val_loss: 0.0964 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nTraining model with units=150, layers=3, dropout=0.5, lr=0.005, batch_size=48\nEpoch 1/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - loss: 0.2519 - val_loss: 0.1011 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0064 - val_loss: 0.0911 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0047 - val_loss: 0.0938 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0044 - val_loss: 0.0931 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0045 - val_loss: 0.0938 - learning_rate: 0.0050\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0044 - val_loss: 0.0937 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0044 - val_loss: 0.0910 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0044 - val_loss: 0.0937 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0042 - val_loss: 0.0954 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0042 - val_loss: 0.0946 - learning_rate: 0.0025\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0046 - val_loss: 0.0946 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0041 - val_loss: 0.0949 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0043 - val_loss: 0.0974 - learning_rate: 0.0012\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0044 - val_loss: 0.0961 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 15/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0040 - val_loss: 0.0966 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 16/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0042 - val_loss: 0.0957 - learning_rate: 6.2500e-04\b\b\b\b\b\b\b\nEpoch 17/100\n\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0041 - val_loss: 0.0954 - learning_rate: 3.1250e-04\b\b\b\b\b\b\b\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2024-11-13 21:20:08.962083: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
        }
      ],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731538780566
        }
      },
      "id": "8cb28c39-2653-41a7-95e5-8b486b84dcd8"
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training history of the best model\n",
        "# Plot the loss and validation loss over epochs for the best model\n",
        "plt.plot(best_history.history['loss'], label='Train Loss')\n",
        "plt.plot(best_history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 640x480 with 1 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        }
      ],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1731538781039
        }
      },
      "id": "115214aa-3add-4c98-87a8-e87493aab78b"
    },
    {
      "cell_type": "code",
      "source": [
        "# Output the best model parameters\n",
        "# Print the best hyperparameters found in the grid search\n",
        "print(f\"Best model parameters: Units={best_params[0]}, Layers={best_params[1]}, Dropout={best_params[2]}, Learning Rate={best_params[3]}, Batch Size={best_params[4]}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Best model parameters: Units=150, Layers=2, Dropout=0.2, Learning Rate=0.0001, Batch Size=48\n"
        }
      ],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1731538781523
        }
      },
      "id": "8b3841a0-3f81-4ec1-bf15-ed1ad06b83f6"
    },
    {
      "cell_type": "code",
      "source": [
        "#best_model.save('LL Prediction 1.h5')"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1731538781852
        }
      },
      "id": "042b6d75-62d1-44e2-81c8-ea6138a5290d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing Part"
      ],
      "metadata": {},
      "id": "2e133462-e8a3-4326-953c-f7d0b9ca59d1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1) Load the model"
      ],
      "metadata": {},
      "id": "3e9ef43e-7b23-45d4-86d7-d55be0c5b542"
    },
    {
      "cell_type": "code",
      "source": [
        "best_model"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 26,
          "data": {
            "text/plain": "<Sequential name=sequential_191, built=True>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731538782187
        }
      },
      "id": "8ef1ae10-315f-4645-a08f-e491085e4c8b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2) Window sampling for testing set"
      ],
      "metadata": {},
      "id": "3064e6bc-e88a-4b59-8c3b-bf832807cb88"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Parameters for window sampling\n",
        "input_window_size = 28\n",
        "output_window_size = 1\n",
        "stride = 1\n",
        "\n",
        "# Initialize lists to store the input (X_test) and output (y_test) sequences for testing set\n",
        "X_test, y_test = [], []\n",
        "\n",
        "# Loop through the testing set to create windows of input and output sequences\n",
        "for i in range(0, len(testing_set) - input_window_size - output_window_size + 1, stride):\n",
        "    # Define the input window (20 data points)\n",
        "    input_window = testing_set.iloc[i:i+input_window_size][['Longitude']]\n",
        "    # Define the output window (1 data point immediately following the input window)\n",
        "    output_window = testing_set.iloc[i+input_window_size:i+input_window_size+output_window_size][['Longitude']]\n",
        "    # Append the input window to X_test and the last value of output window to y_test\n",
        "    X_test.append(input_window.values)\n",
        "    y_test.append(output_window.values[-1])\n",
        "\n",
        "# Convert X_test and y_test lists to numpy arrays for model input\n",
        "X_test, y_test = np.array(X_test), np.array(y_test)\n",
        "\n",
        "# Print the number of samples created for testing\n",
        "print(f\"Number of test samples: {X_test.shape[0]}\")\n",
        "print(f\"Test input shape: {X_test.shape}, Test target shape: {y_test.shape}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Number of test samples: 280\nTest input shape: (280, 28, 1), Test target shape: (280, 1)\n"
        }
      ],
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1731538782551
        }
      },
      "id": "21eb4d35-9feb-4cb5-991f-648de6aa57f6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3) Test the Testing Set Using the Imported Model"
      ],
      "metadata": {},
      "id": "f5067a01-5653-4c44-a2e2-55a792560d85"
    },
    {
      "cell_type": "code",
      "source": [
        "best_model"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 28,
          "data": {
            "text/plain": "<Sequential name=sequential_191, built=True>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731538782956
        }
      },
      "id": "5cac2aa7-758b-4fbe-884a-a516f591b3de"
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the testing set\n",
        "y_pred = best_model.predict(X_test)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\r\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 284ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m6/9\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step\n"
        }
      ],
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1731538783473
        }
      },
      "id": "9063ce56-d2b5-4a47-a40c-989f99422ce6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4) Calculate Error on the Testing Set"
      ],
      "metadata": {},
      "id": "b9406b06-7176-4b4b-937e-f2495d76f9f9"
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 30,
          "data": {
            "text/plain": "array([[0.54440153],\n       [0.5554638 ],\n       [0.56382811],\n       [0.56829003],\n       [0.57425237],\n       [0.58313585],\n       [0.59026783],\n       [0.59282236],\n       [0.59170273],\n       [0.58827891],\n       [0.5824468 ],\n       [0.57443593],\n       [0.56937078],\n       [0.56276703],\n       [0.55471535],\n       [0.54800752],\n       [0.54159654],\n       [0.53394411],\n       [0.52558359],\n       [0.51511276],\n       [0.50573748],\n       [0.49511316],\n       [0.48642578],\n       [0.47728882],\n       [0.46855368],\n       [0.46134796],\n       [0.45659069],\n       [0.45025845],\n       [0.443922  ],\n       [0.43895003],\n       [0.43470956],\n       [0.43094242],\n       [0.42736628],\n       [0.42386545],\n       [0.42021978],\n       [0.41574869],\n       [0.41095753],\n       [0.40547303],\n       [0.3987972 ],\n       [0.39201651],\n       [0.38729488],\n       [0.38622759],\n       [0.38631725],\n       [0.38630336],\n       [0.38635949],\n       [0.38536097],\n       [0.38400286],\n       [0.37732441],\n       [0.36870602],\n       [0.35900373],\n       [0.34935929],\n       [0.34127326],\n       [0.33056814],\n       [0.32260056],\n       [0.319162  ],\n       [0.31563808],\n       [0.31566691],\n       [0.31561759],\n       [0.31561799],\n       [0.315618  ],\n       [0.31561803],\n       [0.31561813],\n       [0.31561793],\n       [0.31561711],\n       [0.31561802],\n       [0.31561799],\n       [0.31136547],\n       [0.31826264],\n       [0.32024485],\n       [0.31967136],\n       [0.3102338 ],\n       [0.2989428 ],\n       [0.2877802 ],\n       [0.2743078 ],\n       [0.26192987],\n       [0.25237225],\n       [0.24114128],\n       [0.23013082],\n       [0.21811043],\n       [0.20765379],\n       [0.19386378],\n       [0.18081196],\n       [0.16929911],\n       [0.15818077],\n       [0.14816592],\n       [0.13783394],\n       [0.12584325],\n       [0.1155826 ],\n       [0.10596358],\n       [0.09965646],\n       [0.08639791],\n       [0.07730224],\n       [0.07158263],\n       [0.06964443],\n       [0.06834369],\n       [0.06657058],\n       [0.06443383],\n       [0.06290118],\n       [0.06158471],\n       [0.060456  ],\n       [0.05999488],\n       [0.05932206],\n       [0.05833617],\n       [0.0578569 ],\n       [0.05774148],\n       [0.05763634],\n       [0.06026349],\n       [0.06385846],\n       [0.06614163],\n       [0.07357681],\n       [0.07927964],\n       [0.09272888],\n       [0.102496  ],\n       [0.11270427],\n       [0.1256377 ],\n       [0.13795057],\n       [0.15151987],\n       [0.16515313],\n       [0.18346327],\n       [0.20279525],\n       [0.22238799],\n       [0.2458878 ],\n       [0.27023254],\n       [0.29449317],\n       [0.32059908],\n       [0.34928839],\n       [0.37260371],\n       [0.39035411],\n       [0.39388449],\n       [0.39552152],\n       [0.39689262],\n       [0.39657937],\n       [0.395734  ],\n       [0.39599312],\n       [0.39589907],\n       [0.39490918],\n       [0.3947208 ],\n       [0.39258971],\n       [0.39168987],\n       [0.3969515 ],\n       [0.39901506],\n       [0.394956  ],\n       [0.39408118],\n       [0.39353032],\n       [0.39137599],\n       [0.39137611],\n       [0.39137772],\n       [0.39137635],\n       [0.39192566],\n       [0.39247497],\n       [0.40182986],\n       [0.41458748],\n       [0.42189554],\n       [0.41601775],\n       [0.38470587],\n       [0.35106148],\n       [0.32313684],\n       [0.29456925],\n       [0.26854198],\n       [0.24596752],\n       [0.22520108],\n       [0.2050359 ],\n       [0.18593068],\n       [0.16688698],\n       [0.15348661],\n       [0.14023258],\n       [0.12752249],\n       [0.11551042],\n       [0.10711176],\n       [0.09666368],\n       [0.08812152],\n       [0.07757054],\n       [0.0698163 ],\n       [0.06599945],\n       [0.06196021],\n       [0.05770446],\n       [0.05786356],\n       [0.05809012],\n       [0.0582736 ],\n       [0.05851741],\n       [0.05865578],\n       [0.05883894],\n       [0.05900274],\n       [0.06082617],\n       [0.06248695],\n       [0.06425045],\n       [0.06612639],\n       [0.06801265],\n       [0.07079991],\n       [0.07860214],\n       [0.08936363],\n       [0.10151336],\n       [0.11545553],\n       [0.12750699],\n       [0.13967485],\n       [0.15005259],\n       [0.1626661 ],\n       [0.17306443],\n       [0.1843362 ],\n       [0.19537595],\n       [0.2075795 ],\n       [0.21910034],\n       [0.23086318],\n       [0.24235118],\n       [0.25384607],\n       [0.26415811],\n       [0.27599141],\n       [0.28603256],\n       [0.29849147],\n       [0.30835269],\n       [0.31902724],\n       [0.33087725],\n       [0.34063561],\n       [0.3550964 ],\n       [0.36420729],\n       [0.37468897],\n       [0.38252857],\n       [0.38575379],\n       [0.39269348],\n       [0.38602999],\n       [0.38490101],\n       [0.38459436],\n       [0.38619282],\n       [0.38886468],\n       [0.39585242],\n       [0.40238474],\n       [0.40866742],\n       [0.41366672],\n       [0.41825953],\n       [0.42279587],\n       [0.42709752],\n       [0.43108481],\n       [0.4356126 ],\n       [0.43969984],\n       [0.44380815],\n       [0.45178818],\n       [0.4563178 ],\n       [0.46249365],\n       [0.46662947],\n       [0.477784  ],\n       [0.48543758],\n       [0.49944034],\n       [0.50777447],\n       [0.51853811],\n       [0.52565866],\n       [0.53985627],\n       [0.54829284],\n       [0.55770095],\n       [0.56538868],\n       [0.57737677],\n       [0.58845301],\n       [0.59687868],\n       [0.60466188],\n       [0.61581645],\n       [0.62878594],\n       [0.63522265],\n       [0.64569842],\n       [0.65371367],\n       [0.66682322],\n       [0.6735362 ],\n       [0.68122959],\n       [0.6913456 ],\n       [0.69905133],\n       [0.70818253],\n       [0.71758548],\n       [0.72471566],\n       [0.73372903],\n       [0.74173902],\n       [0.75087992],\n       [0.76228074],\n       [0.77070263],\n       [0.78114859],\n       [0.7888199 ],\n       [0.79818021],\n       [0.80597521],\n       [0.81527677],\n       [0.82316407],\n       [0.83373094],\n       [0.83914935],\n       [0.8473078 ]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731538783921
        }
      },
      "id": "cf7652c9-f8c7-47ca-b618-25498194e5aa"
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 31,
          "data": {
            "text/plain": "array([[0.50541157],\n       [0.5061922 ],\n       [0.5075259 ],\n       [0.50940955],\n       [0.5117878 ],\n       [0.5146149 ],\n       [0.51787096],\n       [0.5215247 ],\n       [0.52545553],\n       [0.5295146 ],\n       [0.533548  ],\n       [0.5373903 ],\n       [0.5408771 ],\n       [0.54391515],\n       [0.5464192 ],\n       [0.5483157 ],\n       [0.5495771 ],\n       [0.55020076],\n       [0.5501848 ],\n       [0.54953206],\n       [0.54822856],\n       [0.54628706],\n       [0.5437129 ],\n       [0.540547  ],\n       [0.5368265 ],\n       [0.53257746],\n       [0.52787095],\n       [0.5228023 ],\n       [0.51744115],\n       [0.5118631 ],\n       [0.50612336],\n       [0.50030875],\n       [0.49450392],\n       [0.48875415],\n       [0.48308828],\n       [0.4775463 ],\n       [0.4721595 ],\n       [0.46693966],\n       [0.46187565],\n       [0.45693812],\n       [0.45209575],\n       [0.4473225 ],\n       [0.4426678 ],\n       [0.43819293],\n       [0.4339372 ],\n       [0.4299377 ],\n       [0.42621425],\n       [0.4227691 ],\n       [0.41953334],\n       [0.41639656],\n       [0.41325453],\n       [0.41000178],\n       [0.4065846 ],\n       [0.40292752],\n       [0.39900383],\n       [0.39485613],\n       [0.39055255],\n       [0.3861979 ],\n       [0.38188007],\n       [0.3776777 ],\n       [0.37365454],\n       [0.3698587 ],\n       [0.36632326],\n       [0.3630684 ],\n       [0.3601062 ],\n       [0.3574365 ],\n       [0.3550539 ],\n       [0.3528954 ],\n       [0.35103607],\n       [0.34947154],\n       [0.34815395],\n       [0.34693187],\n       [0.34564385],\n       [0.34414643],\n       [0.34229714],\n       [0.33999363],\n       [0.33722377],\n       [0.3339591 ],\n       [0.33019045],\n       [0.32590622],\n       [0.3211212 ],\n       [0.31583843],\n       [0.31005162],\n       [0.30377498],\n       [0.29705787],\n       [0.28994763],\n       [0.28250566],\n       [0.2747673 ],\n       [0.26678523],\n       [0.25861472],\n       [0.25034603],\n       [0.24197462],\n       [0.23353994],\n       [0.22511669],\n       [0.21681777],\n       [0.20877038],\n       [0.20100164],\n       [0.19359711],\n       [0.18661372],\n       [0.18012036],\n       [0.1741334 ],\n       [0.16865425],\n       [0.16368347],\n       [0.15919198],\n       [0.15514374],\n       [0.15152588],\n       [0.14831254],\n       [0.14551394],\n       [0.14313655],\n       [0.14119004],\n       [0.13971737],\n       [0.13873057],\n       [0.138329  ],\n       [0.13855155],\n       [0.13943031],\n       [0.14101726],\n       [0.14332318],\n       [0.14636359],\n       [0.15012765],\n       [0.1546963 ],\n       [0.16009319],\n       [0.16633545],\n       [0.17347011],\n       [0.18155229],\n       [0.19061972],\n       [0.20070982],\n       [0.2118659 ],\n       [0.2240458 ],\n       [0.23711921],\n       [0.25076607],\n       [0.26465762],\n       [0.2784954 ],\n       [0.2920038 ],\n       [0.30495635],\n       [0.31719825],\n       [0.32860857],\n       [0.3391098 ],\n       [0.3486832 ],\n       [0.35728312],\n       [0.36494023],\n       [0.37173674],\n       [0.37778   ],\n       [0.38307595],\n       [0.3876631 ],\n       [0.39160267],\n       [0.3949256 ],\n       [0.3976987 ],\n       [0.39996457],\n       [0.4017837 ],\n       [0.40322295],\n       [0.40432543],\n       [0.40525955],\n       [0.4062265 ],\n       [0.40732095],\n       [0.4084375 ],\n       [0.40916723],\n       [0.40909666],\n       [0.4079829 ],\n       [0.40557832],\n       [0.4017382 ],\n       [0.3964385 ],\n       [0.38972563],\n       [0.38168266],\n       [0.37243629],\n       [0.36212513],\n       [0.35095137],\n       [0.3391203 ],\n       [0.32680857],\n       [0.3141542 ],\n       [0.30136284],\n       [0.2885949 ],\n       [0.27595636],\n       [0.2635164 ],\n       [0.25136352],\n       [0.23959365],\n       [0.22828925],\n       [0.21750683],\n       [0.20733143],\n       [0.19782911],\n       [0.18900096],\n       [0.18085833],\n       [0.17343473],\n       [0.16677883],\n       [0.160973  ],\n       [0.15598518],\n       [0.15173903],\n       [0.14819054],\n       [0.14527947],\n       [0.14294201],\n       [0.14113456],\n       [0.13987938],\n       [0.13922952],\n       [0.13925089],\n       [0.13998988],\n       [0.14148012],\n       [0.14373341],\n       [0.14672107],\n       [0.15041359],\n       [0.15477368],\n       [0.15974721],\n       [0.16529353],\n       [0.17136134],\n       [0.1778882 ],\n       [0.18483709],\n       [0.1921683 ],\n       [0.19982225],\n       [0.20775014],\n       [0.21592541],\n       [0.22430217],\n       [0.2328693 ],\n       [0.24158582],\n       [0.25042462],\n       [0.25936905],\n       [0.26838905],\n       [0.27751538],\n       [0.28671157],\n       [0.29595977],\n       [0.3052058 ],\n       [0.3143223 ],\n       [0.3232528 ],\n       [0.3317878 ],\n       [0.339811  ],\n       [0.34726253],\n       [0.35412338],\n       [0.3604204 ],\n       [0.36623105],\n       [0.37165523],\n       [0.3767707 ],\n       [0.38163728],\n       [0.38629356],\n       [0.39077932],\n       [0.39511934],\n       [0.39933178],\n       [0.40343684],\n       [0.4074517 ],\n       [0.41137785],\n       [0.41528347],\n       [0.41916475],\n       [0.42306185],\n       [0.42696494],\n       [0.43095294],\n       [0.43506637],\n       [0.43938774],\n       [0.44396123],\n       [0.44881523],\n       [0.4539373 ],\n       [0.45940977],\n       [0.46518397],\n       [0.47130632],\n       [0.4776936 ],\n       [0.48434845],\n       [0.49125496],\n       [0.4983664 ],\n       [0.50561345],\n       [0.5130015 ],\n       [0.5205587 ],\n       [0.52822846],\n       [0.5360074 ],\n       [0.5438566 ],\n       [0.5518113 ],\n       [0.55981845],\n       [0.56783897],\n       [0.5758761 ],\n       [0.5838997 ],\n       [0.59188557],\n       [0.59985423],\n       [0.6077693 ],\n       [0.6156437 ],\n       [0.6234324 ],\n       [0.63116467],\n       [0.63885087],\n       [0.64651954],\n       [0.6541828 ],\n       [0.66184205],\n       [0.6694675 ],\n       [0.677074  ],\n       [0.6846616 ],\n       [0.6922244 ],\n       [0.69976544],\n       [0.7072431 ]], dtype=float32)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 31,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731538784373
        }
      },
      "id": "7df0a1ae-aae3-462f-abc2-c61902494a1b"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Calculate MSE between predicted and actual values\n",
        "error = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error on the Testing Set: {error}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Mean Squared Error on the Testing Set: 0.009359235248420524\n"
        }
      ],
      "execution_count": 32,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731538784663
        }
      },
      "id": "8e68e4cc-6596-4a8b-b34a-e36ed460e689"
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the original data for predicted cells and add it to testing set as a new column\n",
        "# Convert predictions to a DataFrame for easier concatenation\n",
        "predictions_df = pd.DataFrame(y_pred, columns=['Predicted_Longitude'])"
      ],
      "outputs": [],
      "execution_count": 33,
      "metadata": {
        "gather": {
          "logged": 1731538784946
        }
      },
      "id": "c96b794c-6223-4bf1-a92d-9aa8fe4f37ae"
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 34,
          "data": {
            "text/plain": "   Predicted_Longitude\n0             0.505412\n1             0.506192\n2             0.507526\n3             0.509410\n4             0.511788",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Predicted_Longitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.505412</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.506192</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.507526</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.509410</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.511788</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 34,
      "metadata": {
        "gather": {
          "logged": 1731538785310
        }
      },
      "id": "be80fb11-820e-4e20-9b61-42581e57b3b0"
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the predictions (y_pred) into a DataFrame for easy handling with timestamps\n",
        "# We assume `testing_set.index[input_window_size:]` matches the `y_pred` in length\n",
        "predicted_longitude = pd.DataFrame(y_pred, index=testing_set.index[input_window_size:], columns=['Predicted_Longitude'])\n",
        "\n",
        "# Add the 'Longitude' column from `testing_set` as the true values for comparison\n",
        "testing_longitudes = testing_set[['Longitude']].iloc[input_window_size:]  # Skip initial window\n",
        "\n",
        "# Define the months for filtering and specific timestamps for illustration\n",
        "months = {\n",
        "    'April': '2024-04',\n",
        "    'May': '2024-05',\n",
        "    'June': '2024-06',\n",
        "    'July': '2024-07',\n",
        "    'August': '2024-08'\n",
        "}\n",
        "\n",
        "# Plot each month's data\n",
        "for month_name, month_str in months.items():\n",
        "    # Filter data for the entire month\n",
        "    monthly_actual_data = testing_longitudes[testing_longitudes.index.to_period('M') == month_str]\n",
        "    monthly_predicted_data = predicted_longitude[predicted_longitude.index.to_period('M') == month_str]\n",
        "    \n",
        "    # Plot actual vs predicted longitude values for the month\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(monthly_actual_data.index, monthly_actual_data['Longitude'], label='Actual Longitude', color='blue')\n",
        "    plt.plot(monthly_predicted_data.index, monthly_predicted_data['Predicted_Longitude'], label='Predicted Longitude', color='orange')\n",
        "    \n",
        "    # Formatting the plot\n",
        "    plt.title(f'{month_name} 2024 - Longitude vs Predicted Longitude')\n",
        "    plt.xlabel('Received Timestamp')\n",
        "    plt.ylabel('Longitude')\n",
        "    plt.legend()\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 1200x600 with 1 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 1200x600 with 1 Axes>",
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAJOCAYAAABm7rQwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB2z0lEQVR4nOzdeZyN9f//8eeZfTCLZcyQsYQY69gblb2IsmfPEqkUiiilUKEdJVspLZSlSIiPFCHJvjWWZGcsYcZYZjvv3x9+c75OMxhj5jrNnMf9dju3mmt9XdfrHOY8Xdf7shljjAAAAAAAAAALebi6AAAAAAAAALgfQikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAIBr2Gw2jRw50pJ9jRw5UjabzZJ95Rb/7s+MGTNks9l08OBBl9X0b1a+h7ITnwUAQHYjlAIAuIXUL642m01r1qxJM98Yo/DwcNlsNj300EOW1ma32zVjxgy1bNlS4eHhyps3rypVqqQ33nhDV65cSXed6dOnKyIiQn5+fipbtqw+/PDDNMt899136tixo+68807lyZNH5cqV0+DBg3X+/Pkb1rN//375+fnJZrNp48aNWXGIDgcPHpTNZtO7776bpdvNTr/99ptGjhx50/PmDlKDg9RXnjx5VKFCBQ0fPlxxcXGuLu+WzJo1S+PHj3fZ/vksAABAKAUAcDN+fn6aNWtWmumrVq3S0aNH5evra3lNly5dUq9evXT69Gk9+eSTGj9+vGrXrq0RI0bowQcflDHGafmpU6eqT58+qlixoj788ENFRUVpwIABeuutt5yW69u3r6Kjo9WtWzd98MEHatasmSZOnKioqChdvnz5uvU899xz8vLyypZjzQkuX76s4cOHO37+7bffNGrUKL6IX2Py5Mn68ssv9f7776t8+fIaPXq0mjVrlua9aoVHH31Uly9fVokSJW5pPVeHUjkBnwUAQHZz3984AQBuqXnz5po7d64++OADp+Bl1qxZqlGjhs6cOWN5TT4+Plq7dq3q1q3rmPb444+rZMmSGjFihFasWKEmTZpIuvol8eWXX1aLFi00b948x7J2u12vv/66+vbtq/z580uS5s2bpwYNGjjtq0aNGurRo4dmzpypPn36pKll2bJlWrZsmYYOHao33ngjm474v83Pz8/VJfzntW/fXoUKFZIkPfnkk2rXrp2+++47/f7774qKikp3nUuXLilPnjxZXounp6c8PT2zfLvgswAAyH5cKQUAcCudO3fWP//8o+XLlzumJSYmat68eerSpUu667z77ruqW7euChYsKH9/f9WoUcMRCKWqX7++qlatmu765cqVU9OmTa9bk4+Pj1MglapNmzaSpOjoaMe0X375Rf/884/69evntOzTTz+tixcvavHixY5p/w6krrfNVElJSRo4cKAGDhyo0qVLX7deK5w6dUq9e/dWaGio/Pz8VLVqVX3++edOy1x7+9O0adNUunRp+fr6qlatWtqwYUOabc6dO1cVKlSQn5+fKlWqpPnz56tnz54qWbKk03LXjqMzcuRIDRkyRJJUqlQpx21rBw8edOx/xowZafaV3lg8a9asUa1ateTn56fSpUtr6tSp1z3+r776SjVq1JC/v78KFCigTp066ciRIzc8Z/PmzZPNZtOqVavSzJs6dapsNpt27twpSYqJiVGvXr1UrFgx+fr6qkiRImrVqlWmx2Vq1KiRJOnAgQOSrr73KlWqpE2bNqlevXrKkyePXnrpJUlSQkKCRowYoTJlysjX11fh4eEaOnSoEhISnLaZkJCg5557TiEhIQoICFDLli119OjRNPu+3phSP/74o+rXr6+AgAAFBgaqVq1ajqskGzRooMWLF+vQoUOOnl77PsjqGm8Hn4Vb/ywAAHIOrpQCALiVkiVLKioqSl9//bUefPBBSVe/vMbGxqpTp0764IMP0qwzYcIEtWzZUl27dlViYqK++eYbPfLII1q0aJFatGgh6eotRI8//rh27typSpUqOdbdsGGD9u7d63QLTEbFxMRIkuOKFEnasmWLJKlmzZpOy9aoUUMeHh7asmWLunXrdkvbTDV+/HidO3dOw4cP13fffXfL9WaVy5cvq0GDBvrrr7/0zDPPqFSpUpo7d6569uyp8+fPa+DAgU7Lz5o1SxcuXNATTzwhm82mt99+W23bttXff/8tb29vSdLixYvVsWNHVa5cWWPHjtW5c+fUu3dv3XHHHTespW3bttq7d6++/vprjRs3znHeQkJCdPr06Qwf044dO/TAAw8oJCREI0eOVHJyskaMGKHQ0NA0y44ePVqvvPKKOnTooD59+uj06dP68MMPVa9ePW3ZskXBwcHp7qNFixbKly+f5syZo/r16zvNmz17tipWrOh4b7Zr1067du1S//79VbJkSZ06dUrLly/X4cOH0wQTGbF//35JUsGCBR3T/vnnHz344IPq1KmTunXrptDQUNntdrVs2VJr1qxR3759FRERoR07dmjcuHHau3evFixY4Fi/T58++uqrr9SlSxfVrVtXP//8s+PzdjMzZszQY489pooVK2rYsGEKDg7Wli1btHTpUnXp0kUvv/yyYmNjdfToUY0bN06SlC9fPkmyrMaM4LOQuc8CACAHMQAAuIHPPvvMSDIbNmwwEydONAEBAebSpUvGGGMeeeQR07BhQ2OMMSVKlDAtWrRwWjd1uVSJiYmmUqVKplGjRo5p58+fN35+fuaFF15wWnbAgAEmb968Jj4+/pZrbtKkiQkMDDTnzp1zTHv66aeNp6dnusuHhISYTp063XCbvXv3Np6enmbv3r1O00+cOGECAgLM1KlTjTHO5ysrHThwwEgy77zzznWXGT9+vJFkvvrqK8e0xMREExUVZfLly2fi4uKctlWwYEFz9uxZx7Lff/+9kWR++OEHx7TKlSubYsWKmQsXLjimrVy50kgyJUqUcNq/JDNixAjHz++8846RZA4cOJDusXz22WdpjuHf22jdurXx8/Mzhw4dckz7888/jaenp7n217GDBw8aT09PM3r0aKft7dixw3h5eaWZ/m+dO3c2hQsXNsnJyY5pJ06cMB4eHua1114zxhhz7ty5m/bgekaMGGEkmT179pjTp0+bAwcOmKlTpxpfX18TGhpqLl68aIwxpn79+kaSmTJlitP6X375pfHw8DCrV692mj5lyhQjyaxdu9YYY8zWrVuNJNOvXz+n5bp06ZLm3Ka+V1P7c/78eRMQEGDq1KljLl++7LS+3W53/H+LFi3S9D67akwPn4Xs/SwAAHIGbt8DALidDh066PLly1q0aJEuXLigRYsWXffWPUny9/d3/P+5c+cUGxur++67T5s3b3ZMDwoKUqtWrfT11187BntOSUnR7Nmz1bp1a+XNm/eWahwzZox++uknvfnmm05XA1y+fFk+Pj7pruPn53fDAcxnzZql6dOna/DgwSpbtqzTvBdeeEF33nlnuuNMWW3JkiUKCwtT586dHdO8vb01YMAAxcfHp7k9rWPHjo5xtCTpvvvukyT9/fffkqTjx49rx44d6t69u+NqGOnqLZeVK1fOzkORdPV9sGzZMrVu3VrFixd3TI+IiEhzW+d3330nu92uDh066MyZM45XWFiYypYtq19++eWG++rYsaNOnTqllStXOqbNmzdPdrtdHTt2lHT1/ezj46OVK1fq3LlzmTqmcuXKKSQkRKVKldITTzyhMmXKaPHixU5jRvn6+qpXr15O682dO1cREREqX7680/Gl3v6XenxLliyRJA0YMMBp/WefffamtS1fvlwXLlzQiy++mGZMJJvNdtP1ragxo/gsZP6zAADIGbh9DwDgdkJCQtSkSRPNmjVLly5dUkpKitq3b3/d5RctWqQ33nhDW7dudRpT5t9fcLt3767Zs2dr9erVqlevnn766SedPHlSjz766C3VN3v2bA0fPly9e/fWU0895TTP399fiYmJ6a535coVpwDtWqtXr1bv3r3VtGlTjR492mne77//ri+//FIrVqyQh8et/XtVSkpKmlt3ChQocN3gLCMOHTqksmXLpqklIiLCMf9a1365leT4Up4auKQuX6ZMmTT7KlOmjFO4mB1Onz6ty5cvpwkCpavhTmq4IUn79u2TMSbdZSU5bsG6nmbNmikoKEizZ89W48aNJV19P0VGRuquu+6SdDUseuuttzR48GCFhobq7rvv1kMPPaTu3bsrLCwsQ8f07bffKjAwUN7e3ipWrFi6Y5Ddcccdad4H+/btU3R0tEJCQtLd7qlTpyRd7ZmHh0ea7ZYrV+6mtaXeSnjtbbS3wooaM4rPQuY/CwCAnIFQCgDglrp06aLHH39cMTExevDBB687Nsnq1avVsmVL1atXT5MmTVKRIkXk7e2tzz77zDFocqqmTZsqNDRUX331lerVq6evvvpKYWFhjifnZcTy5cvVvXt3tWjRQlOmTEkzv0iRIkpJSdGpU6dUuHBhx/TExET9888/Klq0aJp1tm3bppYtW6pSpUqaN2+e01MHJWno0KG67777VKpUKcdg0alPITxx4oQOHz6c5stuqiNHjqhUqVJO03755Zd0B1nPLtd78lrqFWvZ5XpX3aSkpGR6m3a7XTabTT/++GO6x3Xt1S3p8fX1VevWrTV//nxNmjRJJ0+e1Nq1azVmzBin5Z599lk9/PDDWrBggZYtW6ZXXnlFY8eO1c8//6xq1ardtM569eqlOy7ZtdILSO12uypXrqz3338/3XXCw8Nvuu/slhNqvB4+CwCAnIZQCgDgltq0aaMnnnhCv//+u2bPnn3d5b799lv5+flp2bJl8vX1dUz/7LPP0izr6empLl26aMaMGXrrrbe0YMECPf744xl+XP369evVpk0b1axZU3PmzEkTHklSZGSkJGnjxo1q3ry5Y/rGjRtlt9sd81Pt379fzZo1U+HChbVkyZJ0v8gdPnxYhw4dShMuSVLLli0VFBSk8+fPp1tzWFiY05MMJV33KYQZVaJECW3fvl12u93pCpHdu3c75t/q9iTpr7/+SjMvvWn/dr0v3KlXofz73Pz76pWQkBD5+/tr3759abaxZ88ep59Lly4tY4xKlSrluLLpVnXs2FGff/65VqxYoejoaBljHLfu/XtfgwcP1uDBg7Vv3z5FRkbqvffe01dffZWp/WZE6dKltW3bNjVu3PiGt9KVKFFCdrtd+/fvd7ry6N/n63r7kKSdO3eme0VQquvt34oaM4rPwu19FgAA/32MKQUAcEv58uXT5MmTNXLkSD388MPXXc7T01M2m83pX/wPHjzo9ASuaz366KM6d+6cnnjiCcXHx9/wSXjXio6OVosWLVSyZEktWrTourfhNWrUSAUKFNDkyZOdpk+ePFl58uRxevJXTEyMHnjgAXl4eGjZsmXXvR1p2rRpmj9/vtOrf//+kqR3331XM2fOvG7dfn5+atKkidPr2jFtMqN58+aKiYlxCguTk5P14YcfKl++fGmeLHczRYsWVaVKlfTFF18oPj7eMX3VqlXasWPHTddPHQ/s31+4AwMDVahQIf36669O0ydNmuT0s6enp5o2baoFCxbo8OHDjunR0dFatmyZ07Jt27aVp6enRo0alebqFmOM/vnnn5vW26RJExUoUECzZ8/W7NmzVbt2bafA8dKlS7py5YrTOqVLl1ZAQIDT7anZoUOHDjp27Jg+/vjjNPMuX76sixcvSpLjyZj/fhrm+PHjb7qPBx54QAEBARo7dmya47z2nObNm1exsbEuqTGj+Czc3mcBAPDfx5VSAAC31aNHj5su06JFC73//vtq1qyZunTpolOnTumjjz5SmTJltH379jTLV6tWTZUqVXIMlly9evWb7uPChQtq2rSpzp07pyFDhmjx4sVO80uXLq2oqChJV2+Jev311/X000/rkUceUdOmTbV69Wp99dVXGj16tAoUKOBYr1mzZvr77781dOhQrVmzRmvWrHHMCw0N1f333y/p6pf4f0v90lm/fn3VrFnzpsdwq1asWJEmMJCk1q1bq2/fvpo6dap69uypTZs2qWTJkpo3b57Wrl2r8ePHKyAg4Jb3N2bMGLVq1Ur33HOPevXqpXPnzmnixImqVKmS05fz9NSoUUOS9PLLL6tTp07y9vbWww8/rLx586pPnz5688031adPH9WsWVO//vqr9u7dm2Ybo0aN0tKlS3XfffepX79+jmChYsWKTu+j0qVL64033tCwYcN08OBBtW7dWgEBATpw4IDmz5+vvn376vnnn79hvd7e3mrbtq2++eYbXbx4Ue+++67T/L1796px48bq0KGDKlSoIC8vL82fP18nT55Up06dMnpKM+XRRx/VnDlz9OSTT+qXX37RPffco5SUFO3evVtz5szRsmXLVLNmTUVGRqpz586aNGmSYmNjVbduXa1YsSJDV/MEBgZq3Lhx6tOnj2rVqqUuXboof/782rZtmy5duqTPP/9c0tW+zp49W4MGDVKtWrWUL18+Pfzww5bUeC0+C9n3WQAA5AAueeYfAAAWS31s/IYNG264XIkSJUyLFi2cpk2fPt2ULVvW+Pr6mvLly5vPPvvMjBgxwlzvr9G3337bSDJjxozJUG2pj1O/3qtHjx5p1pk2bZopV66c8fHxMaVLlzbjxo1zety9MeaG26xfv/4Na8ro+bpVNzvWL7/80hhjzMmTJ02vXr1MoUKFjI+Pj6lcuXKax82nbuudd95Jsx/96zH0xhjzzTffmPLlyxtfX19TqVIls3DhQtOuXTtTvnz5m677+uuvmzvuuMN4eHgYSebAgQPGGGMuXbpkevfubYKCgkxAQIDp0KGDOXXqVLrbWLVqlalRo4bx8fExd955p5kyZcp130fffvutuffee03evHlN3rx5Tfny5c3TTz9t9uzZc/OTbIxZvny5kWRsNps5cuSI07wzZ86Yp59+2pQvX97kzZvXBAUFmTp16pg5c+bcdLup9Z4+ffqGy9WvX99UrFgx3XmJiYnmrbfeMhUrVjS+vr4mf/78pkaNGmbUqFEmNjbWsdzly5fNgAEDTMGCBU3evHnNww8/bI4cOZLm3Ka+V1N7kmrhwoWmbt26xt/f3wQGBpratWubr7/+2jE/Pj7edOnSxQQHBxtJpkSJEtlWY3r4LFjzWQAA/LfZjMnmkQ8BAHAzEyZM0HPPPaeDBw9ed4Bw/DdERkYqJCQkzbhYgLvhswAAcAXGlAIAIAsZYzR9+nTVr1+fQOo/JCkpScnJyU7TVq5cqW3btln6pEDA1fgsAAD+SxhTCgCALHDx4kUtXLhQv/zyi3bs2KHvv//e1SXhGseOHVOTJk3UrVs3FS1aVLt379aUKVMUFhamJ5980tXlAZbhswAA+C8hlAIAIAucPn1aXbp0UXBwsF566SW1bNnS1SXhGvnz51eNGjX0ySef6PTp08qbN69atGihN998UwULFnR1eYBl+CwAAP5LGFMKAAAAAAAAlmNMKQAAAAAAAFiOUAoAAAAAAACWY0ypLGC323X8+HEFBATIZrO5uhwAAAAAAACXMcbowoULKlq0qDw8rn89FKFUFjh+/LjCw8NdXQYAAAAAAMB/xpEjR1SsWLHrzieUygIBAQGSrp7swMBAF1cDAAAAAADgOnFxcQoPD3fkJddDKJUFUm/ZCwwMJJQCAAAAAACQbjrEEQOdAwAAAAAAwHKEUgAAAAAAALAcoRQAAAAAAAAsx5hSAAAAAABkoZSUFCUlJbm6DCDbeHt7y9PT87a3QygFAAAAAEAWMMYoJiZG58+fd3UpQLYLDg5WWFjYTQczvxFCKQAAAAAAskBqIFW4cGHlyZPntr6sA/9VxhhdunRJp06dkiQVKVIk09silAIAAAAA4DalpKQ4AqmCBQu6uhwgW/n7+0uSTp06pcKFC2f6Vj4GOgcAAAAA4DaljiGVJ08eF1cCWCP1vX4746cRSgEAAAAAkEW4ZQ/uIive64RSAAAAAAAAsByhFAAAAAAA+M+y2WxasGCBq8u4oYMHD8pms2nr1q3Zsv2ccA4yg1AKAAAAAABo3bp18vT0VIsWLW553ZIlS2r8+PFZX1QG9OzZU61bt3bJvlOFh4frxIkTqlSpkiRp5cqVstlsOn/+vEvr+q8jlAIAAAAAAJo+fbr69++vX3/9VcePH3d1OTmKp6enwsLC5OXl5epSchRCKQAAAAAA3Fx8fLxmz56tp556Si1atNCMGTPSLPPDDz+oVq1a8vPzU6FChdSmTRtJUoMGDXTo0CE999xzstlsjgGwR44cqcjISKdtjB8/XiVLlnT8vGHDBt1///0qVKiQgoKCVL9+fW3evDlLj23VqlWqXbu2fH19VaRIEb344otKTk52zG/QoIEGDBigoUOHqkCBAgoLC9PIkSOdtrF7927de++98vPzU4UKFfTTTz853VJ37e17Bw8eVMOGDSVJ+fPnl81mU8+ePSWlf0VZZGSk0/727dunevXqOfa1fPnyNMd05MgRdejQQcHBwSpQoIBatWqlgwcP3u6pshyhFAAAAAAA2cAY6eJF17yMubVa58yZo/Lly6tcuXLq1q2bPv30U5lrNrJ48WK1adNGzZs315YtW7RixQrVrl1bkvTdd9+pWLFieu2113TixAmdOHEiw/u9cOGCevTooTVr1uj3339X2bJl1bx5c124cOHWDuA6jh07pubNm6tWrVratm2bJk+erOnTp+uNN95wWu7zzz9X3rx5tX79er399tt67bXXHGFQSkqKWrdurTx58mj9+vWaNm2aXn755evuMzw8XN9++60kac+ePTpx4oQmTJiQoXrtdrvatm0rHx8frV+/XlOmTNELL7zgtExSUpKaNm2qgIAArV69WmvXrlW+fPnUrFkzJSYm3srpcTmuKwMAAAAAIBtcuiTly+eafcfHS3nzZnz56dOnq1u3bpKkZs2aKTY2VqtWrVKDBg0kSaNHj1anTp00atQoxzpVq1aVJBUoUECenp4KCAhQWFjYLdXZqFEjp5+nTZum4OBgrVq1Sg899NAtbSs9kyZNUnh4uCZOnCibzaby5cvr+PHjeuGFF/Tqq6/Kw+PqtTpVqlTRiBEjJElly5bVxIkTtWLFCt1///1avny59u/fr5UrVzqOb/To0br//vvT3aenp6cKFCggSSpcuLCCg4MzXO9PP/2k3bt3a9myZSpatKgkacyYMXrwwQcdy8yePVt2u12ffPKJ46q0zz77TMHBwVq5cqUeeOCBWztJLsSVUgAAAAAAuLE9e/bojz/+UOfOnSVJXl5e6tixo6ZPn+5YZuvWrWrcuHGW7/vkyZN6/PHHVbZsWQUFBSkwMFDx8fE6fPhwlmw/OjpaUVFRjvBGku655x7Fx8fr6NGjjmlVqlRxWq9IkSI6deqUpKvnJzw83ClwS71KLKtFR0crPDzcEUhJUlRUlNMy27Zt019//aWAgADly5dP+fLlU4ECBXTlyhXt378/W+rKLlwpBQAAAABANsiT5+oVS67ad0ZNnz5dycnJTkGIMUa+vr6aOHGigoKC5O/vf8s1eHh4ON0CKF299exaPXr00D///KMJEyaoRIkS8vX1VVRUlOW3oXl7ezv9bLPZZLfbs3w/GTknNxMfH68aNWpo5syZaeaFhITcVn1WI5QCAAAAACAb2Gy3dgudKyQnJ+uLL77Qe++9l+a2r9atW+vrr7/Wk08+qSpVqmjFihXq1atXutvx8fFRSkqK07SQkBDFxMTIGOO4Umnr1q1Oy6xdu1aTJk1S8+bNJV0dwPvMmTNZdHRSRESEvv32W6ca1q5dq4CAABUrVixD2yhXrpyOHDmikydPKjQ0VNLVAdpvxMfHR5LSPSfXjrkVFxenAwcOONV75MgRnThxQkWKFJEk/f77707bqF69umbPnq3ChQsrMDAwQ8fwX8XtewAAAAAAuKlFixbp3Llz6t27typVquT0ateuneMWvhEjRujrr7/WiBEjFB0drR07duitt95ybKdkyZL69ddfdezYMUeo1KBBA50+fVpvv/229u/fr48++kg//vij0/7Lli2rL7/8UtHR0Vq/fr26du2aqauyYmNjtXXrVqfXkSNH1K9fPx05ckT9+/fX7t279f3332vEiBEaNGiQYzypm7n//vtVunRp9ejRQ9u3b9fatWs1fPhwSXK6LfBaJUqUkM1m06JFi3T69GnF//9L5ho1aqQvv/xSq1ev1o4dO9SjRw95eno61mvSpInuuusu9ejRQ9u2bdPq1avTDKretWtXFSpUSK1atdLq1at14MABrVy5UgMGDHC6JTEnIJQCAAAAAMBNTZ8+XU2aNFFQUFCaee3atdPGjRu1fft2NWjQQHPnztXChQsVGRmpRo0a6Y8//nAs+9prr+ngwYMqXbq04xayiIgITZo0SR999JGqVq2qP/74Q88//3ya/Z87d07Vq1fXo48+qgEDBqhw4cK3fBwrV65UtWrVnF6jRo3SHXfcoSVLluiPP/5Q1apV9eSTT6p3796OUCkjPD09tWDBAsXHx6tWrVrq06ePIyjy8/NLd5077rhDo0aN0osvvqjQ0FA988wzkqRhw4apfv36euihh9SiRQu1bt1apUuXdqzn4eGh+fPn6/Lly6pdu7b69Omj0aNHO207T548+vXXX1W8eHG1bdtWERER6t27t65cuZLjrpyymX/fzIhbFhcXp6CgIMXGxua4NwAAAAAA4PZduXJFBw4cUKlSpa4bVCD3WLt2re6991799ddfTqGSO7nRez6jOQljSgEAAAAAANzA/PnzlS9fPpUtW1Z//fWXBg4cqHvuucdtA6msQigFAAAAAABwAxcuXNALL7ygw4cPq1ChQmrSpInee+89V5eV4xFKAQAAAAAA3ED37t3VvXt3V5eR6zDQOQAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAABL9OzZU61bt3b83KBBAz377LOW17Fy5UrZbDadP3/e8n3fihkzZig4ODhbtv1fOAeEUgAAAAAAuLGePXvKZrPJZrPJx8dHZcqU0Wuvvabk5ORs3/d3332n119/PUPLWh2ilCxZUuPHj7dkX9fTsWNH7d271/HzyJEjFRkZ6bqCspiXqwsAAAAAAACu1axZM3322WdKSEjQkiVL9PTTT8vb21vDhg1Ls2xiYqJ8fHyyZL8FChTIku3kVv7+/vL393d1GdmGK6UAAAAAAHBzvr6+CgsLU4kSJfTUU0+pSZMmWrhwoaT/u+Vu9OjRKlq0qMqVKydJOnLkiDp06KDg4GAVKFBArVq10sGDBx3bTElJ0aBBgxQcHKyCBQtq6NChMsY47ffft+8lJCTohRdeUHh4uHx9fVWmTBlNnz5dBw8eVMOGDSVJ+fPnl81mU8+ePSVJdrtdY8eOValSpeTv76+qVatq3rx5TvtZsmSJ7rrrLvn7+6thw4ZOdWbW5MmTVbp0afn4+KhcuXL68ssvnebbbDZ98sknatOmjfLkyaOyZcs6zmmqhQsXqmzZsvLz81PDhg31+eefO10Ndu3tezNmzNCoUaO0bds2x5VtM2bM0MGDB2Wz2bR161bHds+fPy+bzaaVK1fe0jlYs2aN7rvvPvn7+ys8PFwDBgzQxYsXb/tcXQ+hFAAAAAAA2cEYKfmia17/Cn9ulb+/vxITEx0/r1ixQnv27NHy5cu1aNEiJSUlqWnTpgoICNDq1au1du1a5cuXT82aNXOs995772nGjBn69NNPtWbNGp09e1bz58+/4X67d++ur7/+Wh988IGio6M1depU5cuXT+Hh4fr2228lSXv27NGJEyc0YcIESdLYsWP1xRdfaMqUKdq1a5eee+45devWTatWrZJ0NTxr27atHn74YW3dulV9+vTRiy++eFvnZ/78+Ro4cKAGDx6snTt36oknnlCvXr30yy+/OC03atQodejQQdu3b1fz5s3VtWtXnT17VpJ04MABtW/fXq1bt9a2bdv0xBNP6OWXX77uPjt27KjBgwerYsWKOnHihE6cOKGOHTtmqN6MnIP9+/erWbNmateunbZv367Zs2drzZo1euaZZ27x7GQct+8BAAAAAJAdUi5Jc/K5Zt8d4iWvvLe8mjFGK1as0LJly9S/f3/H9Lx58+qTTz5x3Lb31VdfyW6365NPPpHNZpMkffbZZwoODtbKlSv1wAMPaPz48Ro2bJjatm0rSZoyZYqWLVt23X3v3btXc+bM0fLly9WkSRNJ0p133umYn3qrX+HChR1XDyUkJGjMmDH66aefFBUV5VhnzZo1mjp1qurXr++4oum9996TJJUrV047duzQW2+9dcvnJ9W7776rnj17ql+/fpKkQYMG6ffff9e7777ruKJLunqVWefOnSVJY8aM0QcffKA//vhDzZo109SpU1WuXDm98847jrp27typ0aNHp7tPf39/5cuXT15eXgoLC7ulejNyDsaOHauuXbs6rlwrW7asPvjgA8c59PPzu6V9ZgShFAAAAAAAbm7RokXKly+fkpKSZLfb1aVLF40cOdIxv3Llyk7jSG3btk1//fWXAgICnLZz5coV7d+/X7GxsTpx4oTq1KnjmOfl5aWaNWumuYUv1datW+Xp6an69etnuO6//vpLly5d0v333+80PTExUdWqVZMkRUdHO9UhyRFgZVZ0dLT69u3rNO2ee+5xXL2VqkqVKo7/z5s3rwIDA3Xq1ClJV6/4qlWrltPytWvXvq26blTvzc7Btm3btH37ds2cOdMxzRgju92uAwcOKCIiIsvrIpQCAAAAACA7eOa5esWSq/Z9Cxo2bKjJkyfLx8dHRYsWlZeXc1yQN6/zVVfx8fGqUaOGU4CRKiQk5NbrlTI1oHd8/NXzu3jxYt1xxx1O83x9fTNVR1by9vZ2+tlms8lut2fpPjw8ro7MdG3Yl5SUdMvbiY+P1xNPPKEBAwakmVe8ePHMF3gDhFIAAAAAAGQHmy1Tt9C5Qt68eVWmTJkML1+9enXNnj1bhQsXVmBgYLrLFClSROvXr1e9evUkScnJydq0aZOqV6+e7vKVK1eW3W7XqlWrHLfvXSv1Sq2UlBTHtAoVKsjX11eHDx++7hVWERERaQYY//33329+kDcQERGhtWvXqkePHo5pa9euVYUKFTK8jXLlymnJkiVO0zZs2HDDdXx8fJyOX/q/EPDEiROOq8OuHfQ8td6bnYPq1avrzz//vKX3we1ioHMAAAAAAHBLunbtqkKFCqlVq1ZavXq1Dhw4oJUrV2rAgAE6evSoJGngwIF68803tWDBAu3evVv9+vVzPFUuPSVLllSPHj302GOPacGCBY5tzpkzR5JUokQJ2Ww2LVq0SKdPn1Z8fLwCAgL0/PPP67nnntPnn3+u/fv3a/Pmzfrwww/1+eefS5KefPJJ7du3T0OGDNGePXs0a9YszZgxI0PHeezYMW3dutXpde7cOQ0ZMkQzZszQ5MmTtW/fPr3//vv67rvv9Pzzz2f4HD7xxBPavXu3XnjhBcd4Wql1pY7Tld45OnDggLZu3aozZ84oISFB/v7+uvvuu/Xmm28qOjpaq1at0vDhw53Wy8g5eOGFF/Tbb7/pmWee0datW7Vv3z59//332TrQOaEUAAAAAAC4JXny5NGvv/6q4sWLq23btoqIiFDv3r115coVx5VTgwcP1qOPPqoePXooKipKAQEBatOmzQ23O3nyZLVv3179+vVT+fLl9fjjj+vixYuSpDvuuEOjRo3Siy++qNDQUEdY8vrrr+uVV17R2LFjFRERoWbNmmnx4sUqVaqUpKu3nn377bdasGCBqlatqilTpmjMmDEZOs53331X1apVc3otXrxYrVu31oQJE/Tuu++qYsWKmjp1qj777DM1aNAgw+ewVKlSmjdvnr777jtVqVJFkydPdjx973q3HrZr107NmjVTw4YNFRISoq+//lqS9Omnnyo5OVk1atTQs88+qzfeeMNpvYycgypVqmjVqlXau3ev7rvvPlWrVk2vvvqqihYtmuFjulU2c70RxpBhcXFxCgoKUmxs7HUvWwQAAAAA5F5XrlzRgQMHVKpUqWx5Shncw+jRozVlyhQdOXLE1aXc1I3e8xnNSRhTCgAAAAAAwAUmTZqkWrVqqWDBglq7dq3eeeedbL1d7r+GUAoAAAAAAMAF9u3bpzfeeENnz55V8eLFNXjwYA0bNszVZVmGUAoAAAAAAMAFxo0bp3Hjxrm6DJdhoHMAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAgi9jtdleXAFgiK97rjCkFAAAAAMBt8vHxkYeHh44fP66QkBD5+PjIZrO5uiwgyxljlJiYqNOnT8vDw0M+Pj6Z3hahFAAAAAAAt8nDw0OlSpXSiRMndPz4cVeXA2S7PHnyqHjx4vLwyPxNeIRSAAAAAABkAR8fHxUvXlzJyclKSUlxdTlAtvH09JSXl9dtXw1IKAUAAAAAQBax2Wzy9vaWt7e3q0sB/vMY6BwAAAAAAACWI5QCAAAAAACA5QilAAAAAAAAYLkcF0p99NFHKlmypPz8/FSnTh398ccfN1x+7ty5Kl++vPz8/FS5cmUtWbLkuss++eSTstlsGj9+fBZXDQAAAAAAgGvlqFBq9uzZGjRokEaMGKHNmzeratWqatq0qU6dOpXu8r/99ps6d+6s3r17a8uWLWrdurVat26tnTt3pll2/vz5+v3331W0aNHsPgwAAAAAAAC3l6NCqffff1+PP/64evXqpQoVKmjKlCnKkyePPv3003SXnzBhgpo1a6YhQ4YoIiJCr7/+uqpXr66JEyc6LXfs2DH1799fM2fO5AkJAAAAAAAAFsgxoVRiYqI2bdqkJk2aOKZ5eHioSZMmWrduXbrrrFu3zml5SWratKnT8na7XY8++qiGDBmiihUrZk/xAAAAAAAAcOLl6gIy6syZM0pJSVFoaKjT9NDQUO3evTvddWJiYtJdPiYmxvHzW2+9JS8vLw0YMCDDtSQkJCghIcHxc1xcXIbXBQAAAAAAQA66Uio7bNq0SRMmTNCMGTNks9kyvN7YsWMVFBTkeIWHh2djlQAAAAAAALlPjgmlChUqJE9PT508edJp+smTJxUWFpbuOmFhYTdcfvXq1Tp16pSKFy8uLy8veXl56dChQxo8eLBKlix53VqGDRum2NhYx+vIkSO3d3AAAAAAAABuJseEUj4+PqpRo4ZWrFjhmGa327VixQpFRUWlu05UVJTT8pK0fPlyx/KPPvqotm/frq1btzpeRYsW1ZAhQ7Rs2bLr1uLr66vAwECnFwAAAAAAADIux4wpJUmDBg1Sjx49VLNmTdWuXVvjx4/XxYsX1atXL0lS9+7ddccdd2js2LGSpIEDB6p+/fp677331KJFC33zzTfauHGjpk2bJkkqWLCgChYs6LQPb29vhYWFqVy5ctYeHAAAAAAAgBvJUaFUx44ddfr0ab366quKiYlRZGSkli5d6hjM/PDhw/Lw+L+Lv+rWratZs2Zp+PDheumll1S2bFktWLBAlSpVctUhAAAAAAAAQJLNGGNcXUROFxcXp6CgIMXGxnIrHwAAAAAAcGsZzUlyzJhSAAAAAAAAyD0IpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGC5HBdKffTRRypZsqT8/PxUp04d/fHHHzdcfu7cuSpfvrz8/PxUuXJlLVmyxDEvKSlJL7zwgipXrqy8efOqaNGi6t69u44fP57dhwEAAAAAAODWclQoNXv2bA0aNEgjRozQ5s2bVbVqVTVt2lSnTp1Kd/nffvtNnTt3Vu/evbVlyxa1bt1arVu31s6dOyVJly5d0ubNm/XKK69o8+bN+u6777Rnzx61bNnSysMCAAAAAABwOzZjjHF1ERlVp04d1apVSxMnTpQk2e12hYeHq3///nrxxRfTLN+xY0ddvHhRixYtcky7++67FRkZqSlTpqS7jw0bNqh27do6dOiQihcvnqG64uLiFBQUpNjYWAUGBmbiyAAAAAAAAHKHjOYkOeZKqcTERG3atElNmjRxTPPw8FCTJk20bt26dNdZt26d0/KS1LRp0+suL0mxsbGy2WwKDg6+7jIJCQmKi4tzegEAAAAAACDjckwodebMGaWkpCg0NNRpemhoqGJiYtJdJyYm5paWv3Llil544QV17tz5hkne2LFjFRQU5HiFh4ff4tEAAAAAAAC4txwTSmW3pKQkdejQQcYYTZ48+YbLDhs2TLGxsY7XkSNHLKoSAAAAAAAgd/BydQEZVahQIXl6eurkyZNO00+ePKmwsLB01wkLC8vQ8qmB1KFDh/Tzzz/fdFwoX19f+fr6ZuIoAAAAAAAAIOWgK6V8fHxUo0YNrVixwjHNbrdrxYoVioqKSnedqKgop+Ulafny5U7LpwZS+/bt008//aSCBQtmzwEAAAAAAADAIcdcKSVJgwYNUo8ePVSzZk3Vrl1b48eP18WLF9WrVy9JUvfu3XXHHXdo7NixkqSBAweqfv36eu+999SiRQt988032rhxo6ZNmybpaiDVvn17bd68WYsWLVJKSopjvKkCBQrIx8fHNQcKAAAAAACQy+WoUKpjx446ffq0Xn31VcXExCgyMlJLly51DGZ++PBheXj838VfdevW1axZszR8+HC99NJLKlu2rBYsWKBKlSpJko4dO6aFCxdKkiIjI5329csvv6hBgwaWHBcAAAAAAIC7sRljjKuLyOni4uIUFBSk2NjYm45HBQAAAAAAkJtlNCfJMWNKAQAAAAAAIPcglAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlMh1KJScn66efftLUqVN14cIFSdLx48cVHx+fZcUBAAAAAAAgd/LKzEqHDh1Ss2bNdPjwYSUkJOj+++9XQECA3nrrLSUkJGjKlClZXScAAAAAAABykUxdKTVw4EDVrFlT586dk7+/v2N6mzZttGLFiiwrDgAAAAAAALlTpq6UWr16tX777Tf5+Pg4TS9ZsqSOHTuWJYUBAAAAAAAg98rUlVJ2u10pKSlpph89elQBAQG3XRQAAAAAAAByt0yFUg888IDGjx/v+Nlmsyk+Pl4jRoxQ8+bNs6o2AAAAAAAA5FI2Y4y51ZWOHj2qpk2byhijffv2qWbNmtq3b58KFSqkX3/9VYULF86OWv+z4uLiFBQUpNjYWAUGBrq6HAAAAAAAAJfJaE6SqVBKkpKTk/XNN99o+/btio+PV/Xq1dW1a1engc/dBaEUAAAAAADAVRnNSTI10LkkeXl5qVu3bpldHQAAAAAAAG4sw6HUwoULM7zRli1bZqoYAAAAAAAAuIcMh1KtW7d2+tlms+nfd/7ZbDZJSvfJfAAAAAAAAECqDD99z263O17/+9//FBkZqR9//FHnz5/X+fPn9eOPP6p69epaunRpdtYLAAAAAACAXCBTY0o9++yzmjJliu69917HtKZNmypPnjzq27evoqOjs6xAAAAAAAAA5D4ZvlLqWvv371dwcHCa6UFBQTp48OBtlgQAAAAAAIDcLlOhVK1atTRo0CCdPHnSMe3kyZMaMmSIateunWXFAQAAAAAAIHfKVCj16aef6sSJEypevLjKlCmjMmXKqHjx4jp27JimT5+e1TUCAAAAAAAgl8nUmFJlypTR9u3btXz5cu3evVuSFBERoSZNmjiewAcAAAAAAABcj80YY1xdRE4XFxenoKAgxcbGKjAw0NXlAAAAAAAAuExGc5JMXSn12muv3XD+q6++mpnNAgAAAAAAwE1kKpSaP3++089JSUk6cOCAvLy8VLp0aUIpAAAAAAAA3FCmQqktW7akmRYXF6eePXuqTZs2t10UAAAAAAAAcrdMPX0vPYGBgRo1apReeeWVrNokAAAAAAAAcqksC6UkKTY2VrGxsVm5SQAAAAAAAORCmbp974MPPnD62RijEydO6Msvv9SDDz6YJYUBAAAAAAAg98pUKDVu3Dinnz08PBQSEqIePXpo2LBhWVIYAAAAAAAAcq9MhVIHDhzI6joAAAAAAADgRjI1ptRjjz2mCxcupJl+8eJFPfbYY7ddFAAAAAAAAHK3TIVSn3/+uS5fvpxm+uXLl/XFF1/cdlE38tFHH6lkyZLy8/NTnTp19Mcff9xw+blz56p8+fLy8/NT5cqVtWTJEqf5xhi9+uqrKlKkiPz9/dWkSRPt27cvOw8BAAAAAADA7d1SKBUXF6fY2FgZY3ThwgXFxcU5XufOndOSJUtUuHDh7KpVs2fP1qBBgzRixAht3rxZVatWVdOmTXXq1Kl0l//tt9/UuXNn9e7dW1u2bFHr1q3VunVr7dy507HM22+/rQ8++EBTpkzR+vXrlTdvXjVt2lRXrlzJtuMAAAAAAABwdzZjjMnowh4eHrLZbNffmM2mUaNG6eWXX86S4v6tTp06qlWrliZOnChJstvtCg8PV//+/fXiiy+mWb5jx466ePGiFi1a5Jh29913KzIyUlOmTJExRkWLFtXgwYP1/PPPS5JiY2MVGhqqGTNmqFOnThmqKy4uTkFBQYqNjVVgYGAWHCkAAAAAAEDOlNGc5JYGOv/ll19kjFGjRo307bffqkCBAo55Pj4+KlGihIoWLZr5qm8gMTFRmzZtcnq6n4eHh5o0aaJ169alu866des0aNAgp2lNmzbVggULJF0dsD0mJkZNmjRxzA8KClKdOnW0bt26DIdSAAAAAAAAuDW3FErVr19f0tUwp3jx4je8aiqrnTlzRikpKQoNDXWaHhoaqt27d6e7TkxMTLrLx8TEOOanTrveMulJSEhQQkKC4+e4uLiMHwgAAAAAAAAyHkpt375dlSpVkoeHh2JjY7Vjx47rLlulSpUsKe6/auzYsRo1apSrywAAAAAAAMixMhxKRUZGKiYmRoULF1ZkZKRsNpvSG47KZrMpJSUlS4uUpEKFCsnT01MnT550mn7y5EmFhYWlu05YWNgNl0/978mTJ1WkSBGnZSIjI69by7Bhw5xuC4yLi1N4ePgtHQ8AAAAAAIA7y/DT9w4cOKCQkBDH///99986cOBAmtfff/+dLYX6+PioRo0aWrFihWOa3W7XihUrFBUVle46UVFRTstL0vLlyx3LlypVSmFhYU7LxMXFaf369dfdpiT5+voqMDDQ6QUAAAAAAICMy/CVUiVKlEj3/600aNAg9ejRQzVr1lTt2rU1fvx4Xbx4Ub169ZIkde/eXXfccYfGjh0rSRo4cKDq16+v9957Ty1atNA333yjjRs3atq0aZKuXtX17LPP6o033lDZsmVVqlQpvfLKKypatKhat27tkmMEAAAAAABwB7c00HmqhQsXpjvdZrPJz89PZcqUUalSpW6rsPR07NhRp0+f1quvvqqYmBhFRkZq6dKljoHKDx8+LA+P/7v4q27dupo1a5aGDx+ul156SWXLltWCBQtUqVIlxzJDhw7VxYsX1bdvX50/f1733nuvli5dKj8/vyyvHwAAAAAAAFfZTHoDQ92Eh4dHumNKpU6z2Wy69957tWDBAuXPnz/Liv2viouLU1BQkGJjY7mVDwAAAAAAuLWM5iQZHlPqWsuXL1etWrW0fPlyxcbGKjY2VsuXL1edOnW0aNEi/frrr/rnn3/0/PPPZ/oAAAAAAAAAkHtl6va9gQMHatq0aapbt65jWuPGjeXn56e+fftq165dGj9+vB577LEsKxQAAAAAAAC5R6aulNq/f3+6l18FBgY6nr5XtmxZnTlz5vaqAwAAAAAAQK6UqVCqRo0aGjJkiE6fPu2Ydvr0aQ0dOlS1atWSJO3bt0/h4eFZUyUAAAAAAABylUzdvjd9+nS1atVKxYoVcwRPR44c0Z133qnvv/9ekhQfH6/hw4dnXaUAAAAAAADINTL19D1Jstvt+t///qe9e/dKksqVK6f7779fHh6ZuvgqR+PpewAAAAAAAFdlNCfJdCiF/0MoBQAAAAAAcFVGc5JM3b4nSStWrNCKFSt06tQp2e12p3mffvppZjcLAAAAAAAAN5CpUGrUqFF67bXXVLNmTRUpUkQ2my2r6wIAAAAAAEAulqlQasqUKZoxY4YeffTRrK4HAAAAAAAAbiBTo5InJiaqbt26WV0LAAAAAAAA3ESmQqk+ffpo1qxZWV0LAAAAAAAA3ESmbt+7cuWKpk2bpp9++klVqlSRt7e30/z3338/S4oDAAAAAABA7pSpUGr79u2KjIyUJO3cudNpHoOeAwAAAAAA4GYyFUr98ssvWV0HAAAAAAAA3EimxpS61tGjR3X06NGsqAUAAAAAAABuIlOhlN1u12uvvaagoCCVKFFCJUqUUHBwsF5//XXZ7fasrhEAAAAAAAC5TKZu33v55Zc1ffp0vfnmm7rnnnskSWvWrNHIkSN15coVjR49OkuLBAAAAAAAQO5iM8aYW12paNGimjJlilq2bOk0/fvvv1e/fv107NixLCswJ4iLi1NQUJBiY2MVGBjo6nIAAAAAAABcJqM5SaZu3zt79qzKly+fZnr58uV19uzZzGwSAAAAAAAAbiRToVTVqlU1ceLENNMnTpyoKlWq3HZRAAAAAAAAyN0yNabU22+/rRYtWuinn35SVFSUJGndunU6cuSIlixZkqUFAgAAAAAAIPfJ1JVS9evX1969e9WmTRudP39e58+fV9u2bbVr1y59+eWXWV0jAAAAAAAAcplMDXR+Pdu2bVP16tWVkpKSVZvMERjoHAAAAAAA4KpsHegcAAAAAAAAuB2EUgAAAAAAALAcoRQAAAAAAAAsd0tP32vbtu0N558/f/52agEAAAAAAICbuKVQKigo6Kbzu3fvflsFAQAAAAAAIPe7pVDqs88+y646AAAAAAAA4EYYUwoAAAAAAACWI5QCAAAAAACA5QilAAAAAAAAYDlCKQAAAAAAAFiOUAoAAAAAAACWI5QCAAAAAACA5QilAAAAAAAAYDlCKQAAAAAAAFiOUAoAAAAAAACWI5QCAAAAAACA5QilAAAAAAAAYDlCKQAAAAAAAFiOUAoAAAAAAACWI5QCAAAAAACA5QilAAAAAAAAYDlCKQAAAAAAAFiOUAoAAAAAAACWI5QCAAAAAACA5QilAAAAAAAAYDlCKQAAAAAAAFiOUAoAAAAAAACWI5QCAAAAAACA5QilAAAAAAAAYDlCKQAAAAAAAFiOUAoAAAAAAACWI5QCAAAAAACA5QilAAAAAAAAYDlCKQAAAAAAAFiOUAoAAAAAAACWI5QCAAAAAACA5QilAAAAAAAAYDlCKQAAAAAAAFiOUAoAAAAAAACWI5QCAAAAAACA5QilAAAAAAAAYDlCKQAAAAAAAFiOUAoAAAAAAACWI5QCAAAAAACA5QilAAAAAAAAYDlCKQAAAAAAAFiOUAoAAAAAAACWI5QCAAAAAACA5QilAAAAAAAAYDlCKQAAAAAAAFgux4RSZ8+eVdeuXRUYGKjg4GD17t1b8fHxN1znypUrevrpp1WwYEHly5dP7dq108mTJx3zt23bps6dOys8PFz+/v6KiIjQhAkTsvtQAAAAAAAA3F6OCaW6du2qXbt2afny5Vq0aJF+/fVX9e3b94brPPfcc/rhhx80d+5crVq1SsePH1fbtm0d8zdt2qTChQvrq6++0q5du/Tyyy9r2LBhmjhxYnYfDgAAAAAAgFuzGWOMq4u4mejoaFWoUEEbNmxQzZo1JUlLly5V8+bNdfToURUtWjTNOrGxsQoJCdGsWbPUvn17SdLu3bsVERGhdevW6e677053X08//bSio6P1888/Z7i+uLg4BQUFKTY2VoGBgZk4QgAAAAAAgNwhozlJjrhSat26dQoODnYEUpLUpEkTeXh4aP369emus2nTJiUlJalJkyaOaeXLl1fx4sW1bt266+4rNjZWBQoUuGE9CQkJiouLc3oBAAAAAAAg43JEKBUTE6PChQs7TfPy8lKBAgUUExNz3XV8fHwUHBzsND00NPS66/z222+aPXv2TW8LHDt2rIKCghyv8PDwjB8MAAAAAAAAXBtKvfjii7LZbDd87d6925Jadu7cqVatWmnEiBF64IEHbrjssGHDFBsb63gdOXLEkhoBAAAAAAByCy9X7nzw4MHq2bPnDZe58847FRYWplOnTjlNT05O1tmzZxUWFpbuemFhYUpMTNT58+edrpY6efJkmnX+/PNPNW7cWH379tXw4cNvWrevr698fX1vuhwAAAAAAADS59JQKiQkRCEhITddLioqSufPn9emTZtUo0YNSdLPP/8su92uOnXqpLtOjRo15O3trRUrVqhdu3aSpD179ujw4cOKiopyLLdr1y41atRIPXr00OjRo7PgqAAAAAAAAHAzOeLpe5L04IMP6uTJk5oyZYqSkpLUq1cv1axZU7NmzZIkHTt2TI0bN9YXX3yh2rVrS5KeeuopLVmyRDNmzFBgYKD69+8v6erYUdLVW/YaNWqkpk2b6p133nHsy9PTM0NhWSqevgcAAAAAAHBVRnMSl14pdStmzpypZ555Ro0bN5aHh4fatWunDz74wDE/KSlJe/bs0aVLlxzTxo0b51g2ISFBTZs21aRJkxzz582bp9OnT+urr77SV1995ZheokQJHTx40JLjAgAAAAAAcEc55kqp/zKulAIAAAAAALgqozmJS5++BwAAAAAAAPdEKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACyXY0Kps2fPqmvXrgoMDFRwcLB69+6t+Pj4G65z5coVPf300ypYsKDy5cundu3a6eTJk+ku+88//6hYsWKy2Ww6f/58NhwBAAAAAAAAUuWYUKpr167atWuXli9frkWLFunXX39V3759b7jOc889px9++EFz587VqlWrdPz4cbVt2zbdZXv37q0qVapkR+kAAAAAAAD4F5sxxri6iJuJjo5WhQoVtGHDBtWsWVOStHTpUjVv3lxHjx5V0aJF06wTGxurkJAQzZo1S+3bt5ck7d69WxEREVq3bp3uvvtux7KTJ0/W7Nmz9eqrr6px48Y6d+6cgoODM1xfXFycgoKCFBsbq8DAwNs7WAAAAAAAgBwsozlJjrhSat26dQoODnYEUpLUpEkTeXh4aP369emus2nTJiUlJalJkyaOaeXLl1fx4sW1bt06x7Q///xTr732mr744gt5eGTsdCQkJCguLs7pBQAAAAAAgIzLEaFUTEyMChcu7DTNy8tLBQoUUExMzHXX8fHxSXPFU2hoqGOdhIQEde7cWe+8846KFy+e4XrGjh2roKAgxys8PPzWDggAAAAAAMDNuTSUevHFF2Wz2W742r17d7btf9iwYYqIiFC3bt1ueb3Y2FjH68iRI9lUIQAAAAAAQO7k5cqdDx48WD179rzhMnfeeafCwsJ06tQpp+nJyck6e/aswsLC0l0vLCxMiYmJOn/+vNPVUidPnnSs8/PPP2vHjh2aN2+eJCl1eK1ChQrp5Zdf1qhRo9Ldtq+vr3x9fTNyiAAAAAAAAEiHS0OpkJAQhYSE3HS5qKgonT9/Xps2bVKNGjUkXQ2U7Ha76tSpk+46NWrUkLe3t1asWKF27dpJkvbs2aPDhw8rKipKkvTtt9/q8uXLjnU2bNigxx57TKtXr1bp0qVv9/AAAAAAAABwHS4NpTIqIiJCzZo10+OPP64pU6YoKSlJzzzzjDp16uR48t6xY8fUuHFjffHFF6pdu7aCgoLUu3dvDRo0SAUKFFBgYKD69++vqKgox5P3/h08nTlzxrG/W3n6HgAAAAAAAG5NjgilJGnmzJl65pln1LhxY3l4eKhdu3b64IMPHPOTkpK0Z88eXbp0yTFt3LhxjmUTEhLUtGlTTZo0yRXlAwAAAAAA4Bo2kzqQEjItLi5OQUFBio2NVWBgoKvLAQAAAAAAcJmM5iQuffoeAAAAAAAA3BOhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcl6uLiA3MMZIkuLi4lxcCQAAAAAAgGul5iOpecn1EEplgQsXLkiSwsPDXVwJAAAAAADAf8OFCxcUFBR03fk2c7PYCjdlt9t1/PhxBQQEyGazubqcTImLi1N4eLiOHDmiwMBAV5cDC9Bz90PP3Q89dz/03P3Qc/dCv90PPXc/uaXnxhhduHBBRYsWlYfH9UeO4kqpLODh4aFixYq5uowsERgYmKPf+Lh19Nz90HP3Q8/dDz13P/TcvdBv90PP3U9u6PmNrpBKxUDnAAAAAAAAsByhFAAAAAAAACxHKAVJkq+vr0aMGCFfX19XlwKL0HP3Q8/dDz13P/Tc/dBz90K/3Q89dz/u1nMGOgcAAAAAAIDluFIKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAcDMMLQzgv4BQCtmCv+SA3OfEiRPauHGjq8uAC9ntdleXACALnThxQufOnXN1GbBQUlKS4/d0m83Gn+tugu9m+C/zcnUByPkOHTqkNWvW6OLFi6pSpYruvvtux19yHh7knrnRwYMHtWjRIsXFxalixYpq1aqVq0tCNtu+fbvatGmjvn37qkiRIrrjjjtcXRKy2cGDB7Vu3TqdP39e5cuXV8OGDeXh4SFjjGw2m6vLQzY4cuSIfv/9d50+fVrVq1fX3Xff7eqSkI22bNmiGjVqaOnSpXrggQdcXQ4ssHv3bo0cOVLnz5+Xn5+fFixYwO/qudz58+eVJ08e+fj48Pe3mzh69Kiio6N14cIF1axZU8WLF3d1STdFKIXbsmPHDjVs2FAVKlTQjh07FB4errJly+rbb7+Vh4cHwVQutH37djVr1kyRkZHas2ePwsLC5OnpqYceesjVpSGb7N+/X02aNFHXrl01aNAgeXt7O83nc5777NixQ40bN9bdd9+tXbt2KTAwUGFhYZo/f778/Pz4xTYX2rFjh1q0aKEyZcpo8+bNqlixoh599FE9+eSTri4N2WDbtm2qX7++nnvuOQIpN7Fr1y7Vr19fLVu2VKlSpTRv3jx169ZNX331lSTx53ouFB0drV69eql169Z67rnn5OvrS59zuR07duiBBx5QsWLFtHnzZtWsWVN169bVuHHjXF3aDfEtApl28eJF9e3bVx07dtTPP/+sPXv26IUXXtD27dtVp04dJScnO4Ip5A579+7Vgw8+qMcee0yLFi3SmjVrdP78eZ04ccLVpSEbpF7qPXPmTNWvX1/jxo2Tp6enpk6dqjfeeENvvfWWJBFI5TL//POPunXrpscee0wLFy7Upk2b9Oyzz2rZsmVq0aKFzpw5wy0fuczff/+tli1bqlu3blq8eLH+/PNPlS5dWsuWLXN1acgGO3fu1L333qunn35a7733nux2u7Zs2aLFixdr+/btri4P2SA+Pl79+vVT165d9emnn2rMmDHq06ePChcu7FiGoCJ3OXz4sDp16qT9+/dr8eLFmjx5shISEmSz2biVL5eKjY1Vt27d1KlTJy1fvlwHDhxQixYt9L///e8/f1cL3ySQaQkJCbp48aKaN28uLy8vFS5cWB06dNBXX32lc+fOqVGjRpLkuN0DOVtCQoImTZqkpk2basSIEbLZbCpSpIgiIyO1Y8cODRky5D+fwuPWpP6CeuTIEd11112SpLp162rmzJn64Ycf9NFHH6lChQo6evSoJMYbyi2OHDkiY4yeeOIJSVJwcLAaNWqkcuXKaceOHXr44YclEUbmFklJSfryyy9Vs2ZNDRs2TL6+vipatKgef/xx/fLLLzp48KCrS0QWstvtGjVqlC5evKgRI0ZIkh588EH17dtXDz/8sLp06aLOnTu7uEpktfj4eJ0/f97xxdRms+no0aNatmyZoqKidO+99+q3336TxNhDuYExRj/88IOKFi2qxYsX66677tI333zjFEzxO1vuc+7cOV25ckWdOnVScHCwihcvrueee06vvvqqoqOj1aVLF1eXeF38RolMCwwMVHJysn7++WfHNG9vb9WuXVsff/yxYmJiNHz4cEn860tu4OnpqY4dO2rAgAHy9vaWzWbT6NGj9fXXX+vSpUvav3+/pkyZok6dOrm6VGQxu92u7du3a/bs2cqfP78WLVqkn3/+WevXr1dgYKDatWsniZAiNzl//rx27Njh+PnixYvy9/fXhAkTdPz4cb3//vsurA5ZLTg4WM2aNVNAQIDjcxwWFiYPDw8lJia6uDpkJQ8PD3344YeqWbOmatWqpXr16snHx0cfffSRdu/ercGDB2vz5s3q16+fq0tFFsqfP7+uXLmi9957T3v37tVLL72kjz/+WI899pgGDx6s4OBgderUSf/88w+/s+cCNptNrVq1Up8+fVS7dm1NmTJFFStW1Ndff61Jkybp8uXLXDSQCwUGBiohIcERMEtSQECAWrVqpZdfflk7d+7Uxx9/7MIKr49vEMg0m82m9u3b6/fff9fSpUudpt9zzz168MEHtXHjRiUnJ7uwSmQVLy8vVa9eXZGRkZKu3so3ceJELVy4UJ988om+++47Pffcc9q4caP27dvn2mKRpR599FH9888/mjBhgkqUKKHAwED5+/urSJEiGj9+vE6cOKFNmza5ukxkkdDQUN1555364osv9P7772vp0qWKiopSw4YN1blzZ9WsWVN79uxxdZnIAsYYeXt7q3v37urdu7ek/7viMSwsTCEhIfLy+r/hR6/9RyjkXGFhYVq0aJHy5s2rs2fP6qOPPlLt2rV11113qVu3bmrfvr02bNigs2fPurpUZAFjjHx9fTV+/Hj9+eefGjRokCZPnqypU6dq8ODBat++vRYsWKC4uDjNnTvX1eUiixQtWtTxj4be3t766KOPVLlyZX3zzTeaMmWKrly5IpvN5hhTDDmfn5+f6tWrp+XLl2vXrl1O09u3b68SJUpo1apVLqzw+hjoHBkWExOjv/76S15eXipdurRCQkL06KOP6n//+58mTpwof39/1a9fX9LVACMyMlJLly7VhQsXlD9/fhdXj8xI7bmnp6fKli2rQoUKOebddddd2r59u0JCQhwDXRcsWFDe3t4KCgpyYdW4Hdd+zsuUKaNChQqpQoUKKlOmjGbNmuXoberVFP7+/sqbN6/y5MnjyrJxG679nJcuXVpFihTRhAkTNGLECE2aNEk2m039+vXT6NGjJUmFCxfWoUOHXFw1bkdiYqLjSUySHH9HG2Mcn+3Lly8rNjZWCQkJkqRXXnlFn376qTZu3KgiRYq4pnBkyrX9Tr0KpnDhwvrhhx+0YcMGhYWFSboaSHp7e6tIkSK6dOlSmodaIOf492dcunqb5p49e3T69Gm1aNFCderUkXT1Ft7Tp0+rVKlSKlasmKtKxm06e/asYmJiJEnFihVTYGCg4/fzlJQU+fn56cMPP1T//v31zTffyBijffv26ZNPPlG9evVyxBPa4Oyff/7RsWPHlCdPHhUuXFiBgYF69tln9eCDD+qNN97Q6NGjdeedd0qS8ubNq3r16mn27Nm6fPmy/P39XVy9M0IpZMj27dvVqlUreXp6OpL1jz76SC1bttQnn3yiTp066e2339bhw4f16KOPKjk5Wdu2bVOxYsXk6+vr6vKRCf/uuYeHhyZPnqwHHnjA8YtqwYIFJf1fQLF+/XqVKVOGgCKHSu9zPmnSJD388MMaPXq04uLitHTpUj3zzDOaOHGizp07p4ULF8rf398psETOkV7PJ06cqFatWmnmzJlKSkrSuXPnVKpUKUlXv7SePHlSVapUcXHlyKzo6Gj169dPY8aMUVRUlNOX1mtv27l8+bIuXrwoX19fjRkzRu+8847Wrl1LIJXDpNfv1D6HhISoefPmjmVT/y7/888/ValSJfn4+LikZtye9Hqe2ncfHx+FhITI09NT8+fP17BhwyRJn376qeLj41W1alUXV4/M2LFjhx577DHFxcUpISFBNWrU0MSJEx1/Xnt6eiolJUX+/v6aOHGinnnmGb300kvy9fXVH3/8QSCVA23fvl0dO3ZUYmKikpOTVaRIEU2cOFE1a9bU/Pnzdf/998tut6tfv36Oi0b27dunYsWKydPT08XVp8MAN3Hq1ClTpkwZ88ILL5jDhw+b9evXm6eeesp4enqad9991xhjzK5du0yrVq1M2bJlTcmSJU2jRo1McHCw2bJli2uLR6Zcr+deXl5m3LhxJj4+3mn5s2fPmmHDhpmCBQuaHTt2uKhq3I4b9Tz1c37kyBEzePBgExYWZvLnz29q1KhhQkNDzebNm11cPTLjRn+2v/fee+bChQtOy//111/mpZdeMvnz5zfR0dEuqhq348CBA6Z06dImf/78platWmbdunXGGGPsdnuaZc+ePWuqV69u2rZta/z8/MzGjRutLhe36Vb6bYwxR48eNS+++CJ/l+dgN+u53W43V65cMUOHDjWVKlUyERER5qGHHjKFCxfmd/Ycavfu3SYkJMQMGTLEbNmyxXzyySemQYMGZvz48cYY5897SkqKMcaYJ5980uTPn9/s3LnTJTXj9hw/ftwUK1bMDB061OzcudPMnTvXtGnTxvj6+po5c+YYY4xZt26dqVKliqlRo4apVq2aad26tQkMDDTbtm1zcfXpI5TCTe3bt8+UK1cuzV9WY8aMMTabzUyePNkYY8yxY8fM+vXrzYgRI8zHH39s9u7d64JqkRVu1HMPDw8zbdo0Y8zVv9yWLVtm+vbta0qWLMkvNDlYRj/nsbGx5ujRo2batGlm8eLF5uDBgy6oFlnhVj7nMTEx5tVXXzXh4eGEkDnUlStXTL9+/Uy7du3MzJkzTdu2bU21atWuG1QcP37ceHl5mXz58vFnew50q/3+9ddfTZ8+fUzx4sXpdw6VkZ6nhhIxMTFm7ty55vHHHzdvvfUWv7PnUBcuXDAdOnQwjz/+uNP0Ll26mEaNGqW7ztSpU43NZuPv8hxsw4YNplKlSubQoUOOafHx8aZ///7G19fX/Pjjj8aYq7/nzZs3z/Tr18+MHTv2P/0PioRSuKmNGzcaHx8fR7KamJjomPfqq686zUPucLOe+/r6Ov4V9fjx4+aLL74wBw4ccEWpyCIZ+Zxv377dVeUhG9zK5zwpKckcPHjQHDt2zCW1ImssWLDAfPzxx8YYY1avXm3atGlz3aAiNjbWDBw40OzZs8clteL23Uq/T58+bebPn88/NORwGel5ajCFnO/06dNmwIAB5uuvvzbGGJOcnGyMMebbb7819913n0lOTnZMu9bff/9taZ3IWsuXLzc2m80cPXrUGPN/V8AlJyeb3r17m+DgYLN//35XlnjLbMbwLEjcXLNmzXTx4kV9//33KlCggJKSkuTt7a2UlBQ1b95cxYoV09SpU+Xh4cFj4XOJjPR8ypQp8vb2dhqjAjlXRno+bdo02Ww2Pue5REb/bL/2CWzIPVatWqUPPvhAf//9tyZPnqy7775bCQkJOnjwoMqVK+d4PyB3SK/fV65c0aFDh1SuXDn+Ls+Frtfzw4cP66677nJ1ebhNxhht2LBBtWvXdvxss9n0/fff67XXXtP69evl6ekpm82muLg4BQYGurhiZIWkpCTVr19fpUuX1sSJExUUFOQY1P7w4cPq3LmzWrRooZdeekkpKSn/zTGk/oVvFciQfv36KSUlRUOGDNH58+fl7e0tu90uT09PFSlSRGfOnJGXlxdfVHORjPQ89csKv8TmDhnpuaenJ5/zXCSjf7Yjd7Hb7ZKk+vXra8CAAbrzzjvVr18/rVmzRkOGDFHjxo0VHx9P73OJG/V76NChatKkieLj4/m7PBe5Wc9TP+PI2Ww2W5pASpIuXbqk+Ph4RyA1fPhwtWjRQklJSa4sF1nEy8tLHTt21L59+/Thhx/q4sWLjt/Nixcvrrx582rPnj2SlCMCKYmn7yGDWrRooX379mnu3Lnq16+fPvroI8cjpL29vRUcHKykpCR5eXnxS00uQc/dDz13P/TcPXl4eDi+wKQ+lefDDz9Uw4YNlTdvXv3vf/9Tvnz5XFwlsgr9dj/03P1c+3d0UFCQ/P39HYHU+++/r19//ZUrX3OB1M/1008/rb/++kvff/+9Ll++rOHDh8vf31+SVLhwYRUsWFB2u102my1H/P7G7Xu4qdTLAVNSUjRt2jR99dVX2r9/vx566CH9888/+umnn7Ru3TpVqlTJ1aUii9Bz90PP3Q89x7X/sv7QQw9p7dq1WrNmjSpWrOjiypAd6Lf7oefuafny5Ro9erRq1qypDz/8UL/99ptq1Kjh6rKQRVJ/f0tKStLw4cP1yy+/6PLly2rVqpUOHDighQsXav369apQoYKrS80wQik4SX2TX2+6MUZ//fWXPv/8cx04cEDBwcF6+umnc9SbHs7oufuh5+6Hnruf6/X831JSUvTWW29p9OjRWrt2rSIjI7O/OGQ5+u1+6Ln7yWjPZ8+erc6dOytv3rxatWqVqlevbkF1yEopKSmy2+1OV7ddGzJf+w+LK1eu1Jw5c3Tw4EGFhITohRdeUOXKlV1VeqYQSkGHDh3Sb7/9ps6dO0u6/h94DICZe9Bz90PP3Q89dz8Z7fm/LVy4UGXKlCGEzGHot/uh5+4nMz3fvHmzXnzxRY0fP56e50C7d+/W+PHjFR0drerVq6tVq1Zq0KBBmuX+/V4wxsgYkyPHfmVMKTe3d+9e3X333QoJCdHly5f12GOPycPDI90/8FK/tPAFJmej5+6Hnrsfeu5+bqXn/9ayZUuLqkRWod/uh567n8z2PDIyUrNnz3aMEYmcY9euXWrYsKGaNWumatWq6eeff9aBAwdUuXJlFSxY0GnZ1PdA6u9vOWX8qPRwpZQbO3v2rLp06eIYFO3MmTPq2bOnevfuLSnj//qCnIOeux967n7oufuh5+6Ffrsfeu5+Mttz/oEp54qJidFDDz2kBg0a6N1335UkRUdHq2bNmpo9e7YeeughF1eYffjTy40lJiaqZMmS6tevn6ZNm6YiRYpoxowZmj59uqT/e3JHKvLLnI+eux967n7oufuh5+6Ffrsfeu5+MttzAqmca8uWLSpevLh69eolSUpKSlJERITq1q2rM2fOSMq9n22ulHJTqSl6TEyMQkNDHf/fv39/xcTEqEePHurTp4+kqx8IHiGa89Fz90PP3Q89dz/03L3Qb/dDz90PPXdPu3fv1k8//aRnnnnGaXqTJk3UsGFDvfzyyy6qLPtxpZSbsdvtTj+HhITIZrMpMTFRYWFh+uijjxQWFqbPP/9c06dPV0JCgoYOHapXXnnFRRXjdtFz90PP3Q89dz/03L3Qb/dDz90PPXc/qT232+0qX768+vXr5zRdkry8vJScnOz4eerUqZozZ461hWYzrpRyI3v27NGHH36oCxcuKCQkREOGDFFoaKhjfkpKijw9PXXq1Ck9/fTTOnXqlJKTk7VlyxatWbOGx4nmQPTc/dBz90PP3Q89dy/02/3Qc/dDz93PzXqeOm5Y165dVbt2bQ0cOFAvvfSS3n//fW3dulXly5d3YfVZi1DKTURHR6tOnTp66KGHFB8frxMnTujvv//WJ598oubNm8vX11fS/735jx49qpo1ayoxMVErV65UlSpVXHwEuFX03P3Qc/dDz90PPXcv9Nv90HP3Q8/dT0Z7LkmtW7dWgwYNFB8frzFjxujXX39VzZo1XVh9NjDI9ex2u+nVq5dp37694+f4+HjTt29f4+fnZ7744guTkpLiWP7KlSumb9++JiAgwOzYscNVZeM20HP3Q8/dDz13P/TcvdBv90PP3Q89dz+32vO2bdsaf39/4+/vbzZs2OCqsrOVl6tDMWQ/m82m2NhYFStWTNLVwfPy5s2rqVOnytfXV/369VPZsmV19913y263y9vbW/v27dP//vc/VapUycXVIzPoufuh5+6Hnrsfeu5e6Lf7oefuh567n1vpeVJSkoKDgxUQEKAVK1bk2p5z+56bePLJJ/XLL79o9+7djgHzfHx8JEnt27dXdHS0Nm7cKH9/fxdXiqxCz90PPXc/9Nz90HP3Qr/dDz13P/Tc/dxKz7ds2aLAwECVLl3axVVnH56+l8ulZo5PPfWU/P391a9fPyUnJ8vHx0eJiYmSpAEDBujChQvas2dPmvWQ89Bz90PP3Q89dz/03L3Qb/dDz90PPXc/t9Lz3bt3S5KqVauWqwMpiVAq17PZbJKkiIgIde7cWRs3btTQoUOVlJTkSGNDQ0Pl6emplJSUNOsh56Hn7oeeux967n7ouXuh3+6Hnrsfeu5+bqXndrvdlaVaijGl3EDq5YDPPPOMkpOT9d1336l9+/aaMmWKLl26pJkzZ8rT09NxXytyPnrufui5+6Hn7oeeuxf67X7oufuh5+6HnqdFKJXLpaSkyMfHR3///bdWrFihYcOGqVSpUho/frzuvPNOlSxZUpcuXdL8+fMVGhrq6nKRBei5+6Hn7oeeux967l7ot/uh5+6Hnrsfep4+BjrPxex2uzw8PHTo0CHdc889euihhzRlyhTH/J9//ln58+dXaGioihYt6sJKkVXoufuh5+6Hnrsfeu5e6Lf7oefuh567H3p+fYRSucDu3bu1detWderUKc28M2fOKCoqSo0bN9bkyZNls9lkjOFe5ByOnrsfeu5+6Ln7oefuhX67H3rufui5+6Hnt47b93K4ffv2qVatWrp48aLOnj2rfv36Oc03xmjo0KHq06eP483u7m/6nI6eux967n7oufuh5+6Ffrsfeu5+6Ln7oeeZw5VSOVhsbKz69eunxMREVahQQa+//romTJig/v37S7p6z6qnp6eLq0RWoufuh567H3rufui5e6Hf7oeeux967n7oeeZxpVQOduHCBd1xxx2699571bRpUwUEBGjgwIGSpP79+8vDw8PFFSKr0XP3Q8/dDz13P/TcvdBv90PP3Q89dz/0/DYY5GgHDx50/P/FixfN22+/bWw2m/nggw8c05OSksyZM2dcUR6yAT13P/Tc/dBz90PP3Qv9dj/03P3Qc/dDzzOHK6VyGLvdLmOM49K/EiVKOAZHy5Mnj/r37y9jjFMqO3jwYAUGBuqVV16Rj4+PK8tHJtBz90PP3Q89dz/03L3Qb/dDz90PPXc/9DyLWBR+IQvs2rXLdO3a1TRu3Ng8+eSTZtGiRY55SUlJjv+/fPmyefvtt42Pj4+pU6eOsdlsZvPmza4oGbeJnrsfeu5+6Ln7oefuhX67H3rufui5+6HnWYeBznOIPXv2qE6dOnrwwQdVsmRJ/fjjj/L29ta9996rcePGSZKSk5Pl5XX14rfY2Fg1atRIBw8e1MqVK1W5cmVXlo9MoOfuh567H3rufui5e6Hf7oeeux967n7oeRZzdSqGm7Pb7eall14yHTp0cEyLi4szb7zxhomMjDSPP/64Y3pKSopJSUkxQ4YMMTabzWzfvt0VJeM20XP3Q8/dDz13P/TcvdBv90PP3Q89dz/0POsxBHwOYLPZdPz4ccXExDimBQQEaMCAAerWrZu2bNmit956S5Lk4eGhM2fOyG63a8uWLaSwORQ9dz/03P3Qc/dDz90L/XY/9Nz90HP3Q8+zHqHUf5z5/3dXVq9eXSkpKdqzZ49jXkBAgB577DFVq1ZNCxcu1IULFyRJhQsX1pgxY1S1alWX1IzbQ8/dDz13P/Tc/dBz90K/3Q89dz/03P3Q82zismu0cEv++usvU6hQIfPYY4+ZCxcuGGOuXjpojDGHDx82NpvN/Pjjj64sEVmMnrsfeu5+6Ln7oefuhX67H3rufui5+6HnWcvL1aEYMqZ06dKaM2eOHnzwQfn7+2vkyJEqVKiQJMnb21tVqlRRUFCQi6tEVqLn7oeeux967n7ouXuh3+6Hnrsfeu5+6HnWIpTKQRo2bKi5c+fqkUce0YkTJ9ShQwdVqVJFX3zxhU6dOqXw8HBXl4gsRs/dDz13P/Tc/dBz90K/3Q89dz/03P3Q86xjM+b/3xiJHGPz5s0aNGiQDh48KC8vL3l6euqbb75RtWrVXF0asgk9dz/03P3Qc/dDz90L/XY/9Nz90HP3Q89vH6FUDhUXF6ezZ8/qwoULKlKkiONyQeRe9Nz90HP3Q8/dDz13L/Tb/dBz90PP3Q89vz2EUgAAAAAAALCch6sLAAAAAAAAgPshlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAA4BYdPHhQNptNW7duzdb9jBw5UpGRkZle36o6AQAAMoNQCgAA5Cg9e/aUzWaTzWaTt7e3SpUqpaFDh+rKlSuW1RAeHq4TJ06oUqVKlu3z30aOHOk4D9d7/RfqJBgDAADXQygFAABynGbNmunEiRP6+++/NW7cOE2dOlUjRoywbP+enp4KCwuTl5eXZfv8t+eff14nTpxwvIoVK6bXXnvNadp/oU4AAIDrIZQCAAA5jq+vr8LCwhQeHq7WrVurSZMmWr58uWO+3W7X2LFjVapUKfn7+6tq1aqaN2+e0zZ27dqlhx56SIGBgQoICNB9992n/fv3O+Z/8sknioiIkJ+fn8qXL69JkyY55l179Y/dblexYsU0efJkp+1v2bJFHh4eOnTokCTp/Pnz6tOnj0JCQhQYGKhGjRpp27ZtTuu8+eabCg0NVUBAgHr37n3Dq7/y5cunsLAwx8vT01MBAQFO0/59ldLKlStls9m0bNkyVatWTf7+/mrUqJFOnTqlH3/8UREREQoMDFSXLl106dKlDJ/Pc+fOqWvXrgoJCZG/v7/Kli2rzz77TJJUqlQpSVK1atVks9nUoEEDSdKGDRt0//33q1ChQgoKClL9+vW1efNmp2O02WyaOnWqHnroIeXJk0cRERFat26d/vrrLzVo0EB58+ZV3bp1nfqWesvj1KlTFR4erjx58qhDhw6KjY297rkEAACuQSgFAABytJ07d+q3336Tj4+PY9rYsWP1xRdfaMqUKdq1a5eee+45devWTatWrZIkHTt2TPXq1ZOvr69+/vlnbdq0SY899piSk5MlSTNnztSrr76q0aNHKzo6WmPGjNErr7yizz//PM3+PTw81LlzZ82aNctp+syZM3XPPfeoRIkSkqRHHnnEEf5s2rRJ1atXV+PGjXX27FlJ0pw5czRy5EiNGTNGGzduVJEiRZyCsKw0cuRITZw4Ub/99puOHDmiDh06aPz48Zo1a5YWL16s//3vf/rwww8zfD5feeUV/fnnn/rxxx8VHR2tyZMnq1ChQpKkP/74Q5L0008/6cSJE/ruu+8kSRcuXFCPHj20Zs0a/f777ypbtqyaN2+uCxcuONX6+uuvq3v37tq6davKly+vLl266IknntCwYcO0ceNGGWP0zDPPOK3z119/ac6cOfrhhx+0dOlSbdmyRf369cuWcwkAAG6DAQAAyEF69OhhPD09Td68eY2vr6+RZDw8PMy8efOMMcZcuXLF5MmTx/z2229O6/Xu3dt07tzZGGPMsGHDTKlSpUxiYmK6+yhdurSZNWuW07TXX3/dREVFGWOMOXDggJFktmzZYowxZsuWLcZms5lDhw4ZY4xJSUkxd9xxh5k8ebIxxpjVq1ebwMBAc+XKlTT7mTp1qjHGmKioKNOvXz+n+XXq1DFVq1bN0HkpUaKEGTdunNO0f9f5yy+/GEnmp59+ciwzduxYI8ns37/fMe2JJ54wTZs2NcZk7Hw+/PDDplevXunW9e8ariclJcUEBASYH374wTFNkhk+fLjj53Xr1hlJZvr06Y5pX3/9tfHz83P8PGLECOPp6WmOHj3qmPbjjz8aDw8Pc+LEiRvWAAAArMUAAwAAIMdp2LChJk+erIsXL2rcuHHy8vJSu3btJF29SubSpUu6//77ndZJTExUtWrVJElbt27VfffdJ29v7zTbvnjxovbv36/evXvr8ccfd0xPTk5WUFBQuvVERkYqIiJCs2bN0osvvqhVq1bp1KlTeuSRRyRJ27ZtU3x8vAoWLOi03uXLlx23nkVHR+vJJ590mh8VFaVffvnlVk5NhlSpUsXx/6GhocqTJ4/uvPNOp2mpVzhl5Hw+9dRTateunTZv3qwHHnhArVu3Vt26dW9Yw8mTJzV8+HCtXLlSp06dUkpKii5duqTDhw/fsFZJqly5stO0K1euKC4uToGBgZKk4sWL64477nAsExUVJbvdrj179igsLOzmJwgAAFiCUAoAAOQ4efPmVZkyZSRJn376qapWrarp06erd+/eio+PlyQtXrzYKZiQro5FJUn+/v7X3Xbq+h9//LHq1KnjNM/T0/O663Xt2tURSs2aNUvNmjVzhFDx8fEqUqSIVq5cmWa94ODgGx9sNrg2jEt9iuG1bDab7Ha7JGXofD744IM6dOiQlixZouXLl6tx48Z6+umn9e677163hh49euiff/7RhAkTVKJECfn6+ioqKkqJiYk3rPV601LrBQAAOQehFAAAyNE8PDz00ksvadCgQerSpYsqVKggX19fHT58WPXr1093nSpVqujzzz9XUlJSmkAmNDRURYsW1d9//62uXbtmuI4uXbpo+PDh2rRpk+bNm6cpU6Y45lWvXl0xMTHy8vJSyZIl010/IiJC69evV/fu3R3Tfv/99wzvP7tk5HxKUkhIiHr06KEePXrovvvu05AhQ/Tuu+86xvpKSUlxWn7t2rWaNGmSmjdvLkk6cuSIzpw5kyU1Hz58WMePH1fRokUlXT2PHh4eKleuXJZsHwAAZA1CKQAAkOM98sgjGjJkiD766CM9//zzev755/Xcc8/Jbrfr3nvvVWxsrNauXavAwED16NFDzzzzjD788EN16tRJw4YNU1BQkH7//XfVrl1b5cqV06hRozRgwAAFBQWpWbNmSkhI0MaNG3Xu3DkNGjQo3RpKliypunXrqnfv3kpJSVHLli0d85o0aaKoqCi1bt1ab7/9tu666y4dP35cixcvVps2bVSzZk0NHDhQPXv2VM2aNXXPPfdo5syZ2rVrl9Ntda4QEBBw0/P56quvqkaNGqpYsaISEhK0aNEiRURESJIKFy4sf39/LV26VMWKFZOfn5+CgoJUtmxZffnll6pZs6bi4uI0ZMiQG17Bdiv8/PzUo0cPvfvuu4qLi9OAAQPUoUMHbt0DAOA/hqfvAQCAHM/Ly0vPPPOM3n77bV28eFGvv/66XnnlFY0dO1YRERFq1qyZFi9erFKlSkmSChYsqJ9//lnx8fGqX7++atSooY8//thx1VSfPn30ySef6LPPPlPlypVVv359zZgxw7H+9XTt2lXbtm1TmzZtnAIWm82mJUuWqF69eurVq5fuuusuderUSYcOHXKMk9SxY0e98sorGjp0qGrUqKFDhw7pqaeeyqYzdmtudj59fHw0bNgwValSRfXq1ZOnp6e++eYbSVd788EHH2jq1KkqWrSoWrVqJUmaPn26zp07p+rVq+vRRx/VgAEDVLhw4Sypt0yZMmrbtq2aN2+uBx54QFWqVMm2JxkCAIDMs5n/174dEwEQhEAQPOlIQgqOeAmfXO0l3QqIp5bdfX0EAADcUFWnu8/MvD4FAPhhKQUAAABAnCgFAAAAQJz3PQAAAADiLKUAAAAAiBOlAAAAAIgTpQAAAACIE6UAAAAAiBOlAAAAAIgTpQAAAACIE6UAAAAAiBOlAAAAAIgTpQAAAACI+wCcCj/mQ/2DlAAAAABJRU5ErkJggg=="
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 1200x600 with 1 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 1200x600 with 1 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 1200x600 with 1 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        }
      ],
      "execution_count": 35,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731538786302
        }
      },
      "id": "f71e0a33-7995-4be2-aa66-c84152b9ddd5"
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_real = scaler.inverse_transform(y_test)\n",
        "#y_test = y_test.reshape(-1, 1)  # Reshape if necessary\n",
        "#y_pred = y_pred.reshape(-1, 1)  # Reshape if necessary"
      ],
      "outputs": [],
      "execution_count": 36,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731538786754
        }
      },
      "id": "2515526e-3d8f-4202-839e-6303769964c2"
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_real"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 37,
          "data": {
            "text/plain": "array([[ 53.75052789],\n       [ 55.23332034],\n       [ 56.35447688],\n       [ 56.95255504],\n       [ 57.75175071],\n       [ 58.94249819],\n       [ 59.89847245],\n       [ 60.24088309],\n       [ 60.09080768],\n       [ 59.63187681],\n       [ 58.85013704],\n       [ 57.77635611],\n       [ 57.09741943],\n       [ 56.21225009],\n       [ 55.13299727],\n       [ 54.23387556],\n       [ 53.37454492],\n       [ 52.34880912],\n       [ 51.22816036],\n       [ 49.82464357],\n       [ 48.56797607],\n       [ 47.14388568],\n       [ 45.97942391],\n       [ 44.75470054],\n       [ 43.58383804],\n       [ 42.61797834],\n       [ 41.98031184],\n       [ 41.13153507],\n       [ 40.28219329],\n       [ 39.61574802],\n       [ 39.04735182],\n       [ 38.54240309],\n       [ 38.06305435],\n       [ 37.59380206],\n       [ 37.10513423],\n       [ 36.50582598],\n       [ 35.86361642],\n       [ 35.12847157],\n       [ 34.23363883],\n       [ 33.32475172],\n       [ 32.69186195],\n       [ 32.54880178],\n       [ 32.5608196 ],\n       [ 32.5589575 ],\n       [ 32.56648075],\n       [ 32.43263834],\n       [ 32.25059694],\n       [ 31.35541419],\n       [ 30.20019964],\n       [ 28.89969932],\n       [ 27.60695333],\n       [ 26.52309732],\n       [ 25.0881761 ],\n       [ 24.02019723],\n       [ 23.55929126],\n       [ 23.08694277],\n       [ 23.09080643],\n       [ 23.0841965 ],\n       [ 23.08424933],\n       [ 23.08425043],\n       [ 23.084255  ],\n       [ 23.0842686 ],\n       [ 23.08424162],\n       [ 23.08413213],\n       [ 23.084253  ],\n       [ 23.08424917],\n       [ 22.51423891],\n       [ 23.43873962],\n       [ 23.7044366 ],\n       [ 23.62756523],\n       [ 22.36254959],\n       [ 20.84909782],\n       [ 19.35285647],\n       [ 17.5470084 ],\n       [ 15.88786327],\n       [ 14.60675389],\n       [ 13.1013489 ],\n       [ 11.62549956],\n       [ 10.01427993],\n       [  8.61266599],\n       [  6.76424573],\n       [  5.01477116],\n       [  3.47158247],\n       [  1.98127352],\n       [  0.63887774],\n       [ -0.74602757],\n       [ -2.35326593],\n       [ -3.72860911],\n       [ -5.01794812],\n       [ -5.86335851],\n       [ -7.64054182],\n       [ -8.85973045],\n       [ -9.62639063],\n       [ -9.88618835],\n       [-10.06054056],\n       [-10.29820892],\n       [-10.5846203 ],\n       [-10.79005701],\n       [-10.96651716],\n       [-11.11781112],\n       [-11.17961944],\n       [-11.26980433],\n       [-11.40195368],\n       [-11.46619586],\n       [-11.481667  ],\n       [-11.4957595 ],\n       [-11.14361478],\n       [-10.66174267],\n       [-10.35570568],\n       [ -9.35909   ],\n       [ -8.59467844],\n       [ -6.79193502],\n       [ -5.48274503],\n       [ -4.11442253],\n       [ -2.38081753],\n       [ -0.7303937 ],\n       [  1.08844275],\n       [  2.91585316],\n       [  5.37015452],\n       [  7.96142447],\n       [ 10.587647  ],\n       [ 13.73757507],\n       [ 17.00075785],\n       [ 20.25266623],\n       [ 23.75191776],\n       [ 27.59744893],\n       [ 30.72264792],\n       [ 33.10192186],\n       [ 33.57513636],\n       [ 33.79456505],\n       [ 33.97834793],\n       [ 33.93635916],\n       [ 33.82304533],\n       [ 33.857779  ],\n       [ 33.84517153],\n       [ 33.712487  ],\n       [ 33.6872356 ],\n       [ 33.40158294],\n       [ 33.28096795],\n       [ 33.98623986],\n       [ 34.26284114],\n       [ 33.71876278],\n       [ 33.6015006 ],\n       [ 33.5276634 ],\n       [ 33.23889607],\n       [ 33.2389116 ],\n       [ 33.23912728],\n       [ 33.23894418],\n       [ 33.3125738 ],\n       [ 33.38620342],\n       [ 34.64013856],\n       [ 36.35017769],\n       [ 37.32975332],\n       [ 36.54189164],\n       [ 32.34482902],\n       [ 27.83511575],\n       [ 24.09208013],\n       [ 20.26286424],\n       [ 16.77415373],\n       [ 13.74826025],\n       [ 10.9647146 ],\n       [  8.26176304],\n       [  5.70088817],\n       [  3.148259  ],\n       [  1.35206543],\n       [ -0.42451171],\n       [ -2.12817952],\n       [ -3.73828448],\n       [ -4.86404518],\n       [ -6.26451181],\n       [ -7.40950815],\n       [ -8.82376829],\n       [ -9.86315   ],\n       [-10.374764  ],\n       [-10.91618573],\n       [-11.48662833],\n       [-11.46530213],\n       [-11.434934  ],\n       [-11.41034079],\n       [-11.37766091],\n       [-11.35911315],\n       [-11.33456219],\n       [-11.312607  ],\n       [-11.0681923 ],\n       [-10.84558133],\n       [-10.60919994],\n       [-10.35774768],\n       [-10.10491287],\n       [ -9.73130741],\n       [ -8.68549208],\n       [ -7.24301496],\n       [ -5.61445809],\n       [ -3.74564131],\n       [ -2.13025724],\n       [ -0.49927033],\n       [  0.89176825],\n       [  2.58249029],\n       [  3.9762881 ],\n       [  5.48716261],\n       [  6.96693721],\n       [  8.60270801],\n       [ 10.14696851],\n       [ 11.72366604],\n       [ 13.26352408],\n       [ 14.80430519],\n       [ 16.18653801],\n       [ 17.77267974],\n       [ 19.11860184],\n       [ 20.78860147],\n       [ 22.11040405],\n       [ 23.54122695],\n       [ 25.12960932],\n       [ 26.43762582],\n       [ 28.3759589 ],\n       [ 29.59718789],\n       [ 31.00215735],\n       [ 32.05298192],\n       [ 32.48529319],\n       [ 33.41549249],\n       [ 32.52231503],\n       [ 32.37098592],\n       [ 32.3298825 ],\n       [ 32.54414108],\n       [ 32.90227767],\n       [ 33.83891886],\n       [ 34.71451525],\n       [ 35.55664888],\n       [ 36.22675801],\n       [ 36.84238071],\n       [ 37.45043455],\n       [ 38.02703051],\n       [ 38.56148925],\n       [ 39.16839633],\n       [ 39.71625222],\n       [ 40.26693283],\n       [ 41.33658068],\n       [ 41.94373283],\n       [ 42.77154793],\n       [ 43.32591532],\n       [ 44.82107504],\n       [ 45.84696574],\n       [ 47.72390322],\n       [ 48.84101443],\n       [ 50.28377938],\n       [ 51.23822236],\n       [ 53.14127771],\n       [ 54.27212128],\n       [ 55.53318921],\n       [ 56.56365733],\n       [ 58.17054805],\n       [ 59.65521234],\n       [ 60.78459467],\n       [ 61.82785989],\n       [ 63.32302426],\n       [ 65.06146167],\n       [ 65.92424264],\n       [ 67.32842071],\n       [ 68.4027895 ],\n       [ 70.16000133],\n       [ 71.05981242],\n       [ 72.09103944],\n       [ 73.44699481],\n       [ 74.47987504],\n       [ 75.70382732],\n       [ 76.96420354],\n       [ 77.91993733],\n       [ 79.12809413],\n       [ 80.20175879],\n       [ 81.42701014],\n       [ 82.9551821 ],\n       [ 84.08405647],\n       [ 85.48423909],\n       [ 86.51250642],\n       [ 87.76716817],\n       [ 88.81201468],\n       [ 90.05880106],\n       [ 91.11601851],\n       [ 92.53240826],\n       [ 93.25869511],\n       [ 94.35225812]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 37,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731538787183
        }
      },
      "id": "2ffaa217-ecf8-4a0e-97d7-51e20148d018"
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_real = scaler.inverse_transform(y_pred)\n",
        "y_pred_real"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 38,
          "data": {
            "text/plain": "array([[ 4.85242882e+01],\n       [ 4.86289253e+01],\n       [ 4.88076973e+01],\n       [ 4.90601807e+01],\n       [ 4.93789597e+01],\n       [ 4.97579079e+01],\n       [ 5.01943550e+01],\n       [ 5.06841049e+01],\n       [ 5.12109947e+01],\n       [ 5.17550735e+01],\n       [ 5.22957115e+01],\n       [ 5.28107376e+01],\n       [ 5.32781105e+01],\n       [ 5.36853333e+01],\n       [ 5.40209770e+01],\n       [ 5.42751846e+01],\n       [ 5.44442635e+01],\n       [ 5.45278587e+01],\n       [ 5.45257187e+01],\n       [ 5.44382248e+01],\n       [ 5.42635040e+01],\n       [ 5.40032654e+01],\n       [ 5.36582222e+01],\n       [ 5.32338638e+01],\n       [ 5.27351646e+01],\n       [ 5.21656189e+01],\n       [ 5.15347595e+01],\n       [ 5.08553505e+01],\n       [ 5.01367416e+01],\n       [ 4.93890572e+01],\n       [ 4.86196976e+01],\n       [ 4.78403053e+01],\n       [ 4.70622215e+01],\n       [ 4.62915192e+01],\n       [ 4.55320625e+01],\n       [ 4.47892151e+01],\n       [ 4.40671654e+01],\n       [ 4.33674927e+01],\n       [ 4.26887093e+01],\n       [ 4.20268784e+01],\n       [ 4.13778076e+01],\n       [ 4.07379951e+01],\n       [ 4.01140785e+01],\n       [ 3.95142632e+01],\n       [ 3.89438210e+01],\n       [ 3.84077263e+01],\n       [ 3.79086342e+01],\n       [ 3.74468460e+01],\n       [ 3.70131226e+01],\n       [ 3.65926666e+01],\n       [ 3.61715050e+01],\n       [ 3.57355080e+01],\n       [ 3.52774658e+01],\n       [ 3.47872696e+01],\n       [ 3.42613335e+01],\n       [ 3.37053757e+01],\n       [ 3.31285210e+01],\n       [ 3.25448189e+01],\n       [ 3.19660568e+01],\n       [ 3.14027691e+01],\n       [ 3.08635025e+01],\n       [ 3.03547058e+01],\n       [ 2.98808136e+01],\n       [ 2.94445286e+01],\n       [ 2.90474739e+01],\n       [ 2.86896267e+01],\n       [ 2.83702602e+01],\n       [ 2.80809364e+01],\n       [ 2.78317089e+01],\n       [ 2.76219978e+01],\n       [ 2.74453869e+01],\n       [ 2.72815800e+01],\n       [ 2.71089325e+01],\n       [ 2.69082165e+01],\n       [ 2.66603374e+01],\n       [ 2.63515739e+01],\n       [ 2.59802990e+01],\n       [ 2.55427017e+01],\n       [ 2.50375500e+01],\n       [ 2.44632893e+01],\n       [ 2.38218994e+01],\n       [ 2.31137962e+01],\n       [ 2.23381290e+01],\n       [ 2.14968052e+01],\n       [ 2.05964394e+01],\n       [ 1.96433792e+01],\n       [ 1.86458530e+01],\n       [ 1.76086006e+01],\n       [ 1.65386791e+01],\n       [ 1.54434986e+01],\n       [ 1.43351593e+01],\n       [ 1.32130499e+01],\n       [ 1.20824604e+01],\n       [ 1.09534025e+01],\n       [ 9.84101105e+00],\n       [ 8.76233482e+00],\n       [ 7.72100878e+00],\n       [ 6.72850037e+00],\n       [ 5.79244375e+00],\n       [ 4.92207003e+00],\n       [ 4.11957407e+00],\n       [ 3.38514495e+00],\n       [ 2.71885943e+00],\n       [ 2.11681700e+00],\n       [ 1.57418835e+00],\n       [ 1.08924925e+00],\n       [ 6.58530474e-01],\n       [ 2.83404291e-01],\n       [-3.52625586e-02],\n       [-2.96173722e-01],\n       [-4.93570834e-01],\n       [-6.25842035e-01],\n       [-6.79668903e-01],\n       [-6.49838328e-01],\n       [-5.32048047e-01],\n       [-3.19333106e-01],\n       [-1.02456231e-02],\n       [ 3.97291780e-01],\n       [ 9.01828945e-01],\n       [ 1.51421368e+00],\n       [ 2.23761535e+00],\n       [ 3.07433152e+00],\n       [ 4.03066587e+00],\n       [ 5.11400604e+00],\n       [ 6.32941008e+00],\n       [ 7.68189240e+00],\n       [ 9.17726040e+00],\n       [ 1.08098602e+01],\n       [ 1.25622282e+01],\n       [ 1.43914604e+01],\n       [ 1.62534924e+01],\n       [ 1.81083164e+01],\n       [ 1.99189911e+01],\n       [ 2.16551552e+01],\n       [ 2.32960682e+01],\n       [ 2.48255138e+01],\n       [ 2.62331047e+01],\n       [ 2.75163288e+01],\n       [ 2.86690655e+01],\n       [ 2.96954288e+01],\n       [ 3.06064377e+01],\n       [ 3.14164791e+01],\n       [ 3.21263542e+01],\n       [ 3.27412148e+01],\n       [ 3.32692795e+01],\n       [ 3.37146873e+01],\n       [ 3.40863953e+01],\n       [ 3.43901138e+01],\n       [ 3.46339493e+01],\n       [ 3.48268661e+01],\n       [ 3.49746437e+01],\n       [ 3.50998535e+01],\n       [ 3.52294655e+01],\n       [ 3.53761673e+01],\n       [ 3.55258293e+01],\n       [ 3.56236420e+01],\n       [ 3.56141815e+01],\n       [ 3.54648933e+01],\n       [ 3.51425819e+01],\n       [ 3.46278496e+01],\n       [ 3.39174767e+01],\n       [ 3.30176773e+01],\n       [ 3.19395962e+01],\n       [ 3.07002068e+01],\n       [ 2.93180923e+01],\n       [ 2.78203564e+01],\n       [ 2.62345123e+01],\n       [ 2.45842400e+01],\n       [ 2.28880424e+01],\n       [ 2.11734810e+01],\n       [ 1.94620590e+01],\n       [ 1.77679806e+01],\n       [ 1.61005230e+01],\n       [ 1.44715433e+01],\n       [ 1.28939037e+01],\n       [ 1.13786545e+01],\n       [ 9.93337250e+00],\n       [ 8.56945705e+00],\n       [ 7.29576063e+00],\n       [ 6.11243057e+00],\n       [ 5.02098703e+00],\n       [ 4.02592421e+00],\n       [ 3.13376307e+00],\n       [ 2.35554552e+00],\n       [ 1.68697536e+00],\n       [ 1.11781955e+00],\n       [ 6.42178118e-01],\n       [ 2.51975805e-01],\n       [-6.13380969e-02],\n       [-3.03609908e-01],\n       [-4.71855551e-01],\n       [-5.58962464e-01],\n       [-5.56098223e-01],\n       [-4.57043111e-01],\n       [-2.57291138e-01],\n       [ 4.47417051e-02],\n       [ 4.45208430e-01],\n       [ 9.40156281e-01],\n       [ 1.52458596e+00],\n       [ 2.19124079e+00],\n       [ 2.93467212e+00],\n       [ 3.74800539e+00],\n       [ 4.62286949e+00],\n       [ 5.55430222e+00],\n       [ 6.53698158e+00],\n       [ 7.56292152e+00],\n       [ 8.62558079e+00],\n       [ 9.72139931e+00],\n       [ 1.08442249e+01],\n       [ 1.19925671e+01],\n       [ 1.31609354e+01],\n       [ 1.43456936e+01],\n       [ 1.55446091e+01],\n       [ 1.67536545e+01],\n       [ 1.79769535e+01],\n       [ 1.92096157e+01],\n       [ 2.04492493e+01],\n       [ 2.16885910e+01],\n       [ 2.29105721e+01],\n       [ 2.41076221e+01],\n       [ 2.52516594e+01],\n       [ 2.63270931e+01],\n       [ 2.73259010e+01],\n       [ 2.82455349e+01],\n       [ 2.90895901e+01],\n       [ 2.98684540e+01],\n       [ 3.05955124e+01],\n       [ 3.12811947e+01],\n       [ 3.19335117e+01],\n       [ 3.25576439e+01],\n       [ 3.31589165e+01],\n       [ 3.37406540e+01],\n       [ 3.43052940e+01],\n       [ 3.48555374e+01],\n       [ 3.53936920e+01],\n       [ 3.59199562e+01],\n       [ 3.64434662e+01],\n       [ 3.69637146e+01],\n       [ 3.74860840e+01],\n       [ 3.80092583e+01],\n       [ 3.85438118e+01],\n       [ 3.90951805e+01],\n       [ 3.96744156e+01],\n       [ 4.02874527e+01],\n       [ 4.09380836e+01],\n       [ 4.16246490e+01],\n       [ 4.23581810e+01],\n       [ 4.31321602e+01],\n       [ 4.39528046e+01],\n       [ 4.48089561e+01],\n       [ 4.57009773e+01],\n       [ 4.66267281e+01],\n       [ 4.75799484e+01],\n       [ 4.85513496e+01],\n       [ 4.95416489e+01],\n       [ 5.05546227e+01],\n       [ 5.15826797e+01],\n       [ 5.26253738e+01],\n       [ 5.36774864e+01],\n       [ 5.47437325e+01],\n       [ 5.58170204e+01],\n       [ 5.68920937e+01],\n       [ 5.79693985e+01],\n       [ 5.90448799e+01],\n       [ 6.01153145e+01],\n       [ 6.11834373e+01],\n       [ 6.22443810e+01],\n       [ 6.32998657e+01],\n       [ 6.43438721e+01],\n       [ 6.53803101e+01],\n       [ 6.64105682e+01],\n       [ 6.74384842e+01],\n       [ 6.84656754e+01],\n       [ 6.94923248e+01],\n       [ 7.05144501e+01],\n       [ 7.15340271e+01],\n       [ 7.25510712e+01],\n       [ 7.35647888e+01],\n       [ 7.45755997e+01],\n       [ 7.55779037e+01]], dtype=float32)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 38,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1731538787541
        }
      },
      "id": "3ee7b76b-b5a4-448b-a1f5-97be512b9658"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "a3ef21f8-3a19-4770-af67-6150cb53d9e6"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}